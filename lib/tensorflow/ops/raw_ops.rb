# Generated by `rake generate_ops`
module Tensorflow
  module RawOps
    def self.abort(error_msg: nil, exit_without_error: nil)
      OpsExecutor.execute("Abort", [], error_msg: error_msg, exit_without_error: exit_without_error)
    end

    def self.abs(x: nil)
      OpsExecutor.execute("Abs", [x])
    end

    def self.accumulate_nv2(inputs: nil, shape: nil)
      OpsExecutor.execute("AccumulateNV2", [inputs], shape: shape)
    end

    def self.accumulator_apply_gradient(handle: nil, local_step: nil, gradient: nil, dtype: nil)
      OpsExecutor.execute("AccumulatorApplyGradient", [handle, local_step, gradient], dtype: dtype)
    end

    def self.accumulator_num_accumulated(handle: nil)
      OpsExecutor.execute("AccumulatorNumAccumulated", [handle])
    end

    def self.accumulator_set_global_step(handle: nil, new_global_step: nil)
      OpsExecutor.execute("AccumulatorSetGlobalStep", [handle, new_global_step])
    end

    def self.accumulator_take_gradient(handle: nil, num_required: nil, dtype: nil)
      OpsExecutor.execute("AccumulatorTakeGradient", [handle, num_required], dtype: dtype)
    end

    def self.acos(x: nil)
      OpsExecutor.execute("Acos", [x])
    end

    def self.acosh(x: nil)
      OpsExecutor.execute("Acosh", [x])
    end

    def self.add(x: nil, y: nil)
      OpsExecutor.execute("Add", [x, y])
    end

    def self.add_many_sparse_to_tensors_map(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("AddManySparseToTensorsMap", [sparse_indices, sparse_values, sparse_shape], container: container, shared_name: shared_name)
    end

    def self.add_n(inputs: nil)
      OpsExecutor.execute("AddN", [inputs])
    end

    def self.add_sparse_to_tensors_map(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("AddSparseToTensorsMap", [sparse_indices, sparse_values, sparse_shape], container: container, shared_name: shared_name)
    end

    def self.add_v2(x: nil, y: nil)
      OpsExecutor.execute("AddV2", [x, y])
    end

    def self.adjust_contrast(images: nil, contrast_factor: nil, min_value: nil, max_value: nil)
      OpsExecutor.execute("AdjustContrast", [images, contrast_factor, min_value, max_value])
    end

    def self.adjust_contrastv2(images: nil, contrast_factor: nil)
      OpsExecutor.execute("AdjustContrastv2", [images, contrast_factor])
    end

    def self.adjust_hue(images: nil, delta: nil)
      OpsExecutor.execute("AdjustHue", [images, delta])
    end

    def self.adjust_saturation(images: nil, scale: nil)
      OpsExecutor.execute("AdjustSaturation", [images, scale])
    end

    def self.all(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("All", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.all_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("AllCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, seed: seed, seed2: seed2)
    end

    def self.all_to_all(input: nil, group_assignment: nil, concat_dimension: nil, split_dimension: nil, split_count: nil)
      OpsExecutor.execute("AllToAll", [input, group_assignment], concat_dimension: concat_dimension, split_dimension: split_dimension, split_count: split_count)
    end

    def self.angle(input: nil)
      OpsExecutor.execute("Angle", [input])
    end

    def self.anonymous_iterator(output_types: nil, output_shapes: nil)
      OpsExecutor.execute("AnonymousIterator", [], output_types: output_types, output_shapes: output_shapes)
    end

    def self.anonymous_iterator_v2(output_types: nil, output_shapes: nil)
      OpsExecutor.execute("AnonymousIteratorV2", [], output_types: output_types, output_shapes: output_shapes)
    end

    def self.any(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("Any", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.apply_ada_max(var: nil, m: nil, v: nil, beta1_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ApplyAdaMax", [var, m, v, beta1_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking)
    end

    def self.apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad], use_locking: use_locking)
    end

    def self.apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, use_locking: nil, update_slots: nil)
      OpsExecutor.execute("ApplyAdagrad", [var, accum, lr, grad], use_locking: use_locking, update_slots: update_slots)
    end

    def self.apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
      OpsExecutor.execute("ApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step], use_locking: use_locking)
    end

    def self.apply_adam(var: nil, m: nil, v: nil, beta1_power: nil, beta2_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("ApplyAdam", [var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.apply_add_sign(var: nil, m: nil, lr: nil, alpha: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ApplyAddSign", [var, m, lr, alpha, sign_decay, beta, grad], use_locking: use_locking)
    end

    def self.apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
    end

    def self.apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("ApplyFtrl", [var, accum, linear, grad, lr, l1, l2, lr_power], use_locking: use_locking)
    end

    def self.apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("ApplyFtrlV2", [var, accum, linear, grad, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
    end

    def self.apply_gradient_descent(var: nil, alpha: nil, delta: nil, use_locking: nil)
      OpsExecutor.execute("ApplyGradientDescent", [var, alpha, delta], use_locking: use_locking)
    end

    def self.apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("ApplyMomentum", [var, accum, lr, grad, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.apply_power_sign(var: nil, m: nil, lr: nil, logbase: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ApplyPowerSign", [var, m, lr, logbase, sign_decay, beta, grad], use_locking: use_locking)
    end

    def self.apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ApplyProximalAdagrad", [var, accum, lr, l1, l2, grad], use_locking: use_locking)
    end

    def self.apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, delta: nil, use_locking: nil)
      OpsExecutor.execute("ApplyProximalGradientDescent", [var, alpha, l1, l2, delta], use_locking: use_locking)
    end

    def self.apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
    end

    def self.approximate_equal(x: nil, y: nil, tolerance: nil)
      OpsExecutor.execute("ApproximateEqual", [x, y], tolerance: tolerance)
    end

    def self.arg_max(input: nil, dimension: nil, output_type: nil)
      OpsExecutor.execute("ArgMax", [input, dimension], output_type: output_type)
    end

    def self.arg_min(input: nil, dimension: nil, output_type: nil)
      OpsExecutor.execute("ArgMin", [input, dimension], output_type: output_type)
    end

    def self.as_string(input: nil, precision: nil, scientific: nil, shortest: nil, width: nil, fill: nil)
      OpsExecutor.execute("AsString", [input], precision: precision, scientific: scientific, shortest: shortest, width: width, fill: fill)
    end

    def self.asin(x: nil)
      OpsExecutor.execute("Asin", [x])
    end

    def self.asinh(x: nil)
      OpsExecutor.execute("Asinh", [x])
    end

    def self.assert(condition: nil, data: nil, summarize: nil)
      OpsExecutor.execute("Assert", [condition, data], summarize: summarize)
    end

    def self.assign(ref: nil, value: nil, validate_shape: nil, use_locking: nil)
      OpsExecutor.execute("Assign", [ref, value], validate_shape: validate_shape, use_locking: use_locking)
    end

    def self.assign_add(ref: nil, value: nil, use_locking: nil)
      OpsExecutor.execute("AssignAdd", [ref, value], use_locking: use_locking)
    end

    def self.assign_add_variable_op(resource: nil, value: nil, dtype: nil)
      OpsExecutor.execute("AssignAddVariableOp", [resource, value], dtype: dtype)
    end

    def self.assign_sub(ref: nil, value: nil, use_locking: nil)
      OpsExecutor.execute("AssignSub", [ref, value], use_locking: use_locking)
    end

    def self.assign_sub_variable_op(resource: nil, value: nil, dtype: nil)
      OpsExecutor.execute("AssignSubVariableOp", [resource, value], dtype: dtype)
    end

    def self.assign_variable_op(resource: nil, value: nil, dtype: nil)
      OpsExecutor.execute("AssignVariableOp", [resource, value], dtype: dtype)
    end

    def self.atan(x: nil)
      OpsExecutor.execute("Atan", [x])
    end

    def self.atan2(y: nil, x: nil)
      OpsExecutor.execute("Atan2", [y, x])
    end

    def self.atanh(x: nil)
      OpsExecutor.execute("Atanh", [x])
    end

    def self.audio_spectrogram(input: nil, window_size: nil, stride: nil, magnitude_squared: nil)
      OpsExecutor.execute("AudioSpectrogram", [input], window_size: window_size, stride: stride, magnitude_squared: magnitude_squared)
    end

    def self.audio_summary(tag: nil, tensor: nil, sample_rate: nil, max_outputs: nil)
      OpsExecutor.execute("AudioSummary", [tag, tensor], sample_rate: sample_rate, max_outputs: max_outputs)
    end

    def self.audio_summary_v2(tag: nil, tensor: nil, sample_rate: nil, max_outputs: nil)
      OpsExecutor.execute("AudioSummaryV2", [tag, tensor, sample_rate], max_outputs: max_outputs)
    end

    def self.avg_pool(value: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("AvgPool", [value], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.avg_pool3d(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("AvgPool3D", [input], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.avg_pool3d_grad(orig_input_shape: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("AvgPool3DGrad", [orig_input_shape, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.avg_pool_grad(orig_input_shape: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("AvgPoolGrad", [orig_input_shape, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.barrier(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("Barrier", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
    end

    def self.barrier_close(handle: nil, cancel_pending_enqueues: nil)
      OpsExecutor.execute("BarrierClose", [handle], cancel_pending_enqueues: cancel_pending_enqueues)
    end

    def self.barrier_incomplete_size(handle: nil)
      OpsExecutor.execute("BarrierIncompleteSize", [handle])
    end

    def self.barrier_insert_many(handle: nil, keys: nil, values: nil, component_index: nil)
      OpsExecutor.execute("BarrierInsertMany", [handle, keys, values], component_index: component_index)
    end

    def self.barrier_ready_size(handle: nil)
      OpsExecutor.execute("BarrierReadySize", [handle])
    end

    def self.barrier_take_many(handle: nil, num_elements: nil, component_types: nil, allow_small_batch: nil, wait_for_incomplete: nil, timeout_ms: nil)
      OpsExecutor.execute("BarrierTakeMany", [handle, num_elements], component_types: component_types, allow_small_batch: allow_small_batch, wait_for_incomplete: wait_for_incomplete, timeout_ms: timeout_ms)
    end

    def self.batch(in_tensors: nil, num_batch_threads: nil, max_batch_size: nil, max_enqueued_batches: nil, batch_timeout_micros: nil, allowed_batch_sizes: nil, grad_timeout_micros: nil, container: nil, shared_name: nil, batching_queue: nil)
      OpsExecutor.execute("Batch", [in_tensors], num_batch_threads: num_batch_threads, max_batch_size: max_batch_size, max_enqueued_batches: max_enqueued_batches, batch_timeout_micros: batch_timeout_micros, allowed_batch_sizes: allowed_batch_sizes, grad_timeout_micros: grad_timeout_micros, container: container, shared_name: shared_name, batching_queue: batching_queue)
    end

    def self.batch_cholesky(input: nil)
      OpsExecutor.execute("BatchCholesky", [input])
    end

    def self.batch_cholesky_grad(l: nil, grad: nil)
      OpsExecutor.execute("BatchCholeskyGrad", [l, grad])
    end

    def self.batch_dataset(input_dataset: nil, batch_size: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("BatchDataset", [input_dataset, batch_size], output_types: output_types, output_shapes: output_shapes)
    end

    def self.batch_dataset_v2(input_dataset: nil, batch_size: nil, drop_remainder: nil, parallel_copy: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("BatchDatasetV2", [input_dataset, batch_size, drop_remainder], parallel_copy: parallel_copy, output_types: output_types, output_shapes: output_shapes)
    end

    def self.batch_fft(input: nil)
      OpsExecutor.execute("BatchFFT", [input])
    end

    def self.batch_fft2d(input: nil)
      OpsExecutor.execute("BatchFFT2D", [input])
    end

    def self.batch_fft3d(input: nil)
      OpsExecutor.execute("BatchFFT3D", [input])
    end

    def self.batch_function(in_tensors: nil, captured_tensors: nil, f: nil, num_batch_threads: nil, max_batch_size: nil, batch_timeout_micros: nil, max_enqueued_batches: nil, allowed_batch_sizes: nil, container: nil, shared_name: nil, batching_queue: nil)
      OpsExecutor.execute("BatchFunction", [in_tensors, captured_tensors], f: f, num_batch_threads: num_batch_threads, max_batch_size: max_batch_size, batch_timeout_micros: batch_timeout_micros, max_enqueued_batches: max_enqueued_batches, allowed_batch_sizes: allowed_batch_sizes, container: container, shared_name: shared_name, batching_queue: batching_queue)
    end

    def self.batch_ifft(input: nil)
      OpsExecutor.execute("BatchIFFT", [input])
    end

    def self.batch_ifft2d(input: nil)
      OpsExecutor.execute("BatchIFFT2D", [input])
    end

    def self.batch_ifft3d(input: nil)
      OpsExecutor.execute("BatchIFFT3D", [input])
    end

    def self.batch_mat_mul(x: nil, y: nil, adj_x: nil, adj_y: nil)
      OpsExecutor.execute("BatchMatMul", [x, y], adj_x: adj_x, adj_y: adj_y)
    end

    def self.batch_mat_mul_v2(x: nil, y: nil, adj_x: nil, adj_y: nil)
      OpsExecutor.execute("BatchMatMulV2", [x, y], adj_x: adj_x, adj_y: adj_y)
    end

    def self.batch_matrix_band_part(input: nil, num_lower: nil, num_upper: nil)
      OpsExecutor.execute("BatchMatrixBandPart", [input, num_lower, num_upper])
    end

    def self.batch_matrix_determinant(input: nil)
      OpsExecutor.execute("BatchMatrixDeterminant", [input])
    end

    def self.batch_matrix_diag(diagonal: nil)
      OpsExecutor.execute("BatchMatrixDiag", [diagonal])
    end

    def self.batch_matrix_diag_part(input: nil)
      OpsExecutor.execute("BatchMatrixDiagPart", [input])
    end

    def self.batch_matrix_inverse(input: nil, adjoint: nil)
      OpsExecutor.execute("BatchMatrixInverse", [input], adjoint: adjoint)
    end

    def self.batch_matrix_set_diag(input: nil, diagonal: nil)
      OpsExecutor.execute("BatchMatrixSetDiag", [input, diagonal])
    end

    def self.batch_matrix_solve(matrix: nil, rhs: nil, adjoint: nil)
      OpsExecutor.execute("BatchMatrixSolve", [matrix, rhs], adjoint: adjoint)
    end

    def self.batch_matrix_solve_ls(matrix: nil, rhs: nil, l2_regularizer: nil, fast: nil)
      OpsExecutor.execute("BatchMatrixSolveLs", [matrix, rhs, l2_regularizer], fast: fast)
    end

    def self.batch_matrix_triangular_solve(matrix: nil, rhs: nil, lower: nil, adjoint: nil)
      OpsExecutor.execute("BatchMatrixTriangularSolve", [matrix, rhs], lower: lower, adjoint: adjoint)
    end

    def self.batch_norm_with_global_normalization(t: nil, m: nil, v: nil, beta: nil, gamma: nil, variance_epsilon: nil, scale_after_normalization: nil)
      OpsExecutor.execute("BatchNormWithGlobalNormalization", [t, m, v, beta, gamma], variance_epsilon: variance_epsilon, scale_after_normalization: scale_after_normalization)
    end

    def self.batch_norm_with_global_normalization_grad(t: nil, m: nil, v: nil, gamma: nil, backprop: nil, variance_epsilon: nil, scale_after_normalization: nil)
      OpsExecutor.execute("BatchNormWithGlobalNormalizationGrad", [t, m, v, gamma, backprop], variance_epsilon: variance_epsilon, scale_after_normalization: scale_after_normalization)
    end

    def self.batch_self_adjoint_eig(input: nil)
      OpsExecutor.execute("BatchSelfAdjointEig", [input])
    end

    def self.batch_self_adjoint_eig_v2(input: nil, compute_v: nil)
      OpsExecutor.execute("BatchSelfAdjointEigV2", [input], compute_v: compute_v)
    end

    def self.batch_svd(input: nil, compute_uv: nil, full_matrices: nil)
      OpsExecutor.execute("BatchSvd", [input], compute_uv: compute_uv, full_matrices: full_matrices)
    end

    def self.batch_to_space(input: nil, crops: nil, block_size: nil)
      OpsExecutor.execute("BatchToSpace", [input, crops], block_size: block_size)
    end

    def self.batch_to_space_nd(input: nil, block_shape: nil, crops: nil)
      OpsExecutor.execute("BatchToSpaceND", [input, block_shape, crops])
    end

    def self.bessel_i0e(x: nil)
      OpsExecutor.execute("BesselI0e", [x])
    end

    def self.bessel_i1e(x: nil)
      OpsExecutor.execute("BesselI1e", [x])
    end

    def self.betainc(a: nil, b: nil, x: nil)
      OpsExecutor.execute("Betainc", [a, b, x])
    end

    def self.bias_add(value: nil, bias: nil, data_format: nil)
      OpsExecutor.execute("BiasAdd", [value, bias], data_format: data_format)
    end

    def self.bias_add_grad(out_backprop: nil, data_format: nil)
      OpsExecutor.execute("BiasAddGrad", [out_backprop], data_format: data_format)
    end

    def self.bias_add_v1(value: nil, bias: nil)
      OpsExecutor.execute("BiasAddV1", [value, bias])
    end

    def self.big_query_reader(container: nil, shared_name: nil, project_id: nil, dataset_id: nil, table_id: nil, columns: nil, timestamp_millis: nil, test_end_point: nil)
      OpsExecutor.execute("BigQueryReader", [], container: container, shared_name: shared_name, project_id: project_id, dataset_id: dataset_id, table_id: table_id, columns: columns, timestamp_millis: timestamp_millis, test_end_point: test_end_point)
    end

    def self.bincount(arr: nil, size: nil, weights: nil)
      OpsExecutor.execute("Bincount", [arr, size, weights])
    end

    def self.bitcast(input: nil, type: nil)
      OpsExecutor.execute("Bitcast", [input], type: type)
    end

    def self.bitwise_and(x: nil, y: nil)
      OpsExecutor.execute("BitwiseAnd", [x, y])
    end

    def self.bitwise_or(x: nil, y: nil)
      OpsExecutor.execute("BitwiseOr", [x, y])
    end

    def self.bitwise_xor(x: nil, y: nil)
      OpsExecutor.execute("BitwiseXor", [x, y])
    end

    def self.boosted_trees_aggregate_stats(node_ids: nil, gradients: nil, hessians: nil, feature: nil, max_splits: nil, num_buckets: nil)
      OpsExecutor.execute("BoostedTreesAggregateStats", [node_ids, gradients, hessians, feature], max_splits: max_splits, num_buckets: num_buckets)
    end

    def self.boosted_trees_bucketize(float_values: nil, bucket_boundaries: nil, num_features: nil)
      OpsExecutor.execute("BoostedTreesBucketize", [float_values, bucket_boundaries], num_features: num_features)
    end

    def self.boosted_trees_calculate_best_feature_split(node_id_range: nil, stats_summary: nil, l1: nil, l2: nil, tree_complexity: nil, min_node_weight: nil, logits_dimension: nil, split_type: nil)
      OpsExecutor.execute("BoostedTreesCalculateBestFeatureSplit", [node_id_range, stats_summary, l1, l2, tree_complexity, min_node_weight], logits_dimension: logits_dimension, split_type: split_type)
    end

    def self.boosted_trees_calculate_best_gains_per_feature(node_id_range: nil, stats_summary_list: nil, l1: nil, l2: nil, tree_complexity: nil, min_node_weight: nil, max_splits: nil, num_features: nil)
      OpsExecutor.execute("BoostedTreesCalculateBestGainsPerFeature", [node_id_range, stats_summary_list, l1, l2, tree_complexity, min_node_weight], max_splits: max_splits, num_features: num_features)
    end

    def self.boosted_trees_center_bias(tree_ensemble_handle: nil, mean_gradients: nil, mean_hessians: nil, l1: nil, l2: nil)
      OpsExecutor.execute("BoostedTreesCenterBias", [tree_ensemble_handle, mean_gradients, mean_hessians, l1, l2])
    end

    def self.boosted_trees_create_ensemble(tree_ensemble_handle: nil, stamp_token: nil, tree_ensemble_serialized: nil)
      OpsExecutor.execute("BoostedTreesCreateEnsemble", [tree_ensemble_handle, stamp_token, tree_ensemble_serialized])
    end

    def self.boosted_trees_create_quantile_stream_resource(quantile_stream_resource_handle: nil, epsilon: nil, num_streams: nil, max_elements: nil)
      OpsExecutor.execute("BoostedTreesCreateQuantileStreamResource", [quantile_stream_resource_handle, epsilon, num_streams], max_elements: max_elements)
    end

    def self.boosted_trees_deserialize_ensemble(tree_ensemble_handle: nil, stamp_token: nil, tree_ensemble_serialized: nil)
      OpsExecutor.execute("BoostedTreesDeserializeEnsemble", [tree_ensemble_handle, stamp_token, tree_ensemble_serialized])
    end

    def self.boosted_trees_ensemble_resource_handle_op(container: nil, shared_name: nil)
      OpsExecutor.execute("BoostedTreesEnsembleResourceHandleOp", [], container: container, shared_name: shared_name)
    end

    def self.boosted_trees_example_debug_outputs(tree_ensemble_handle: nil, bucketized_features: nil, num_bucketized_features: nil, logits_dimension: nil)
      OpsExecutor.execute("BoostedTreesExampleDebugOutputs", [tree_ensemble_handle, bucketized_features], num_bucketized_features: num_bucketized_features, logits_dimension: logits_dimension)
    end

    def self.boosted_trees_get_ensemble_states(tree_ensemble_handle: nil)
      OpsExecutor.execute("BoostedTreesGetEnsembleStates", [tree_ensemble_handle])
    end

    def self.boosted_trees_make_quantile_summaries(float_values: nil, example_weights: nil, epsilon: nil, num_features: nil)
      OpsExecutor.execute("BoostedTreesMakeQuantileSummaries", [float_values, example_weights, epsilon], num_features: num_features)
    end

    def self.boosted_trees_make_stats_summary(node_ids: nil, gradients: nil, hessians: nil, bucketized_features_list: nil, max_splits: nil, num_buckets: nil, num_features: nil)
      OpsExecutor.execute("BoostedTreesMakeStatsSummary", [node_ids, gradients, hessians, bucketized_features_list], max_splits: max_splits, num_buckets: num_buckets, num_features: num_features)
    end

    def self.boosted_trees_predict(tree_ensemble_handle: nil, bucketized_features: nil, num_bucketized_features: nil, logits_dimension: nil)
      OpsExecutor.execute("BoostedTreesPredict", [tree_ensemble_handle, bucketized_features], num_bucketized_features: num_bucketized_features, logits_dimension: logits_dimension)
    end

    def self.boosted_trees_quantile_stream_resource_add_summaries(quantile_stream_resource_handle: nil, summaries: nil, num_features: nil)
      OpsExecutor.execute("BoostedTreesQuantileStreamResourceAddSummaries", [quantile_stream_resource_handle, summaries], num_features: num_features)
    end

    def self.boosted_trees_quantile_stream_resource_deserialize(quantile_stream_resource_handle: nil, bucket_boundaries: nil, num_streams: nil)
      OpsExecutor.execute("BoostedTreesQuantileStreamResourceDeserialize", [quantile_stream_resource_handle, bucket_boundaries], num_streams: num_streams)
    end

    def self.boosted_trees_quantile_stream_resource_flush(quantile_stream_resource_handle: nil, num_buckets: nil, generate_quantiles: nil)
      OpsExecutor.execute("BoostedTreesQuantileStreamResourceFlush", [quantile_stream_resource_handle, num_buckets], generate_quantiles: generate_quantiles)
    end

    def self.boosted_trees_quantile_stream_resource_get_bucket_boundaries(quantile_stream_resource_handle: nil, num_features: nil)
      OpsExecutor.execute("BoostedTreesQuantileStreamResourceGetBucketBoundaries", [quantile_stream_resource_handle], num_features: num_features)
    end

    def self.boosted_trees_quantile_stream_resource_handle_op(container: nil, shared_name: nil)
      OpsExecutor.execute("BoostedTreesQuantileStreamResourceHandleOp", [], container: container, shared_name: shared_name)
    end

    def self.boosted_trees_serialize_ensemble(tree_ensemble_handle: nil)
      OpsExecutor.execute("BoostedTreesSerializeEnsemble", [tree_ensemble_handle])
    end

    def self.boosted_trees_training_predict(tree_ensemble_handle: nil, cached_tree_ids: nil, cached_node_ids: nil, bucketized_features: nil, num_bucketized_features: nil, logits_dimension: nil)
      OpsExecutor.execute("BoostedTreesTrainingPredict", [tree_ensemble_handle, cached_tree_ids, cached_node_ids, bucketized_features], num_bucketized_features: num_bucketized_features, logits_dimension: logits_dimension)
    end

    def self.boosted_trees_update_ensemble(tree_ensemble_handle: nil, feature_ids: nil, node_ids: nil, gains: nil, thresholds: nil, left_node_contribs: nil, right_node_contribs: nil, max_depth: nil, learning_rate: nil, pruning_mode: nil, num_features: nil)
      OpsExecutor.execute("BoostedTreesUpdateEnsemble", [tree_ensemble_handle, feature_ids, node_ids, gains, thresholds, left_node_contribs, right_node_contribs, max_depth, learning_rate], pruning_mode: pruning_mode, num_features: num_features)
    end

    def self.broadcast_args(s0: nil, s1: nil)
      OpsExecutor.execute("BroadcastArgs", [s0, s1])
    end

    def self.broadcast_gradient_args(s0: nil, s1: nil)
      OpsExecutor.execute("BroadcastGradientArgs", [s0, s1])
    end

    def self.broadcast_to(input: nil, shape: nil)
      OpsExecutor.execute("BroadcastTo", [input, shape])
    end

    def self.bucketize(input: nil, boundaries: nil)
      OpsExecutor.execute("Bucketize", [input], boundaries: boundaries)
    end

    def self.ctc_beam_search_decoder(inputs: nil, sequence_length: nil, beam_width: nil, top_paths: nil, merge_repeated: nil)
      OpsExecutor.execute("CTCBeamSearchDecoder", [inputs, sequence_length], beam_width: beam_width, top_paths: top_paths, merge_repeated: merge_repeated)
    end

    def self.ctc_greedy_decoder(inputs: nil, sequence_length: nil, merge_repeated: nil)
      OpsExecutor.execute("CTCGreedyDecoder", [inputs, sequence_length], merge_repeated: merge_repeated)
    end

    def self.ctc_loss(inputs: nil, labels_indices: nil, labels_values: nil, sequence_length: nil, preprocess_collapse_repeated: nil, ctc_merge_repeated: nil, ignore_longer_outputs_than_inputs: nil)
      OpsExecutor.execute("CTCLoss", [inputs, labels_indices, labels_values, sequence_length], preprocess_collapse_repeated: preprocess_collapse_repeated, ctc_merge_repeated: ctc_merge_repeated, ignore_longer_outputs_than_inputs: ignore_longer_outputs_than_inputs)
    end

    def self.cache_dataset(input_dataset: nil, filename: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("CacheDataset", [input_dataset, filename], output_types: output_types, output_shapes: output_shapes)
    end

    def self.case(branch_index: nil, input: nil, branches: nil, output_shapes: nil)
      OpsExecutor.execute("Case", [branch_index, input], branches: branches, output_shapes: output_shapes)
    end

    def self.cast(x: nil, srct: nil, dstt: nil, truncate: false)
      OpsExecutor.execute("Cast", [x], SrcT: srct, DstT: dstt, truncate: truncate)
    end

    def self.ceil(x: nil)
      OpsExecutor.execute("Ceil", [x])
    end

    def self.check_numerics(tensor: nil, message: nil)
      OpsExecutor.execute("CheckNumerics", [tensor], message: message)
    end

    def self.cholesky(input: nil)
      OpsExecutor.execute("Cholesky", [input])
    end

    def self.cholesky_grad(l: nil, grad: nil)
      OpsExecutor.execute("CholeskyGrad", [l, grad])
    end

    def self.choose_fastest_branch_dataset(input_dataset: nil, ratio_numerator: nil, ratio_denominator: nil, other_arguments: nil, num_elements_per_branch: nil, branches: nil, other_arguments_lengths: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ChooseFastestBranchDataset", [input_dataset, ratio_numerator, ratio_denominator, other_arguments], num_elements_per_branch: num_elements_per_branch, branches: branches, other_arguments_lengths: other_arguments_lengths, output_types: output_types, output_shapes: output_shapes)
    end

    def self.clip_by_value(t: nil, clip_value_min: nil, clip_value_max: nil)
      OpsExecutor.execute("ClipByValue", [t, clip_value_min, clip_value_max])
    end

    def self.close_summary_writer(writer: nil)
      OpsExecutor.execute("CloseSummaryWriter", [writer])
    end

    def self.collective_bcast_recv(group_size: nil, group_key: nil, instance_key: nil, shape: nil)
      OpsExecutor.execute("CollectiveBcastRecv", [], group_size: group_size, group_key: group_key, instance_key: instance_key, shape: shape)
    end

    def self.collective_bcast_send(input: nil, group_size: nil, group_key: nil, instance_key: nil, shape: nil)
      OpsExecutor.execute("CollectiveBcastSend", [input], group_size: group_size, group_key: group_key, instance_key: instance_key, shape: shape)
    end

    def self.collective_gather(input: nil, group_size: nil, group_key: nil, instance_key: nil, shape: nil)
      OpsExecutor.execute("CollectiveGather", [input], group_size: group_size, group_key: group_key, instance_key: instance_key, shape: shape)
    end

    def self.collective_permute(input: nil, source_target_pairs: nil)
      OpsExecutor.execute("CollectivePermute", [input, source_target_pairs])
    end

    def self.collective_reduce(input: nil, group_size: nil, group_key: nil, instance_key: nil, merge_op: nil, final_op: nil, subdiv_offsets: nil, wait_for: nil)
      OpsExecutor.execute("CollectiveReduce", [input], group_size: group_size, group_key: group_key, instance_key: instance_key, merge_op: merge_op, final_op: final_op, subdiv_offsets: subdiv_offsets, wait_for: wait_for)
    end

    def self.combined_non_max_suppression(boxes: nil, scores: nil, max_output_size_per_class: nil, max_total_size: nil, iou_threshold: nil, score_threshold: nil, pad_per_class: nil, clip_boxes: nil)
      OpsExecutor.execute("CombinedNonMaxSuppression", [boxes, scores, max_output_size_per_class, max_total_size, iou_threshold, score_threshold], pad_per_class: pad_per_class, clip_boxes: clip_boxes)
    end

    def self.compare_and_bitpack(input: nil, threshold: nil)
      OpsExecutor.execute("CompareAndBitpack", [input, threshold])
    end

    def self.complex(real: nil, imag: nil)
      OpsExecutor.execute("Complex", [real, imag])
    end

    def self.complex_abs(x: nil)
      OpsExecutor.execute("ComplexAbs", [x])
    end

    def self.compute_accidental_hits(true_classes: nil, sampled_candidates: nil, num_true: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("ComputeAccidentalHits", [true_classes, sampled_candidates], num_true: num_true, seed: seed, seed2: seed2)
    end

    def self.concat(concat_dim: nil, values: nil)
      OpsExecutor.execute("Concat", [concat_dim, values])
    end

    def self.concat_offset(concat_dim: nil, shape: nil)
      OpsExecutor.execute("ConcatOffset", [concat_dim, shape])
    end

    def self.concat_v2(values: nil, axis: nil)
      OpsExecutor.execute("ConcatV2", [values, axis])
    end

    def self.concatenate_dataset(input_dataset: nil, another_dataset: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ConcatenateDataset", [input_dataset, another_dataset], output_types: output_types, output_shapes: output_shapes)
    end

    def self.conditional_accumulator(dtype: nil, shape: nil, container: nil, shared_name: nil, reduction_type: nil)
      OpsExecutor.execute("ConditionalAccumulator", [], dtype: dtype, shape: shape, container: container, shared_name: shared_name, reduction_type: reduction_type)
    end

    def self.configure_distributed_tpu(embedding_config: nil, tpu_embedding_config: nil, is_global_init: nil)
      OpsExecutor.execute("ConfigureDistributedTPU", [], embedding_config: embedding_config, tpu_embedding_config: tpu_embedding_config, is_global_init: is_global_init)
    end

    def self.conj(input: nil)
      OpsExecutor.execute("Conj", [input])
    end

    def self.conjugate_transpose(x: nil, perm: nil)
      OpsExecutor.execute("ConjugateTranspose", [x, perm])
    end

    def self.const(value: nil, dtype: nil)
      OpsExecutor.execute("Const", [], value: value, dtype: dtype)
    end

    def self.consume_mutex_lock(mutex_lock: nil)
      OpsExecutor.execute("ConsumeMutexLock", [mutex_lock])
    end

    def self.control_trigger
      OpsExecutor.execute("ControlTrigger", [])
    end

    def self.conv2d(input: nil, filter: nil, strides: nil, use_cudnn_on_gpu: nil, padding: nil, explicit_paddings: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("Conv2D", [input, filter], strides: strides, use_cudnn_on_gpu: use_cudnn_on_gpu, padding: padding, explicit_paddings: explicit_paddings, data_format: data_format, dilations: dilations)
    end

    def self.conv2d_backprop_filter(input: nil, filter_sizes: nil, out_backprop: nil, strides: nil, use_cudnn_on_gpu: nil, padding: nil, explicit_paddings: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("Conv2DBackpropFilter", [input, filter_sizes, out_backprop], strides: strides, use_cudnn_on_gpu: use_cudnn_on_gpu, padding: padding, explicit_paddings: explicit_paddings, data_format: data_format, dilations: dilations)
    end

    def self.conv2d_backprop_input(input_sizes: nil, filter: nil, out_backprop: nil, strides: nil, use_cudnn_on_gpu: nil, padding: nil, explicit_paddings: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("Conv2DBackpropInput", [input_sizes, filter, out_backprop], strides: strides, use_cudnn_on_gpu: use_cudnn_on_gpu, padding: padding, explicit_paddings: explicit_paddings, data_format: data_format, dilations: dilations)
    end

    def self.conv3d(input: nil, filter: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("Conv3D", [input, filter], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
    end

    def self.conv3d_backprop_filter(input: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("Conv3DBackpropFilter", [input, filter, out_backprop], strides: strides, padding: padding, dilations: dilations)
    end

    def self.conv3d_backprop_filter_v2(input: nil, filter_sizes: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("Conv3DBackpropFilterV2", [input, filter_sizes, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
    end

    def self.conv3d_backprop_input(input: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("Conv3DBackpropInput", [input, filter, out_backprop], strides: strides, padding: padding, dilations: dilations)
    end

    def self.conv3d_backprop_input_v2(input_sizes: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("Conv3DBackpropInputV2", [input_sizes, filter, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
    end

    def self.copy(input: nil, tensor_name: nil, debug_ops_spec: nil)
      OpsExecutor.execute("Copy", [input], tensor_name: tensor_name, debug_ops_spec: debug_ops_spec)
    end

    def self.copy_host(input: nil, tensor_name: nil, debug_ops_spec: nil)
      OpsExecutor.execute("CopyHost", [input], tensor_name: tensor_name, debug_ops_spec: debug_ops_spec)
    end

    def self.cos(x: nil)
      OpsExecutor.execute("Cos", [x])
    end

    def self.cosh(x: nil)
      OpsExecutor.execute("Cosh", [x])
    end

    def self.count_up_to(ref: nil, limit: nil)
      OpsExecutor.execute("CountUpTo", [ref], limit: limit)
    end

    def self.create_summary_db_writer(writer: nil, db_uri: nil, experiment_name: nil, run_name: nil, user_name: nil)
      OpsExecutor.execute("CreateSummaryDbWriter", [writer, db_uri, experiment_name, run_name, user_name])
    end

    def self.create_summary_file_writer(writer: nil, logdir: nil, max_queue: nil, flush_millis: nil, filename_suffix: nil)
      OpsExecutor.execute("CreateSummaryFileWriter", [writer, logdir, max_queue, flush_millis, filename_suffix])
    end

    def self.crop_and_resize(image: nil, boxes: nil, box_ind: nil, crop_size: nil, method: nil, extrapolation_value: nil)
      OpsExecutor.execute("CropAndResize", [image, boxes, box_ind, crop_size], method: method, extrapolation_value: extrapolation_value)
    end

    def self.crop_and_resize_grad_boxes(grads: nil, image: nil, boxes: nil, box_ind: nil, method: nil)
      OpsExecutor.execute("CropAndResizeGradBoxes", [grads, image, boxes, box_ind], method: method)
    end

    def self.crop_and_resize_grad_image(grads: nil, boxes: nil, box_ind: nil, image_size: nil, method: nil)
      OpsExecutor.execute("CropAndResizeGradImage", [grads, boxes, box_ind, image_size], method: method)
    end

    def self.cross(a: nil, b: nil)
      OpsExecutor.execute("Cross", [a, b])
    end

    def self.cross_replica_sum(input: nil, group_assignment: nil)
      OpsExecutor.execute("CrossReplicaSum", [input, group_assignment])
    end

    def self.cudnn_rnn(input: nil, input_h: nil, input_c: nil, params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, is_training: nil)
      OpsExecutor.execute("CudnnRNN", [input, input_h, input_c, params], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, is_training: is_training)
    end

    def self.cudnn_rnn_backprop(input: nil, input_h: nil, input_c: nil, params: nil, output: nil, output_h: nil, output_c: nil, output_backprop: nil, output_h_backprop: nil, output_c_backprop: nil, reserve_space: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("CudnnRNNBackprop", [input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
    end

    def self.cudnn_rnn_backprop_v2(input: nil, input_h: nil, input_c: nil, params: nil, output: nil, output_h: nil, output_c: nil, output_backprop: nil, output_h_backprop: nil, output_c_backprop: nil, reserve_space: nil, host_reserved: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("CudnnRNNBackpropV2", [input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, host_reserved], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
    end

    def self.cudnn_rnn_backprop_v3(input: nil, input_h: nil, input_c: nil, params: nil, sequence_lengths: nil, output: nil, output_h: nil, output_c: nil, output_backprop: nil, output_h_backprop: nil, output_c_backprop: nil, reserve_space: nil, host_reserved: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, time_major: nil)
      OpsExecutor.execute("CudnnRNNBackpropV3", [input, input_h, input_c, params, sequence_lengths, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, host_reserved], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, time_major: time_major)
    end

    def self.cudnn_rnn_canonical_to_params(num_layers: nil, num_units: nil, input_size: nil, weights: nil, biases: nil, num_params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("CudnnRNNCanonicalToParams", [num_layers, num_units, input_size, weights, biases], num_params: num_params, rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
    end

    def self.cudnn_rnn_params_size(num_layers: nil, num_units: nil, input_size: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("CudnnRNNParamsSize", [num_layers, num_units, input_size], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
    end

    def self.cudnn_rnn_params_to_canonical(num_layers: nil, num_units: nil, input_size: nil, params: nil, num_params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("CudnnRNNParamsToCanonical", [num_layers, num_units, input_size, params], num_params: num_params, rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
    end

    def self.cudnn_rnnv2(input: nil, input_h: nil, input_c: nil, params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, is_training: nil)
      OpsExecutor.execute("CudnnRNNV2", [input, input_h, input_c, params], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, is_training: is_training)
    end

    def self.cudnn_rnnv3(input: nil, input_h: nil, input_c: nil, params: nil, sequence_lengths: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, is_training: nil, time_major: nil)
      OpsExecutor.execute("CudnnRNNV3", [input, input_h, input_c, params, sequence_lengths], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, is_training: is_training, time_major: time_major)
    end

    def self.cumprod(x: nil, axis: nil, exclusive: nil, reverse: nil)
      OpsExecutor.execute("Cumprod", [x, axis], exclusive: exclusive, reverse: reverse)
    end

    def self.cumsum(x: nil, axis: nil, exclusive: nil, reverse: nil)
      OpsExecutor.execute("Cumsum", [x, axis], exclusive: exclusive, reverse: reverse)
    end

    def self.data_format_dim_map(x: nil, src_format: nil, dst_format: nil)
      OpsExecutor.execute("DataFormatDimMap", [x], src_format: src_format, dst_format: dst_format)
    end

    def self.data_format_vec_permute(x: nil, src_format: nil, dst_format: nil)
      OpsExecutor.execute("DataFormatVecPermute", [x], src_format: src_format, dst_format: dst_format)
    end

    def self.dataset_to_graph(input_dataset: nil)
      OpsExecutor.execute("DatasetToGraph", [input_dataset])
    end

    def self.dataset_to_single_element(dataset: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("DatasetToSingleElement", [dataset], output_types: output_types, output_shapes: output_shapes)
    end

    def self.debug_gradient_identity(input: nil)
      OpsExecutor.execute("DebugGradientIdentity", [input])
    end

    def self.debug_gradient_ref_identity(input: nil)
      OpsExecutor.execute("DebugGradientRefIdentity", [input])
    end

    def self.debug_identity(input: nil, device_name: nil, tensor_name: nil, debug_urls: nil, gated_grpc: nil)
      OpsExecutor.execute("DebugIdentity", [input], device_name: device_name, tensor_name: tensor_name, debug_urls: debug_urls, gated_grpc: gated_grpc)
    end

    def self.debug_nan_count(input: nil, device_name: nil, tensor_name: nil, debug_urls: nil, gated_grpc: nil)
      OpsExecutor.execute("DebugNanCount", [input], device_name: device_name, tensor_name: tensor_name, debug_urls: debug_urls, gated_grpc: gated_grpc)
    end

    def self.debug_numeric_summary(input: nil, device_name: nil, tensor_name: nil, debug_urls: nil, lower_bound: nil, upper_bound: nil, mute_if_healthy: nil, gated_grpc: nil)
      OpsExecutor.execute("DebugNumericSummary", [input], device_name: device_name, tensor_name: tensor_name, debug_urls: debug_urls, lower_bound: lower_bound, upper_bound: upper_bound, mute_if_healthy: mute_if_healthy, gated_grpc: gated_grpc)
    end

    def self.decode_and_crop_jpeg(contents: nil, crop_window: nil, channels: nil, ratio: nil, fancy_upscaling: nil, try_recover_truncated: nil, acceptable_fraction: nil, dct_method: nil)
      OpsExecutor.execute("DecodeAndCropJpeg", [contents, crop_window], channels: channels, ratio: ratio, fancy_upscaling: fancy_upscaling, try_recover_truncated: try_recover_truncated, acceptable_fraction: acceptable_fraction, dct_method: dct_method)
    end

    def self.decode_base64(input: nil)
      OpsExecutor.execute("DecodeBase64", [input])
    end

    def self.decode_bmp(contents: nil, channels: nil)
      OpsExecutor.execute("DecodeBmp", [contents], channels: channels)
    end

    def self.decode_csv(records: nil, record_defaults: nil, field_delim: nil, use_quote_delim: nil, na_value: nil, select_cols: nil)
      OpsExecutor.execute("DecodeCSV", [records, record_defaults], field_delim: field_delim, use_quote_delim: use_quote_delim, na_value: na_value, select_cols: select_cols)
    end

    def self.decode_compressed(bytes: nil, compression_type: nil)
      OpsExecutor.execute("DecodeCompressed", [bytes], compression_type: compression_type)
    end

    def self.decode_gif(contents: nil)
      OpsExecutor.execute("DecodeGif", [contents])
    end

    def self.decode_json_example(json_examples: nil)
      OpsExecutor.execute("DecodeJSONExample", [json_examples])
    end

    def self.decode_jpeg(contents: nil, channels: nil, ratio: nil, fancy_upscaling: nil, try_recover_truncated: nil, acceptable_fraction: nil, dct_method: nil)
      OpsExecutor.execute("DecodeJpeg", [contents], channels: channels, ratio: ratio, fancy_upscaling: fancy_upscaling, try_recover_truncated: try_recover_truncated, acceptable_fraction: acceptable_fraction, dct_method: dct_method)
    end

    def self.decode_padded_raw(input_bytes: nil, fixed_length: nil, out_type: nil, little_endian: nil)
      OpsExecutor.execute("DecodePaddedRaw", [input_bytes, fixed_length], out_type: out_type, little_endian: little_endian)
    end

    def self.decode_png(contents: nil, channels: nil, dtype: nil)
      OpsExecutor.execute("DecodePng", [contents], channels: channels, dtype: dtype)
    end

    def self.decode_proto_v2(bytes: nil, message_type: nil, field_names: nil, output_types: nil, descriptor_source: nil, message_format: nil, sanitize: nil)
      OpsExecutor.execute("DecodeProtoV2", [bytes], message_type: message_type, field_names: field_names, output_types: output_types, descriptor_source: descriptor_source, message_format: message_format, sanitize: sanitize)
    end

    def self.decode_raw(bytes: nil, out_type: nil, little_endian: nil)
      OpsExecutor.execute("DecodeRaw", [bytes], out_type: out_type, little_endian: little_endian)
    end

    def self.decode_wav(contents: nil, desired_channels: nil, desired_samples: nil)
      OpsExecutor.execute("DecodeWav", [contents], desired_channels: desired_channels, desired_samples: desired_samples)
    end

    def self.deep_copy(x: nil)
      OpsExecutor.execute("DeepCopy", [x])
    end

    def self.delete_iterator(handle: nil, deleter: nil)
      OpsExecutor.execute("DeleteIterator", [handle, deleter])
    end

    def self.delete_session_tensor(handle: nil)
      OpsExecutor.execute("DeleteSessionTensor", [handle])
    end

    def self.dense_to_dense_set_operation(set1: nil, set2: nil, set_operation: nil, validate_indices: nil)
      OpsExecutor.execute("DenseToDenseSetOperation", [set1, set2], set_operation: set_operation, validate_indices: validate_indices)
    end

    def self.dense_to_sparse_set_operation(set1: nil, set2_indices: nil, set2_values: nil, set2_shape: nil, set_operation: nil, validate_indices: nil)
      OpsExecutor.execute("DenseToSparseSetOperation", [set1, set2_indices, set2_values, set2_shape], set_operation: set_operation, validate_indices: validate_indices)
    end

    def self.depth_to_space(input: nil, block_size: nil, data_format: nil)
      OpsExecutor.execute("DepthToSpace", [input], block_size: block_size, data_format: data_format)
    end

    def self.depthwise_conv2d_native(input: nil, filter: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("DepthwiseConv2dNative", [input, filter], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
    end

    def self.depthwise_conv2d_native_backprop_filter(input: nil, filter_sizes: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("DepthwiseConv2dNativeBackpropFilter", [input, filter_sizes, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
    end

    def self.depthwise_conv2d_native_backprop_input(input_sizes: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
      OpsExecutor.execute("DepthwiseConv2dNativeBackpropInput", [input_sizes, filter, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
    end

    def self.dequantize(input: nil, min_range: nil, max_range: nil, mode: nil)
      OpsExecutor.execute("Dequantize", [input, min_range, max_range], mode: mode)
    end

    def self.deserialize_iterator(resource_handle: nil, serialized: nil)
      OpsExecutor.execute("DeserializeIterator", [resource_handle, serialized])
    end

    def self.deserialize_many_sparse(serialized_sparse: nil, dtype: nil)
      OpsExecutor.execute("DeserializeManySparse", [serialized_sparse], dtype: dtype)
    end

    def self.deserialize_sparse(serialized_sparse: nil, dtype: nil)
      OpsExecutor.execute("DeserializeSparse", [serialized_sparse], dtype: dtype)
    end

    def self.destroy_resource_op(resource: nil, ignore_lookup_error: nil)
      OpsExecutor.execute("DestroyResourceOp", [resource], ignore_lookup_error: ignore_lookup_error)
    end

    def self.destroy_temporary_variable(ref: nil, var_name: nil)
      OpsExecutor.execute("DestroyTemporaryVariable", [ref], var_name: var_name)
    end

    def self.diag(diagonal: nil)
      OpsExecutor.execute("Diag", [diagonal])
    end

    def self.diag_part(input: nil)
      OpsExecutor.execute("DiagPart", [input])
    end

    def self.digamma(x: nil)
      OpsExecutor.execute("Digamma", [x])
    end

    def self.dilation2d(input: nil, filter: nil, strides: nil, rates: nil, padding: nil)
      OpsExecutor.execute("Dilation2D", [input, filter], strides: strides, rates: rates, padding: padding)
    end

    def self.dilation2d_backprop_filter(input: nil, filter: nil, out_backprop: nil, strides: nil, rates: nil, padding: nil)
      OpsExecutor.execute("Dilation2DBackpropFilter", [input, filter, out_backprop], strides: strides, rates: rates, padding: padding)
    end

    def self.dilation2d_backprop_input(input: nil, filter: nil, out_backprop: nil, strides: nil, rates: nil, padding: nil)
      OpsExecutor.execute("Dilation2DBackpropInput", [input, filter, out_backprop], strides: strides, rates: rates, padding: padding)
    end

    def self.div(x: nil, y: nil)
      OpsExecutor.execute("Div", [x, y])
    end

    def self.div_no_nan(x: nil, y: nil)
      OpsExecutor.execute("DivNoNan", [x, y])
    end

    def self.draw_bounding_boxes(images: nil, boxes: nil)
      OpsExecutor.execute("DrawBoundingBoxes", [images, boxes])
    end

    def self.draw_bounding_boxes_v2(images: nil, boxes: nil, colors: nil)
      OpsExecutor.execute("DrawBoundingBoxesV2", [images, boxes, colors])
    end

    def self.dynamic_partition(data: nil, partitions: nil, num_partitions: nil)
      OpsExecutor.execute("DynamicPartition", [data, partitions], num_partitions: num_partitions)
    end

    def self.dynamic_stitch(indices: nil, data: nil)
      OpsExecutor.execute("DynamicStitch", [indices, data])
    end

    def self.eager_py_func(input: nil, token: nil)
      OpsExecutor.execute("EagerPyFunc", [input], token: token)
    end

    def self.edit_distance(hypothesis_indices: nil, hypothesis_values: nil, hypothesis_shape: nil, truth_indices: nil, truth_values: nil, truth_shape: nil, normalize: nil)
      OpsExecutor.execute("EditDistance", [hypothesis_indices, hypothesis_values, hypothesis_shape, truth_indices, truth_values, truth_shape], normalize: normalize)
    end

    def self.elu(features: nil)
      OpsExecutor.execute("Elu", [features])
    end

    def self.elu_grad(gradients: nil, outputs: nil)
      OpsExecutor.execute("EluGrad", [gradients, outputs])
    end

    def self.empty(shape: nil, dtype: nil, init: nil)
      OpsExecutor.execute("Empty", [shape], dtype: dtype, init: init)
    end

    def self.empty_tensor_list(element_shape: nil, max_num_elements: nil, element_dtype: nil, shape_type: nil)
      OpsExecutor.execute("EmptyTensorList", [element_shape, max_num_elements], element_dtype: element_dtype, shape_type: shape_type)
    end

    def self.encode_base64(input: nil, pad: nil)
      OpsExecutor.execute("EncodeBase64", [input], pad: pad)
    end

    def self.encode_jpeg(image: nil, format: nil, quality: nil, progressive: nil, optimize_size: nil, chroma_downsampling: nil, density_unit: nil, x_density: nil, y_density: nil, xmp_metadata: nil)
      OpsExecutor.execute("EncodeJpeg", [image], format: format, quality: quality, progressive: progressive, optimize_size: optimize_size, chroma_downsampling: chroma_downsampling, density_unit: density_unit, x_density: x_density, y_density: y_density, xmp_metadata: xmp_metadata)
    end

    def self.encode_jpeg_variable_quality(images: nil, quality: nil)
      OpsExecutor.execute("EncodeJpegVariableQuality", [images, quality])
    end

    def self.encode_png(image: nil, compression: nil)
      OpsExecutor.execute("EncodePng", [image], compression: compression)
    end

    def self.encode_proto(sizes: nil, values: nil, field_names: nil, message_type: nil, descriptor_source: nil)
      OpsExecutor.execute("EncodeProto", [sizes, values], field_names: field_names, message_type: message_type, descriptor_source: descriptor_source)
    end

    def self.encode_wav(audio: nil, sample_rate: nil)
      OpsExecutor.execute("EncodeWav", [audio, sample_rate])
    end

    def self.enqueue_tpu_embedding_integer_batch(batch: nil, mode_override: nil, device_ordinal: nil)
      OpsExecutor.execute("EnqueueTPUEmbeddingIntegerBatch", [batch, mode_override], device_ordinal: device_ordinal)
    end

    def self.enqueue_tpu_embedding_sparse_batch(sample_indices: nil, embedding_indices: nil, aggregation_weights: nil, mode_override: nil, device_ordinal: nil, combiners: nil)
      OpsExecutor.execute("EnqueueTPUEmbeddingSparseBatch", [sample_indices, embedding_indices, aggregation_weights, mode_override], device_ordinal: device_ordinal, combiners: combiners)
    end

    def self.enqueue_tpu_embedding_sparse_tensor_batch(sample_indices: nil, embedding_indices: nil, aggregation_weights: nil, mode_override: nil, device_ordinal: nil, combiners: nil, table_ids: nil, max_sequence_lengths: nil)
      OpsExecutor.execute("EnqueueTPUEmbeddingSparseTensorBatch", [sample_indices, embedding_indices, aggregation_weights, mode_override], device_ordinal: device_ordinal, combiners: combiners, table_ids: table_ids, max_sequence_lengths: max_sequence_lengths)
    end

    def self.ensure_shape(input: nil, shape: nil)
      OpsExecutor.execute("EnsureShape", [input], shape: shape)
    end

    def self.enter(data: nil, frame_name: nil, is_constant: nil, parallel_iterations: nil)
      OpsExecutor.execute("Enter", [data], frame_name: frame_name, is_constant: is_constant, parallel_iterations: parallel_iterations)
    end

    def self.equal(x: nil, y: nil)
      OpsExecutor.execute("Equal", [x, y])
    end

    def self.erf(x: nil)
      OpsExecutor.execute("Erf", [x])
    end

    def self.erfc(x: nil)
      OpsExecutor.execute("Erfc", [x])
    end

    def self.euclidean_norm(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("EuclideanNorm", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.exit(data: nil)
      OpsExecutor.execute("Exit", [data])
    end

    def self.exp(x: nil)
      OpsExecutor.execute("Exp", [x])
    end

    def self.expand_dims(input: nil, dim: nil)
      OpsExecutor.execute("ExpandDims", [input, dim])
    end

    def self.experimental_assert_next_dataset(input_dataset: nil, transformations: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalAssertNextDataset", [input_dataset, transformations], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_auto_shard_dataset(input_dataset: nil, num_workers: nil, index: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalAutoShardDataset", [input_dataset, num_workers, index], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_bytes_produced_stats_dataset(input_dataset: nil, tag: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalBytesProducedStatsDataset", [input_dataset, tag], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_csv_dataset(filenames: nil, compression_type: nil, buffer_size: nil, header: nil, field_delim: nil, use_quote_delim: nil, na_value: nil, select_cols: nil, record_defaults: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalCSVDataset", [filenames, compression_type, buffer_size, header, field_delim, use_quote_delim, na_value, select_cols, record_defaults], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_choose_fastest_dataset(input_datasets: nil, num_experiments: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalChooseFastestDataset", [input_datasets], num_experiments: num_experiments, output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_dataset_cardinality(input_dataset: nil)
      OpsExecutor.execute("ExperimentalDatasetCardinality", [input_dataset])
    end

    def self.experimental_dataset_to_tf_record(input_dataset: nil, filename: nil, compression_type: nil)
      OpsExecutor.execute("ExperimentalDatasetToTFRecord", [input_dataset, filename, compression_type])
    end

    def self.experimental_dense_to_sparse_batch_dataset(input_dataset: nil, batch_size: nil, row_shape: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalDenseToSparseBatchDataset", [input_dataset, batch_size, row_shape], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_directed_interleave_dataset(selector_input_dataset: nil, data_input_datasets: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalDirectedInterleaveDataset", [selector_input_dataset, data_input_datasets], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_group_by_reducer_dataset(input_dataset: nil, key_func_other_arguments: nil, init_func_other_arguments: nil, reduce_func_other_arguments: nil, finalize_func_other_arguments: nil, key_func: nil, init_func: nil, reduce_func: nil, finalize_func: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalGroupByReducerDataset", [input_dataset, key_func_other_arguments, init_func_other_arguments, reduce_func_other_arguments, finalize_func_other_arguments], key_func: key_func, init_func: init_func, reduce_func: reduce_func, finalize_func: finalize_func, output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_group_by_window_dataset(input_dataset: nil, key_func_other_arguments: nil, reduce_func_other_arguments: nil, window_size_func_other_arguments: nil, key_func: nil, reduce_func: nil, window_size_func: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalGroupByWindowDataset", [input_dataset, key_func_other_arguments, reduce_func_other_arguments, window_size_func_other_arguments], key_func: key_func, reduce_func: reduce_func, window_size_func: window_size_func, output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_identity_indexed_dataset(size: nil)
      OpsExecutor.execute("ExperimentalIdentityIndexedDataset", [size])
    end

    def self.experimental_ignore_errors_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalIgnoreErrorsDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_indexed_dataset_get(materialized: nil, index: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalIndexedDatasetGet", [materialized, index], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_indexed_dataset_materialize(dataset: nil, materialized: nil)
      OpsExecutor.execute("ExperimentalIndexedDatasetMaterialize", [dataset, materialized])
    end

    def self.experimental_iterator_get_device(resource: nil)
      OpsExecutor.execute("ExperimentalIteratorGetDevice", [resource])
    end

    def self.experimental_lmdb_dataset(filenames: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalLMDBDataset", [filenames], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_latency_stats_dataset(input_dataset: nil, tag: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalLatencyStatsDataset", [input_dataset, tag], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_map_and_batch_dataset(input_dataset: nil, other_arguments: nil, batch_size: nil, num_parallel_calls: nil, drop_remainder: nil, f: nil, output_types: nil, output_shapes: nil, preserve_cardinality: nil)
      OpsExecutor.execute("ExperimentalMapAndBatchDataset", [input_dataset, other_arguments, batch_size, num_parallel_calls, drop_remainder], f: f, output_types: output_types, output_shapes: output_shapes, preserve_cardinality: preserve_cardinality)
    end

    def self.experimental_map_dataset(input_dataset: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil, preserve_cardinality: nil)
      OpsExecutor.execute("ExperimentalMapDataset", [input_dataset, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism, preserve_cardinality: preserve_cardinality)
    end

    def self.experimental_matching_files_dataset(patterns: nil)
      OpsExecutor.execute("ExperimentalMatchingFilesDataset", [patterns])
    end

    def self.experimental_materialized_index_dataset_handle(container: nil, shared_name: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalMaterializedIndexDatasetHandle", [], container: container, shared_name: shared_name, output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_max_intra_op_parallelism_dataset(input_dataset: nil, max_intra_op_parallelism: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalMaxIntraOpParallelismDataset", [input_dataset, max_intra_op_parallelism], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_non_serializable_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalNonSerializableDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_numa_map_and_batch_dataset(input_dataset: nil, other_arguments: nil, batch_size: nil, num_parallel_calls: nil, drop_remainder: nil, f: nil, output_types: nil, output_shapes: nil, preserve_cardinality: nil)
      OpsExecutor.execute("ExperimentalNumaMapAndBatchDataset", [input_dataset, other_arguments, batch_size, num_parallel_calls, drop_remainder], f: f, output_types: output_types, output_shapes: output_shapes, preserve_cardinality: preserve_cardinality)
    end

    def self.experimental_parallel_interleave_dataset(input_dataset: nil, other_arguments: nil, cycle_length: nil, block_length: nil, sloppy: nil, buffer_output_elements: nil, prefetch_input_elements: nil, f: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalParallelInterleaveDataset", [input_dataset, other_arguments, cycle_length, block_length, sloppy, buffer_output_elements, prefetch_input_elements], f: f, output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_parse_example_dataset(input_dataset: nil, num_parallel_calls: nil, dense_defaults: nil, sparse_keys: nil, dense_keys: nil, sparse_types: nil, dense_shapes: nil, output_types: nil, output_shapes: nil, sloppy: nil)
      OpsExecutor.execute("ExperimentalParseExampleDataset", [input_dataset, num_parallel_calls, dense_defaults], sparse_keys: sparse_keys, dense_keys: dense_keys, sparse_types: sparse_types, dense_shapes: dense_shapes, output_types: output_types, output_shapes: output_shapes, sloppy: sloppy)
    end

    def self.experimental_private_thread_pool_dataset(input_dataset: nil, num_threads: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalPrivateThreadPoolDataset", [input_dataset, num_threads], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_random_dataset(seed: nil, seed2: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalRandomDataset", [seed, seed2], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_rebatch_dataset(input_dataset: nil, num_workers: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalRebatchDataset", [input_dataset, num_workers], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_scan_dataset(input_dataset: nil, initial_state: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, preserve_cardinality: nil)
      OpsExecutor.execute("ExperimentalScanDataset", [input_dataset, initial_state, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, preserve_cardinality: preserve_cardinality)
    end

    def self.experimental_set_stats_aggregator_dataset(input_dataset: nil, stats_aggregator: nil, tag: nil, counter_prefix: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalSetStatsAggregatorDataset", [input_dataset, stats_aggregator, tag, counter_prefix], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_sleep_dataset(input_dataset: nil, sleep_microseconds: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalSleepDataset", [input_dataset, sleep_microseconds], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_sliding_window_dataset(input_dataset: nil, window_size: nil, window_shift: nil, window_stride: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalSlidingWindowDataset", [input_dataset, window_size, window_shift, window_stride], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_sql_dataset(driver_name: nil, data_source_name: nil, query: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalSqlDataset", [driver_name, data_source_name, query], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_stats_aggregator_handle(container: nil, shared_name: nil)
      OpsExecutor.execute("ExperimentalStatsAggregatorHandle", [], container: container, shared_name: shared_name)
    end

    def self.experimental_stats_aggregator_summary(iterator: nil)
      OpsExecutor.execute("ExperimentalStatsAggregatorSummary", [iterator])
    end

    def self.experimental_take_while_dataset(input_dataset: nil, other_arguments: nil, predicate: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalTakeWhileDataset", [input_dataset, other_arguments], predicate: predicate, output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_thread_pool_dataset(input_dataset: nil, thread_pool: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalThreadPoolDataset", [input_dataset, thread_pool], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_thread_pool_handle(num_threads: nil, max_intra_op_parallelism: nil, display_name: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("ExperimentalThreadPoolHandle", [], num_threads: num_threads, max_intra_op_parallelism: max_intra_op_parallelism, display_name: display_name, container: container, shared_name: shared_name)
    end

    def self.experimental_unbatch_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalUnbatchDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
    end

    def self.experimental_unique_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ExperimentalUniqueDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
    end

    def self.expm1(x: nil)
      OpsExecutor.execute("Expm1", [x])
    end

    def self.extract_glimpse(input: nil, size: nil, offsets: nil, centered: nil, normalized: nil, uniform_noise: nil, noise: nil)
      OpsExecutor.execute("ExtractGlimpse", [input, size, offsets], centered: centered, normalized: normalized, uniform_noise: uniform_noise, noise: noise)
    end

    def self.extract_image_patches(images: nil, ksizes: nil, strides: nil, rates: nil, padding: nil)
      OpsExecutor.execute("ExtractImagePatches", [images], ksizes: ksizes, strides: strides, rates: rates, padding: padding)
    end

    def self.extract_jpeg_shape(contents: nil, output_type: nil)
      OpsExecutor.execute("ExtractJpegShape", [contents], output_type: output_type)
    end

    def self.extract_volume_patches(input: nil, ksizes: nil, strides: nil, padding: nil)
      OpsExecutor.execute("ExtractVolumePatches", [input], ksizes: ksizes, strides: strides, padding: padding)
    end

    def self.fft(input: nil)
      OpsExecutor.execute("FFT", [input])
    end

    def self.fft2d(input: nil)
      OpsExecutor.execute("FFT2D", [input])
    end

    def self.fft3d(input: nil)
      OpsExecutor.execute("FFT3D", [input])
    end

    def self.fifo_queue(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("FIFOQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
    end

    def self.fifo_queue_v2(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("FIFOQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
    end

    def self.fact
      OpsExecutor.execute("Fact", [])
    end

    def self.fake_param(dtype: nil, shape: nil)
      OpsExecutor.execute("FakeParam", [], dtype: dtype, shape: shape)
    end

    def self.fake_quant_with_min_max_args(inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
      OpsExecutor.execute("FakeQuantWithMinMaxArgs", [inputs], min: min, max: max, num_bits: num_bits, narrow_range: narrow_range)
    end

    def self.fake_quant_with_min_max_args_gradient(gradients: nil, inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
      OpsExecutor.execute("FakeQuantWithMinMaxArgsGradient", [gradients, inputs], min: min, max: max, num_bits: num_bits, narrow_range: narrow_range)
    end

    def self.fake_quant_with_min_max_vars(inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
      OpsExecutor.execute("FakeQuantWithMinMaxVars", [inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
    end

    def self.fake_quant_with_min_max_vars_gradient(gradients: nil, inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
      OpsExecutor.execute("FakeQuantWithMinMaxVarsGradient", [gradients, inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
    end

    def self.fake_quant_with_min_max_vars_per_channel(inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
      OpsExecutor.execute("FakeQuantWithMinMaxVarsPerChannel", [inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
    end

    def self.fake_quant_with_min_max_vars_per_channel_gradient(gradients: nil, inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
      OpsExecutor.execute("FakeQuantWithMinMaxVarsPerChannelGradient", [gradients, inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
    end

    def self.fake_queue(resource: nil)
      OpsExecutor.execute("FakeQueue", [resource])
    end

    def self.fill(dims: nil, value: nil, index_type: :int64)
      OpsExecutor.execute("Fill", [dims, value], index_type: index_type)
    end

    def self.filter_by_last_component_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("FilterByLastComponentDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
    end

    def self.filter_dataset(input_dataset: nil, other_arguments: nil, predicate: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("FilterDataset", [input_dataset, other_arguments], predicate: predicate, output_types: output_types, output_shapes: output_shapes)
    end

    def self.fingerprint(data: nil, method: nil)
      OpsExecutor.execute("Fingerprint", [data, method])
    end

    def self.fixed_length_record_dataset(filenames: nil, header_bytes: nil, record_bytes: nil, footer_bytes: nil, buffer_size: nil)
      OpsExecutor.execute("FixedLengthRecordDataset", [filenames, header_bytes, record_bytes, footer_bytes, buffer_size])
    end

    def self.fixed_length_record_dataset_v2(filenames: nil, header_bytes: nil, record_bytes: nil, footer_bytes: nil, buffer_size: nil, compression_type: nil)
      OpsExecutor.execute("FixedLengthRecordDatasetV2", [filenames, header_bytes, record_bytes, footer_bytes, buffer_size, compression_type])
    end

    def self.fixed_length_record_reader(header_bytes: nil, record_bytes: nil, footer_bytes: nil, hop_bytes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("FixedLengthRecordReader", [], header_bytes: header_bytes, record_bytes: record_bytes, footer_bytes: footer_bytes, hop_bytes: hop_bytes, container: container, shared_name: shared_name)
    end

    def self.fixed_length_record_reader_v2(header_bytes: nil, record_bytes: nil, footer_bytes: nil, hop_bytes: nil, container: nil, shared_name: nil, encoding: nil)
      OpsExecutor.execute("FixedLengthRecordReaderV2", [], header_bytes: header_bytes, record_bytes: record_bytes, footer_bytes: footer_bytes, hop_bytes: hop_bytes, container: container, shared_name: shared_name, encoding: encoding)
    end

    def self.fixed_unigram_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, vocab_file: nil, distortion: nil, num_reserved_ids: nil, num_shards: nil, shard: nil, unigrams: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("FixedUnigramCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, vocab_file: vocab_file, distortion: distortion, num_reserved_ids: num_reserved_ids, num_shards: num_shards, shard: shard, unigrams: unigrams, seed: seed, seed2: seed2)
    end

    def self.flat_map_dataset(input_dataset: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("FlatMapDataset", [input_dataset, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes)
    end

    def self.floor(x: nil)
      OpsExecutor.execute("Floor", [x])
    end

    def self.floor_div(x: nil, y: nil)
      OpsExecutor.execute("FloorDiv", [x, y])
    end

    def self.floor_mod(x: nil, y: nil)
      OpsExecutor.execute("FloorMod", [x, y])
    end

    def self.flush_summary_writer(writer: nil)
      OpsExecutor.execute("FlushSummaryWriter", [writer])
    end

    def self.for(start: nil, limit: nil, delta: nil, input: nil, body: nil)
      OpsExecutor.execute("For", [start, limit, delta, input], body: body)
    end

    def self.fractional_avg_pool(value: nil, pooling_ratio: nil, pseudo_random: nil, overlapping: nil, deterministic: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("FractionalAvgPool", [value], pooling_ratio: pooling_ratio, pseudo_random: pseudo_random, overlapping: overlapping, deterministic: deterministic, seed: seed, seed2: seed2)
    end

    def self.fractional_avg_pool_grad(orig_input_tensor_shape: nil, out_backprop: nil, row_pooling_sequence: nil, col_pooling_sequence: nil, overlapping: nil)
      OpsExecutor.execute("FractionalAvgPoolGrad", [orig_input_tensor_shape, out_backprop, row_pooling_sequence, col_pooling_sequence], overlapping: overlapping)
    end

    def self.fractional_max_pool(value: nil, pooling_ratio: nil, pseudo_random: nil, overlapping: nil, deterministic: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("FractionalMaxPool", [value], pooling_ratio: pooling_ratio, pseudo_random: pseudo_random, overlapping: overlapping, deterministic: deterministic, seed: seed, seed2: seed2)
    end

    def self.fractional_max_pool_grad(orig_input: nil, orig_output: nil, out_backprop: nil, row_pooling_sequence: nil, col_pooling_sequence: nil, overlapping: nil)
      OpsExecutor.execute("FractionalMaxPoolGrad", [orig_input, orig_output, out_backprop, row_pooling_sequence, col_pooling_sequence], overlapping: overlapping)
    end

    def self.fused_batch_norm(x: nil, scale: nil, offset: nil, mean: nil, variance: nil, epsilon: nil, data_format: nil, is_training: nil)
      OpsExecutor.execute("FusedBatchNorm", [x, scale, offset, mean, variance], epsilon: epsilon, data_format: data_format, is_training: is_training)
    end

    def self.fused_batch_norm_grad(y_backprop: nil, x: nil, scale: nil, reserve_space_1: nil, reserve_space_2: nil, epsilon: nil, data_format: nil, is_training: nil)
      OpsExecutor.execute("FusedBatchNormGrad", [y_backprop, x, scale, reserve_space_1, reserve_space_2], epsilon: epsilon, data_format: data_format, is_training: is_training)
    end

    def self.fused_batch_norm_grad_v2(y_backprop: nil, x: nil, scale: nil, reserve_space_1: nil, reserve_space_2: nil, epsilon: nil, data_format: nil, is_training: nil)
      OpsExecutor.execute("FusedBatchNormGradV2", [y_backprop, x, scale, reserve_space_1, reserve_space_2], epsilon: epsilon, data_format: data_format, is_training: is_training)
    end

    def self.fused_batch_norm_grad_v3(y_backprop: nil, x: nil, scale: nil, reserve_space_1: nil, reserve_space_2: nil, reserve_space_3: nil, epsilon: nil, data_format: nil, is_training: nil)
      OpsExecutor.execute("FusedBatchNormGradV3", [y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3], epsilon: epsilon, data_format: data_format, is_training: is_training)
    end

    def self.fused_batch_norm_v2(x: nil, scale: nil, offset: nil, mean: nil, variance: nil, epsilon: nil, data_format: nil, is_training: nil)
      OpsExecutor.execute("FusedBatchNormV2", [x, scale, offset, mean, variance], epsilon: epsilon, data_format: data_format, is_training: is_training)
    end

    def self.fused_batch_norm_v3(x: nil, scale: nil, offset: nil, mean: nil, variance: nil, epsilon: nil, data_format: nil, is_training: nil)
      OpsExecutor.execute("FusedBatchNormV3", [x, scale, offset, mean, variance], epsilon: epsilon, data_format: data_format, is_training: is_training)
    end

    def self.fused_pad_conv2d(input: nil, paddings: nil, filter: nil, mode: nil, strides: nil, padding: nil)
      OpsExecutor.execute("FusedPadConv2D", [input, paddings, filter], mode: mode, strides: strides, padding: padding)
    end

    def self.fused_resize_and_pad_conv2d(input: nil, size: nil, paddings: nil, filter: nil, resize_align_corners: nil, mode: nil, strides: nil, padding: nil)
      OpsExecutor.execute("FusedResizeAndPadConv2D", [input, size, paddings, filter], resize_align_corners: resize_align_corners, mode: mode, strides: strides, padding: padding)
    end

    def self.gather(params: nil, indices: nil, validate_indices: nil)
      OpsExecutor.execute("Gather", [params, indices], validate_indices: validate_indices)
    end

    def self.gather_nd(params: nil, indices: nil)
      OpsExecutor.execute("GatherNd", [params, indices])
    end

    def self.gather_v2(params: nil, indices: nil, axis: nil, batch_dims: nil)
      OpsExecutor.execute("GatherV2", [params, indices, axis], batch_dims: batch_dims)
    end

    def self.gcs_configure_block_cache(max_cache_size: nil, block_size: nil, max_staleness: nil)
      OpsExecutor.execute("GcsConfigureBlockCache", [max_cache_size, block_size, max_staleness])
    end

    def self.gcs_configure_credentials(json: nil)
      OpsExecutor.execute("GcsConfigureCredentials", [json])
    end

    def self.generate_big_query_reader_partitions(project_id: nil, dataset_id: nil, table_id: nil, columns: nil, timestamp_millis: nil, num_partitions: nil, test_end_point: nil)
      OpsExecutor.execute("GenerateBigQueryReaderPartitions", [], project_id: project_id, dataset_id: dataset_id, table_id: table_id, columns: columns, timestamp_millis: timestamp_millis, num_partitions: num_partitions, test_end_point: test_end_point)
    end

    def self.generate_vocab_remapping(new_vocab_file: nil, old_vocab_file: nil, new_vocab_offset: nil, num_new_vocab: nil, old_vocab_size: nil)
      OpsExecutor.execute("GenerateVocabRemapping", [new_vocab_file, old_vocab_file], new_vocab_offset: new_vocab_offset, num_new_vocab: num_new_vocab, old_vocab_size: old_vocab_size)
    end

    def self.generator_dataset(init_func_other_args: nil, next_func_other_args: nil, finalize_func_other_args: nil, init_func: nil, next_func: nil, finalize_func: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("GeneratorDataset", [init_func_other_args, next_func_other_args, finalize_func_other_args], init_func: init_func, next_func: next_func, finalize_func: finalize_func, output_types: output_types, output_shapes: output_shapes)
    end

    def self.get_session_handle(value: nil)
      OpsExecutor.execute("GetSessionHandle", [value])
    end

    def self.get_session_handle_v2(value: nil)
      OpsExecutor.execute("GetSessionHandleV2", [value])
    end

    def self.get_session_tensor(handle: nil, dtype: nil)
      OpsExecutor.execute("GetSessionTensor", [handle], dtype: dtype)
    end

    def self.greater(x: nil, y: nil)
      OpsExecutor.execute("Greater", [x, y])
    end

    def self.greater_equal(x: nil, y: nil)
      OpsExecutor.execute("GreaterEqual", [x, y])
    end

    def self.guarantee_const(input: nil)
      OpsExecutor.execute("GuaranteeConst", [input])
    end

    def self.hsv_to_rgb(images: nil)
      OpsExecutor.execute("HSVToRGB", [images])
    end

    def self.hash_table(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
      OpsExecutor.execute("HashTable", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
    end

    def self.hash_table_v2(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
      OpsExecutor.execute("HashTableV2", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
    end

    def self.histogram_fixed_width(values: nil, value_range: nil, nbins: nil, dtype: nil)
      OpsExecutor.execute("HistogramFixedWidth", [values, value_range, nbins], dtype: dtype)
    end

    def self.histogram_summary(tag: nil, values: nil)
      OpsExecutor.execute("HistogramSummary", [tag, values])
    end

    def self.host_const(value: nil, dtype: nil)
      OpsExecutor.execute("HostConst", [], value: value, dtype: dtype)
    end

    def self.ifft(input: nil)
      OpsExecutor.execute("IFFT", [input])
    end

    def self.ifft2d(input: nil)
      OpsExecutor.execute("IFFT2D", [input])
    end

    def self.ifft3d(input: nil)
      OpsExecutor.execute("IFFT3D", [input])
    end

    def self.irfft(input: nil, fft_length: nil)
      OpsExecutor.execute("IRFFT", [input, fft_length])
    end

    def self.irfft2d(input: nil, fft_length: nil)
      OpsExecutor.execute("IRFFT2D", [input, fft_length])
    end

    def self.irfft3d(input: nil, fft_length: nil)
      OpsExecutor.execute("IRFFT3D", [input, fft_length])
    end

    def self.identity(input: nil)
      OpsExecutor.execute("Identity", [input])
    end

    def self.identity_n(input: nil)
      OpsExecutor.execute("IdentityN", [input])
    end

    def self.identity_reader(container: nil, shared_name: nil)
      OpsExecutor.execute("IdentityReader", [], container: container, shared_name: shared_name)
    end

    def self.identity_reader_v2(container: nil, shared_name: nil)
      OpsExecutor.execute("IdentityReaderV2", [], container: container, shared_name: shared_name)
    end

    def self.if(cond: nil, input: nil, then_branch: nil, else_branch: nil, output_shapes: nil)
      OpsExecutor.execute("If", [cond, input], then_branch: then_branch, else_branch: else_branch, output_shapes: output_shapes)
    end

    def self.igamma(a: nil, x: nil)
      OpsExecutor.execute("Igamma", [a, x])
    end

    def self.igamma_grad_a(a: nil, x: nil)
      OpsExecutor.execute("IgammaGradA", [a, x])
    end

    def self.igammac(a: nil, x: nil)
      OpsExecutor.execute("Igammac", [a, x])
    end

    def self.imag(input: nil)
      OpsExecutor.execute("Imag", [input])
    end

    def self.image_summary(tag: nil, tensor: nil, max_images: nil, bad_color: nil)
      OpsExecutor.execute("ImageSummary", [tag, tensor], max_images: max_images, bad_color: bad_color)
    end

    def self.immutable_const(dtype: nil, shape: nil, memory_region_name: nil)
      OpsExecutor.execute("ImmutableConst", [], dtype: dtype, shape: shape, memory_region_name: memory_region_name)
    end

    def self.import_event(writer: nil, event: nil)
      OpsExecutor.execute("ImportEvent", [writer, event])
    end

    def self.in_top_k(predictions: nil, targets: nil, k: nil)
      OpsExecutor.execute("InTopK", [predictions, targets], k: k)
    end

    def self.in_top_kv2(predictions: nil, targets: nil, k: nil)
      OpsExecutor.execute("InTopKV2", [predictions, targets, k])
    end

    def self.infeed_dequeue(dtype: nil, shape: nil)
      OpsExecutor.execute("InfeedDequeue", [], dtype: dtype, shape: shape)
    end

    def self.infeed_dequeue_tuple(dtypes: nil, shapes: nil)
      OpsExecutor.execute("InfeedDequeueTuple", [], dtypes: dtypes, shapes: shapes)
    end

    def self.infeed_enqueue(input: nil, dtype: nil, shape: nil, layout: nil, device_ordinal: nil)
      OpsExecutor.execute("InfeedEnqueue", [input], dtype: dtype, shape: shape, layout: layout, device_ordinal: device_ordinal)
    end

    def self.infeed_enqueue_prelinearized_buffer(input: nil, device_ordinal: nil)
      OpsExecutor.execute("InfeedEnqueuePrelinearizedBuffer", [input], device_ordinal: device_ordinal)
    end

    def self.infeed_enqueue_tuple(inputs: nil, dtypes: nil, shapes: nil, layouts: nil, device_ordinal: nil)
      OpsExecutor.execute("InfeedEnqueueTuple", [inputs], dtypes: dtypes, shapes: shapes, layouts: layouts, device_ordinal: device_ordinal)
    end

    def self.initialize_table(table_handle: nil, keys: nil, values: nil)
      OpsExecutor.execute("InitializeTable", [table_handle, keys, values])
    end

    def self.initialize_table_from_text_file(table_handle: nil, filename: nil, key_index: nil, value_index: nil, vocab_size: nil, delimiter: nil)
      OpsExecutor.execute("InitializeTableFromTextFile", [table_handle, filename], key_index: key_index, value_index: value_index, vocab_size: vocab_size, delimiter: delimiter)
    end

    def self.initialize_table_from_text_file_v2(table_handle: nil, filename: nil, key_index: nil, value_index: nil, vocab_size: nil, delimiter: nil)
      OpsExecutor.execute("InitializeTableFromTextFileV2", [table_handle, filename], key_index: key_index, value_index: value_index, vocab_size: vocab_size, delimiter: delimiter)
    end

    def self.initialize_table_v2(table_handle: nil, keys: nil, values: nil)
      OpsExecutor.execute("InitializeTableV2", [table_handle, keys, values])
    end

    def self.inplace_add(x: nil, i: nil, v: nil)
      OpsExecutor.execute("InplaceAdd", [x, i, v])
    end

    def self.inplace_sub(x: nil, i: nil, v: nil)
      OpsExecutor.execute("InplaceSub", [x, i, v])
    end

    def self.inplace_update(x: nil, i: nil, v: nil)
      OpsExecutor.execute("InplaceUpdate", [x, i, v])
    end

    def self.interleave_dataset(input_dataset: nil, other_arguments: nil, cycle_length: nil, block_length: nil, f: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("InterleaveDataset", [input_dataset, other_arguments, cycle_length, block_length], f: f, output_types: output_types, output_shapes: output_shapes)
    end

    def self.inv(x: nil)
      OpsExecutor.execute("Inv", [x])
    end

    def self.inv_grad(y: nil, dy: nil)
      OpsExecutor.execute("InvGrad", [y, dy])
    end

    def self.invert(x: nil)
      OpsExecutor.execute("Invert", [x])
    end

    def self.invert_permutation(x: nil)
      OpsExecutor.execute("InvertPermutation", [x])
    end

    def self.is_boosted_trees_ensemble_initialized(tree_ensemble_handle: nil)
      OpsExecutor.execute("IsBoostedTreesEnsembleInitialized", [tree_ensemble_handle])
    end

    def self.is_boosted_trees_quantile_stream_resource_initialized(quantile_stream_resource_handle: nil)
      OpsExecutor.execute("IsBoostedTreesQuantileStreamResourceInitialized", [quantile_stream_resource_handle])
    end

    def self.is_finite(x: nil)
      OpsExecutor.execute("IsFinite", [x])
    end

    def self.is_inf(x: nil)
      OpsExecutor.execute("IsInf", [x])
    end

    def self.is_nan(x: nil)
      OpsExecutor.execute("IsNan", [x])
    end

    def self.is_variable_initialized(ref: nil, dtype: nil)
      OpsExecutor.execute("IsVariableInitialized", [ref], dtype: dtype)
    end

    def self.iterator(shared_name: nil, container: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("Iterator", [], shared_name: shared_name, container: container, output_types: output_types, output_shapes: output_shapes)
    end

    def self.iterator_from_string_handle(string_handle: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("IteratorFromStringHandle", [string_handle], output_types: output_types, output_shapes: output_shapes)
    end

    def self.iterator_from_string_handle_v2(string_handle: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("IteratorFromStringHandleV2", [string_handle], output_types: output_types, output_shapes: output_shapes)
    end

    def self.iterator_get_next(iterator: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("IteratorGetNext", [iterator], output_types: output_types, output_shapes: output_shapes)
    end

    def self.iterator_get_next_as_optional(iterator: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("IteratorGetNextAsOptional", [iterator], output_types: output_types, output_shapes: output_shapes)
    end

    def self.iterator_get_next_sync(iterator: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("IteratorGetNextSync", [iterator], output_types: output_types, output_shapes: output_shapes)
    end

    def self.iterator_to_string_handle(resource_handle: nil)
      OpsExecutor.execute("IteratorToStringHandle", [resource_handle])
    end

    def self.iterator_v2(shared_name: nil, container: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("IteratorV2", [], shared_name: shared_name, container: container, output_types: output_types, output_shapes: output_shapes)
    end

    def self.kmc2_chain_initialization(distances: nil, seed: nil)
      OpsExecutor.execute("KMC2ChainInitialization", [distances, seed])
    end

    def self.kmeans_plus_plus_initialization(points: nil, num_to_sample: nil, seed: nil, num_retries_per_sample: nil)
      OpsExecutor.execute("KmeansPlusPlusInitialization", [points, num_to_sample, seed, num_retries_per_sample])
    end

    def self.l2_loss(t: nil)
      OpsExecutor.execute("L2Loss", [t])
    end

    def self.lmdb_reader(container: nil, shared_name: nil)
      OpsExecutor.execute("LMDBReader", [], container: container, shared_name: shared_name)
    end

    def self.lrn(input: nil, depth_radius: nil, bias: nil, alpha: nil, beta: nil)
      OpsExecutor.execute("LRN", [input], depth_radius: depth_radius, bias: bias, alpha: alpha, beta: beta)
    end

    def self.lrn_grad(input_grads: nil, input_image: nil, output_image: nil, depth_radius: nil, bias: nil, alpha: nil, beta: nil)
      OpsExecutor.execute("LRNGrad", [input_grads, input_image, output_image], depth_radius: depth_radius, bias: bias, alpha: alpha, beta: beta)
    end

    def self.leaky_relu(features: nil, alpha: nil)
      OpsExecutor.execute("LeakyRelu", [features], alpha: alpha)
    end

    def self.leaky_relu_grad(gradients: nil, features: nil, alpha: nil)
      OpsExecutor.execute("LeakyReluGrad", [gradients, features], alpha: alpha)
    end

    def self.learned_unigram_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("LearnedUnigramCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
    end

    def self.left_shift(x: nil, y: nil)
      OpsExecutor.execute("LeftShift", [x, y])
    end

    def self.less(x: nil, y: nil)
      OpsExecutor.execute("Less", [x, y])
    end

    def self.less_equal(x: nil, y: nil)
      OpsExecutor.execute("LessEqual", [x, y])
    end

    def self.lgamma(x: nil)
      OpsExecutor.execute("Lgamma", [x])
    end

    def self.lin_space(start: nil, stop: nil, num: nil)
      OpsExecutor.execute("LinSpace", [start, stop, num])
    end

    def self.list_diff(x: nil, y: nil, out_idx: nil)
      OpsExecutor.execute("ListDiff", [x, y], out_idx: out_idx)
    end

    def self.load_and_remap_matrix(ckpt_path: nil, old_tensor_name: nil, row_remapping: nil, col_remapping: nil, initializing_values: nil, num_rows: nil, num_cols: nil, max_rows_in_memory: nil)
      OpsExecutor.execute("LoadAndRemapMatrix", [ckpt_path, old_tensor_name, row_remapping, col_remapping, initializing_values], num_rows: num_rows, num_cols: num_cols, max_rows_in_memory: max_rows_in_memory)
    end

    def self.load_tpu_embedding_adam_parameters(parameters: nil, momenta: nil, velocities: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingADAMParameters", [parameters, momenta, velocities], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_adam_parameters_grad_accum_debug(parameters: nil, momenta: nil, velocities: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingADAMParametersGradAccumDebug", [parameters, momenta, velocities, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_adadelta_parameters(parameters: nil, accumulators: nil, updates: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingAdadeltaParameters", [parameters, accumulators, updates], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_adadelta_parameters_grad_accum_debug(parameters: nil, accumulators: nil, updates: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingAdadeltaParametersGradAccumDebug", [parameters, accumulators, updates, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_adagrad_parameters(parameters: nil, accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingAdagradParameters", [parameters, accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_adagrad_parameters_grad_accum_debug(parameters: nil, accumulators: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingAdagradParametersGradAccumDebug", [parameters, accumulators, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_centered_rms_prop_parameters(parameters: nil, ms: nil, mom: nil, mg: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingCenteredRMSPropParameters", [parameters, ms, mom, mg], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_ftrl_parameters(parameters: nil, accumulators: nil, linears: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingFTRLParameters", [parameters, accumulators, linears], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_ftrl_parameters_grad_accum_debug(parameters: nil, accumulators: nil, linears: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingFTRLParametersGradAccumDebug", [parameters, accumulators, linears, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_mdl_adagrad_light_parameters(parameters: nil, accumulators: nil, weights: nil, benefits: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingMDLAdagradLightParameters", [parameters, accumulators, weights, benefits], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_momentum_parameters(parameters: nil, momenta: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingMomentumParameters", [parameters, momenta], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_momentum_parameters_grad_accum_debug(parameters: nil, momenta: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingMomentumParametersGradAccumDebug", [parameters, momenta, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_proximal_adagrad_parameters(parameters: nil, accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingProximalAdagradParameters", [parameters, accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(parameters: nil, accumulators: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug", [parameters, accumulators, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_rms_prop_parameters(parameters: nil, ms: nil, mom: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingRMSPropParameters", [parameters, ms, mom], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_rms_prop_parameters_grad_accum_debug(parameters: nil, ms: nil, mom: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingRMSPropParametersGradAccumDebug", [parameters, ms, mom, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.load_tpu_embedding_stochastic_gradient_descent_parameters(parameters: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("LoadTPUEmbeddingStochasticGradientDescentParameters", [parameters], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.log(x: nil)
      OpsExecutor.execute("Log", [x])
    end

    def self.log1p(x: nil)
      OpsExecutor.execute("Log1p", [x])
    end

    def self.log_matrix_determinant(input: nil)
      OpsExecutor.execute("LogMatrixDeterminant", [input])
    end

    def self.log_softmax(logits: nil)
      OpsExecutor.execute("LogSoftmax", [logits])
    end

    def self.log_uniform_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("LogUniformCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
    end

    def self.logical_and(x: nil, y: nil)
      OpsExecutor.execute("LogicalAnd", [x, y])
    end

    def self.logical_not(x: nil)
      OpsExecutor.execute("LogicalNot", [x])
    end

    def self.logical_or(x: nil, y: nil)
      OpsExecutor.execute("LogicalOr", [x, y])
    end

    def self.lookup_table_export(table_handle: nil)
      OpsExecutor.execute("LookupTableExport", [table_handle])
    end

    def self.lookup_table_export_v2(table_handle: nil)
      OpsExecutor.execute("LookupTableExportV2", [table_handle])
    end

    def self.lookup_table_find(table_handle: nil, keys: nil, default_value: nil)
      OpsExecutor.execute("LookupTableFind", [table_handle, keys, default_value])
    end

    def self.lookup_table_find_v2(table_handle: nil, keys: nil, default_value: nil)
      OpsExecutor.execute("LookupTableFindV2", [table_handle, keys, default_value])
    end

    def self.lookup_table_import(table_handle: nil, keys: nil, values: nil)
      OpsExecutor.execute("LookupTableImport", [table_handle, keys, values])
    end

    def self.lookup_table_import_v2(table_handle: nil, keys: nil, values: nil)
      OpsExecutor.execute("LookupTableImportV2", [table_handle, keys, values])
    end

    def self.lookup_table_insert(table_handle: nil, keys: nil, values: nil)
      OpsExecutor.execute("LookupTableInsert", [table_handle, keys, values])
    end

    def self.lookup_table_insert_v2(table_handle: nil, keys: nil, values: nil)
      OpsExecutor.execute("LookupTableInsertV2", [table_handle, keys, values])
    end

    def self.lookup_table_remove_v2(table_handle: nil, keys: nil)
      OpsExecutor.execute("LookupTableRemoveV2", [table_handle, keys])
    end

    def self.lookup_table_size(table_handle: nil)
      OpsExecutor.execute("LookupTableSize", [table_handle])
    end

    def self.lookup_table_size_v2(table_handle: nil)
      OpsExecutor.execute("LookupTableSizeV2", [table_handle])
    end

    def self.loop_cond(input: nil)
      OpsExecutor.execute("LoopCond", [input])
    end

    def self.lower_bound(sorted_inputs: nil, values: nil, out_type: nil)
      OpsExecutor.execute("LowerBound", [sorted_inputs, values], out_type: out_type)
    end

    def self.lu(input: nil, output_idx_type: nil)
      OpsExecutor.execute("Lu", [input], output_idx_type: output_idx_type)
    end

    def self.make_iterator(dataset: nil, iterator: nil)
      OpsExecutor.execute("MakeIterator", [dataset, iterator])
    end

    def self.map_clear(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("MapClear", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.map_dataset(input_dataset: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil, preserve_cardinality: nil)
      OpsExecutor.execute("MapDataset", [input_dataset, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism, preserve_cardinality: preserve_cardinality)
    end

    def self.map_defun(arguments: nil, captured_inputs: nil, output_types: nil, output_shapes: nil, f: nil, max_intra_op_parallelism: nil)
      OpsExecutor.execute("MapDefun", [arguments, captured_inputs], output_types: output_types, output_shapes: output_shapes, f: f, max_intra_op_parallelism: max_intra_op_parallelism)
    end

    def self.map_incomplete_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("MapIncompleteSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.map_peek(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("MapPeek", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.map_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("MapSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.map_stage(key: nil, indices: nil, values: nil, capacity: nil, memory_limit: nil, dtypes: nil, fake_dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("MapStage", [key, indices, values], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, fake_dtypes: fake_dtypes, container: container, shared_name: shared_name)
    end

    def self.map_unstage(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("MapUnstage", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.map_unstage_no_key(indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("MapUnstageNoKey", [indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.mat_mul(a: nil, b: nil, transpose_a: nil, transpose_b: nil)
      OpsExecutor.execute("MatMul", [a, b], transpose_a: transpose_a, transpose_b: transpose_b)
    end

    def self.matching_files(pattern: nil)
      OpsExecutor.execute("MatchingFiles", [pattern])
    end

    def self.matrix_band_part(input: nil, num_lower: nil, num_upper: nil)
      OpsExecutor.execute("MatrixBandPart", [input, num_lower, num_upper])
    end

    def self.matrix_determinant(input: nil)
      OpsExecutor.execute("MatrixDeterminant", [input])
    end

    def self.matrix_diag(diagonal: nil)
      OpsExecutor.execute("MatrixDiag", [diagonal])
    end

    def self.matrix_diag_part(input: nil)
      OpsExecutor.execute("MatrixDiagPart", [input])
    end

    def self.matrix_exponential(input: nil)
      OpsExecutor.execute("MatrixExponential", [input])
    end

    def self.matrix_inverse(input: nil, adjoint: nil)
      OpsExecutor.execute("MatrixInverse", [input], adjoint: adjoint)
    end

    def self.matrix_logarithm(input: nil)
      OpsExecutor.execute("MatrixLogarithm", [input])
    end

    def self.matrix_set_diag(input: nil, diagonal: nil)
      OpsExecutor.execute("MatrixSetDiag", [input, diagonal])
    end

    def self.matrix_solve(matrix: nil, rhs: nil, adjoint: nil)
      OpsExecutor.execute("MatrixSolve", [matrix, rhs], adjoint: adjoint)
    end

    def self.matrix_solve_ls(matrix: nil, rhs: nil, l2_regularizer: nil, fast: nil)
      OpsExecutor.execute("MatrixSolveLs", [matrix, rhs, l2_regularizer], fast: fast)
    end

    def self.matrix_square_root(input: nil)
      OpsExecutor.execute("MatrixSquareRoot", [input])
    end

    def self.matrix_triangular_solve(matrix: nil, rhs: nil, lower: nil, adjoint: nil)
      OpsExecutor.execute("MatrixTriangularSolve", [matrix, rhs], lower: lower, adjoint: adjoint)
    end

    def self.max(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("Max", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.max_pool(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPool", [input], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.max_pool3d(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPool3D", [input], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.max_pool3d_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPool3DGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.max_pool3d_grad_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPool3DGradGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.max_pool_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPoolGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.max_pool_grad_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPoolGradGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
    end

    def self.max_pool_grad_grad_v2(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPoolGradGradV2", [orig_input, orig_output, grad, ksize, strides], padding: padding, data_format: data_format)
    end

    def self.max_pool_grad_grad_with_argmax(input: nil, grad: nil, argmax: nil, ksize: nil, strides: nil, padding: nil, include_batch_in_index: nil)
      OpsExecutor.execute("MaxPoolGradGradWithArgmax", [input, grad, argmax], ksize: ksize, strides: strides, padding: padding, include_batch_in_index: include_batch_in_index)
    end

    def self.max_pool_grad_v2(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPoolGradV2", [orig_input, orig_output, grad, ksize, strides], padding: padding, data_format: data_format)
    end

    def self.max_pool_grad_with_argmax(input: nil, grad: nil, argmax: nil, ksize: nil, strides: nil, padding: nil, include_batch_in_index: nil)
      OpsExecutor.execute("MaxPoolGradWithArgmax", [input, grad, argmax], ksize: ksize, strides: strides, padding: padding, include_batch_in_index: include_batch_in_index)
    end

    def self.max_pool_v2(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
      OpsExecutor.execute("MaxPoolV2", [input, ksize, strides], padding: padding, data_format: data_format)
    end

    def self.max_pool_with_argmax(input: nil, ksize: nil, strides: nil, padding: nil, include_batch_in_index: nil)
      OpsExecutor.execute("MaxPoolWithArgmax", [input], ksize: ksize, strides: strides, padding: padding, include_batch_in_index: include_batch_in_index)
    end

    def self.maximum(x: nil, y: nil)
      OpsExecutor.execute("Maximum", [x, y])
    end

    def self.mean(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("Mean", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.merge(inputs: nil)
      OpsExecutor.execute("Merge", [inputs])
    end

    def self.merge_summary(inputs: nil)
      OpsExecutor.execute("MergeSummary", [inputs])
    end

    def self.merge_v2_checkpoints(checkpoint_prefixes: nil, destination_prefix: nil, delete_old_dirs: nil)
      OpsExecutor.execute("MergeV2Checkpoints", [checkpoint_prefixes, destination_prefix], delete_old_dirs: delete_old_dirs)
    end

    def self.mfcc(spectrogram: nil, sample_rate: nil, upper_frequency_limit: nil, lower_frequency_limit: nil, filterbank_channel_count: nil, dct_coefficient_count: nil)
      OpsExecutor.execute("Mfcc", [spectrogram, sample_rate], upper_frequency_limit: upper_frequency_limit, lower_frequency_limit: lower_frequency_limit, filterbank_channel_count: filterbank_channel_count, dct_coefficient_count: dct_coefficient_count)
    end

    def self.min(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("Min", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.minimum(x: nil, y: nil)
      OpsExecutor.execute("Minimum", [x, y])
    end

    def self.mirror_pad(input: nil, paddings: nil, mode: nil)
      OpsExecutor.execute("MirrorPad", [input, paddings], mode: mode)
    end

    def self.mirror_pad_grad(input: nil, paddings: nil, mode: nil)
      OpsExecutor.execute("MirrorPadGrad", [input, paddings], mode: mode)
    end

    def self.mod(x: nil, y: nil)
      OpsExecutor.execute("Mod", [x, y])
    end

    def self.model_dataset(input_dataset: nil, cpu_budget: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ModelDataset", [input_dataset], cpu_budget: cpu_budget, output_types: output_types, output_shapes: output_shapes)
    end

    def self.mul(x: nil, y: nil)
      OpsExecutor.execute("Mul", [x, y])
    end

    def self.mul_no_nan(x: nil, y: nil)
      OpsExecutor.execute("MulNoNan", [x, y])
    end

    def self.multi_device_iterator(devices: nil, shared_name: nil, container: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("MultiDeviceIterator", [], devices: devices, shared_name: shared_name, container: container, output_types: output_types, output_shapes: output_shapes)
    end

    def self.multi_device_iterator_from_string_handle(string_handle: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("MultiDeviceIteratorFromStringHandle", [string_handle], output_types: output_types, output_shapes: output_shapes)
    end

    def self.multi_device_iterator_get_next_from_shard(multi_device_iterator: nil, shard_num: nil, incarnation_id: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("MultiDeviceIteratorGetNextFromShard", [multi_device_iterator, shard_num, incarnation_id], output_types: output_types, output_shapes: output_shapes)
    end

    def self.multi_device_iterator_init(dataset: nil, multi_device_iterator: nil, max_buffer_size: nil)
      OpsExecutor.execute("MultiDeviceIteratorInit", [dataset, multi_device_iterator, max_buffer_size])
    end

    def self.multi_device_iterator_to_string_handle(multi_device_iterator: nil)
      OpsExecutor.execute("MultiDeviceIteratorToStringHandle", [multi_device_iterator])
    end

    def self.multinomial(logits: nil, num_samples: nil, seed: nil, seed2: nil, output_dtype: nil)
      OpsExecutor.execute("Multinomial", [logits, num_samples], seed: seed, seed2: seed2, output_dtype: output_dtype)
    end

    def self.mutable_dense_hash_table(empty_key: nil, container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil, initial_num_buckets: nil, max_load_factor: nil)
      OpsExecutor.execute("MutableDenseHashTable", [empty_key], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape, initial_num_buckets: initial_num_buckets, max_load_factor: max_load_factor)
    end

    def self.mutable_dense_hash_table_v2(empty_key: nil, deleted_key: nil, container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil, initial_num_buckets: nil, max_load_factor: nil)
      OpsExecutor.execute("MutableDenseHashTableV2", [empty_key, deleted_key], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape, initial_num_buckets: initial_num_buckets, max_load_factor: max_load_factor)
    end

    def self.mutable_hash_table(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
      OpsExecutor.execute("MutableHashTable", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
    end

    def self.mutable_hash_table_of_tensors(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil)
      OpsExecutor.execute("MutableHashTableOfTensors", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape)
    end

    def self.mutable_hash_table_of_tensors_v2(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil)
      OpsExecutor.execute("MutableHashTableOfTensorsV2", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape)
    end

    def self.mutable_hash_table_v2(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
      OpsExecutor.execute("MutableHashTableV2", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
    end

    def self.mutex_lock(mutex: nil)
      OpsExecutor.execute("MutexLock", [mutex])
    end

    def self.mutex_v2(container: nil, shared_name: nil)
      OpsExecutor.execute("MutexV2", [], container: container, shared_name: shared_name)
    end

    def self.nccl_all_reduce(input: nil, reduction: nil, num_devices: nil, shared_name: nil)
      OpsExecutor.execute("NcclAllReduce", [input], reduction: reduction, num_devices: num_devices, shared_name: shared_name)
    end

    def self.nccl_broadcast(input: nil, shape: nil)
      OpsExecutor.execute("NcclBroadcast", [input], shape: shape)
    end

    def self.nccl_reduce(input: nil, reduction: nil, num_devices: nil)
      OpsExecutor.execute("NcclReduce", [input], reduction: reduction, num_devices: num_devices)
    end

    def self.nearest_neighbors(points: nil, centers: nil, k: nil)
      OpsExecutor.execute("NearestNeighbors", [points, centers, k])
    end

    def self.neg(x: nil)
      OpsExecutor.execute("Neg", [x])
    end

    def self.neg_train(w_in: nil, w_out: nil, examples: nil, labels: nil, lr: nil, vocab_count: nil, num_negative_samples: nil)
      OpsExecutor.execute("NegTrain", [w_in, w_out, examples, labels, lr], vocab_count: vocab_count, num_negative_samples: num_negative_samples)
    end

    def self.next_after(x1: nil, x2: nil)
      OpsExecutor.execute("NextAfter", [x1, x2])
    end

    def self.next_iteration(data: nil)
      OpsExecutor.execute("NextIteration", [data])
    end

    def self.no_op
      OpsExecutor.execute("NoOp", [])
    end

    def self.non_deterministic_ints(shape: nil, dtype: nil, shape_dtype: nil)
      OpsExecutor.execute("NonDeterministicInts", [shape], dtype: dtype, shape_dtype: shape_dtype)
    end

    def self.non_max_suppression(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil)
      OpsExecutor.execute("NonMaxSuppression", [boxes, scores, max_output_size], iou_threshold: iou_threshold)
    end

    def self.non_max_suppression_v2(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil)
      OpsExecutor.execute("NonMaxSuppressionV2", [boxes, scores, max_output_size, iou_threshold])
    end

    def self.non_max_suppression_v3(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil, score_threshold: nil)
      OpsExecutor.execute("NonMaxSuppressionV3", [boxes, scores, max_output_size, iou_threshold, score_threshold])
    end

    def self.non_max_suppression_v4(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil, score_threshold: nil, pad_to_max_output_size: nil)
      OpsExecutor.execute("NonMaxSuppressionV4", [boxes, scores, max_output_size, iou_threshold, score_threshold], pad_to_max_output_size: pad_to_max_output_size)
    end

    def self.non_max_suppression_with_overlaps(overlaps: nil, scores: nil, max_output_size: nil, overlap_threshold: nil, score_threshold: nil)
      OpsExecutor.execute("NonMaxSuppressionWithOverlaps", [overlaps, scores, max_output_size, overlap_threshold, score_threshold])
    end

    def self.not_equal(x: nil, y: nil)
      OpsExecutor.execute("NotEqual", [x, y])
    end

    def self.nth_element(input: nil, n: nil, reverse: nil)
      OpsExecutor.execute("NthElement", [input, n], reverse: reverse)
    end

    def self.one_hot(indices: nil, depth: nil, on_value: nil, off_value: nil, axis: nil)
      OpsExecutor.execute("OneHot", [indices, depth, on_value, off_value], axis: axis)
    end

    def self.one_shot_iterator(dataset_factory: nil, output_types: nil, output_shapes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OneShotIterator", [], dataset_factory: dataset_factory, output_types: output_types, output_shapes: output_shapes, container: container, shared_name: shared_name)
    end

    def self.ones_like(x: nil)
      OpsExecutor.execute("OnesLike", [x])
    end

    def self.optimize_dataset(input_dataset: nil, optimizations: nil, output_types: nil, output_shapes: nil, optimization_configs: nil)
      OpsExecutor.execute("OptimizeDataset", [input_dataset, optimizations], output_types: output_types, output_shapes: output_shapes, optimization_configs: optimization_configs)
    end

    def self.optional_from_value(components: nil)
      OpsExecutor.execute("OptionalFromValue", [components])
    end

    def self.optional_get_value(optional: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("OptionalGetValue", [optional], output_types: output_types, output_shapes: output_shapes)
    end

    def self.optional_has_value(optional: nil)
      OpsExecutor.execute("OptionalHasValue", [optional])
    end

    def self.optional_none
      OpsExecutor.execute("OptionalNone", [])
    end

    def self.ordered_map_clear(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OrderedMapClear", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.ordered_map_incomplete_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OrderedMapIncompleteSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.ordered_map_peek(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OrderedMapPeek", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.ordered_map_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OrderedMapSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.ordered_map_stage(key: nil, indices: nil, values: nil, capacity: nil, memory_limit: nil, dtypes: nil, fake_dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OrderedMapStage", [key, indices, values], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, fake_dtypes: fake_dtypes, container: container, shared_name: shared_name)
    end

    def self.ordered_map_unstage(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OrderedMapUnstage", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.ordered_map_unstage_no_key(indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("OrderedMapUnstageNoKey", [indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.outfeed_dequeue(dtype: nil, shape: nil, device_ordinal: nil)
      OpsExecutor.execute("OutfeedDequeue", [], dtype: dtype, shape: shape, device_ordinal: device_ordinal)
    end

    def self.outfeed_dequeue_tuple(dtypes: nil, shapes: nil, device_ordinal: nil)
      OpsExecutor.execute("OutfeedDequeueTuple", [], dtypes: dtypes, shapes: shapes, device_ordinal: device_ordinal)
    end

    def self.outfeed_enqueue(input: nil, dtype: nil)
      OpsExecutor.execute("OutfeedEnqueue", [input], dtype: dtype)
    end

    def self.outfeed_enqueue_tuple(inputs: nil, dtypes: nil)
      OpsExecutor.execute("OutfeedEnqueueTuple", [inputs], dtypes: dtypes)
    end

    def self.pack(values: nil, axis: nil)
      OpsExecutor.execute("Pack", [values], axis: axis)
    end

    def self.pad(input: nil, paddings: nil)
      OpsExecutor.execute("Pad", [input, paddings])
    end

    def self.pad_v2(input: nil, paddings: nil, constant_values: nil)
      OpsExecutor.execute("PadV2", [input, paddings, constant_values])
    end

    def self.padded_batch_dataset(input_dataset: nil, batch_size: nil, padded_shapes: nil, padding_values: nil, output_shapes: nil)
      OpsExecutor.execute("PaddedBatchDataset", [input_dataset, batch_size, padded_shapes, padding_values], output_shapes: output_shapes)
    end

    def self.padded_batch_dataset_v2(input_dataset: nil, batch_size: nil, padded_shapes: nil, padding_values: nil, drop_remainder: nil, parallel_copy: nil, output_shapes: nil)
      OpsExecutor.execute("PaddedBatchDatasetV2", [input_dataset, batch_size, padded_shapes, padding_values, drop_remainder], parallel_copy: parallel_copy, output_shapes: output_shapes)
    end

    def self.padding_fifo_queue(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("PaddingFIFOQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
    end

    def self.padding_fifo_queue_v2(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("PaddingFIFOQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
    end

    def self.parallel_concat(values: nil, shape: nil)
      OpsExecutor.execute("ParallelConcat", [values], shape: shape)
    end

    def self.parallel_dynamic_stitch(indices: nil, data: nil)
      OpsExecutor.execute("ParallelDynamicStitch", [indices, data])
    end

    def self.parallel_interleave_dataset_v2(input_dataset: nil, other_arguments: nil, cycle_length: nil, block_length: nil, num_parallel_calls: nil, f: nil, output_types: nil, output_shapes: nil, sloppy: nil)
      OpsExecutor.execute("ParallelInterleaveDatasetV2", [input_dataset, other_arguments, cycle_length, block_length, num_parallel_calls], f: f, output_types: output_types, output_shapes: output_shapes, sloppy: sloppy)
    end

    def self.parallel_map_dataset(input_dataset: nil, other_arguments: nil, num_parallel_calls: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil, sloppy: nil, preserve_cardinality: nil)
      OpsExecutor.execute("ParallelMapDataset", [input_dataset, other_arguments, num_parallel_calls], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism, sloppy: sloppy, preserve_cardinality: preserve_cardinality)
    end

    def self.parameterized_truncated_normal(shape: nil, means: nil, stdevs: nil, minvals: nil, maxvals: nil, seed: nil, seed2: nil, dtype: nil)
      OpsExecutor.execute("ParameterizedTruncatedNormal", [shape, means, stdevs, minvals, maxvals], seed: seed, seed2: seed2, dtype: dtype)
    end

    def self.parse_example(serialized: nil, names: nil, sparse_keys: nil, dense_keys: nil, dense_defaults: nil, sparse_types: nil, dense_shapes: nil)
      OpsExecutor.execute("ParseExample", [serialized, names, sparse_keys, dense_keys, dense_defaults], sparse_types: sparse_types, dense_shapes: dense_shapes)
    end

    def self.parse_sequence_example(serialized: nil, debug_name: nil, context_dense_defaults: nil, feature_list_dense_missing_assumed_empty: nil, context_sparse_keys: nil, context_dense_keys: nil, feature_list_sparse_keys: nil, feature_list_dense_keys: nil, context_sparse_types: nil, feature_list_dense_types: nil, context_dense_shapes: nil, feature_list_sparse_types: nil, feature_list_dense_shapes: nil)
      OpsExecutor.execute("ParseSequenceExample", [serialized, debug_name, context_dense_defaults], feature_list_dense_missing_assumed_empty: feature_list_dense_missing_assumed_empty, context_sparse_keys: context_sparse_keys, context_dense_keys: context_dense_keys, feature_list_sparse_keys: feature_list_sparse_keys, feature_list_dense_keys: feature_list_dense_keys, context_sparse_types: context_sparse_types, feature_list_dense_types: feature_list_dense_types, context_dense_shapes: context_dense_shapes, feature_list_sparse_types: feature_list_sparse_types, feature_list_dense_shapes: feature_list_dense_shapes)
    end

    def self.parse_single_example(serialized: nil, dense_defaults: nil, num_sparse: nil, sparse_keys: nil, dense_keys: nil, sparse_types: nil, dense_shapes: nil)
      OpsExecutor.execute("ParseSingleExample", [serialized, dense_defaults], num_sparse: num_sparse, sparse_keys: sparse_keys, dense_keys: dense_keys, sparse_types: sparse_types, dense_shapes: dense_shapes)
    end

    def self.parse_single_sequence_example(serialized: nil, feature_list_dense_missing_assumed_empty: nil, context_sparse_keys: nil, context_dense_keys: nil, feature_list_sparse_keys: nil, feature_list_dense_keys: nil, context_dense_defaults: nil, debug_name: nil, context_sparse_types: nil, feature_list_dense_types: nil, context_dense_shapes: nil, feature_list_sparse_types: nil, feature_list_dense_shapes: nil)
      OpsExecutor.execute("ParseSingleSequenceExample", [serialized, feature_list_dense_missing_assumed_empty, context_sparse_keys, context_dense_keys, feature_list_sparse_keys, feature_list_dense_keys, context_dense_defaults, debug_name], context_sparse_types: context_sparse_types, feature_list_dense_types: feature_list_dense_types, context_dense_shapes: context_dense_shapes, feature_list_sparse_types: feature_list_sparse_types, feature_list_dense_shapes: feature_list_dense_shapes)
    end

    def self.parse_tensor(serialized: nil, out_type: nil)
      OpsExecutor.execute("ParseTensor", [serialized], out_type: out_type)
    end

    def self.partitioned_call(args: nil, f: nil, config: nil, config_proto: nil, executor_type: nil)
      OpsExecutor.execute("PartitionedCall", [args], f: f, config: config, config_proto: config_proto, executor_type: executor_type)
    end

    def self.placeholder(dtype: nil, shape: nil)
      OpsExecutor.execute("Placeholder", [], dtype: dtype, shape: shape)
    end

    def self.placeholder_v2(dtype: nil, shape: nil)
      OpsExecutor.execute("PlaceholderV2", [], dtype: dtype, shape: shape)
    end

    def self.placeholder_with_default(input: nil, dtype: nil, shape: nil)
      OpsExecutor.execute("PlaceholderWithDefault", [input], dtype: dtype, shape: shape)
    end

    def self.polygamma(a: nil, x: nil)
      OpsExecutor.execute("Polygamma", [a, x])
    end

    def self.population_count(x: nil)
      OpsExecutor.execute("PopulationCount", [x])
    end

    def self.pow(x: nil, y: nil)
      OpsExecutor.execute("Pow", [x, y])
    end

    def self.prefetch_dataset(input_dataset: nil, buffer_size: nil, output_types: nil, output_shapes: nil, slack_period: nil)
      OpsExecutor.execute("PrefetchDataset", [input_dataset, buffer_size], output_types: output_types, output_shapes: output_shapes, slack_period: slack_period)
    end

    def self.prelinearize(input: nil, dtype: nil, shape: nil, layout: nil)
      OpsExecutor.execute("Prelinearize", [input], dtype: dtype, shape: shape, layout: layout)
    end

    def self.prelinearize_tuple(inputs: nil, dtypes: nil, shapes: nil, layouts: nil)
      OpsExecutor.execute("PrelinearizeTuple", [inputs], dtypes: dtypes, shapes: shapes, layouts: layouts)
    end

    def self.prevent_gradient(input: nil, message: nil)
      OpsExecutor.execute("PreventGradient", [input], message: message)
    end

    def self.print(input: nil, data: nil, message: nil, first_n: nil, summarize: nil)
      OpsExecutor.execute("Print", [input, data], message: message, first_n: first_n, summarize: summarize)
    end

    def self.print_v2(input: nil, output_stream: nil, stop: nil)
      OpsExecutor.execute("PrintV2", [input], output_stream: output_stream, stop: stop)
    end

    def self.priority_queue(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("PriorityQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
    end

    def self.priority_queue_v2(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("PriorityQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
    end

    def self.prod(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("Prod", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.py_func(input: nil, token: nil)
      OpsExecutor.execute("PyFunc", [input], token: token)
    end

    def self.py_func_stateless(input: nil, token: nil)
      OpsExecutor.execute("PyFuncStateless", [input], token: token)
    end

    def self.qr(input: nil, full_matrices: nil)
      OpsExecutor.execute("Qr", [input], full_matrices: full_matrices)
    end

    def self.quantize_and_dequantize(input: nil, signed_input: nil, num_bits: nil, range_given: nil, input_min: nil, input_max: nil)
      OpsExecutor.execute("QuantizeAndDequantize", [input], signed_input: signed_input, num_bits: num_bits, range_given: range_given, input_min: input_min, input_max: input_max)
    end

    def self.quantize_and_dequantize_v2(input: nil, input_min: nil, input_max: nil, signed_input: nil, num_bits: nil, range_given: nil, round_mode: nil)
      OpsExecutor.execute("QuantizeAndDequantizeV2", [input, input_min, input_max], signed_input: signed_input, num_bits: num_bits, range_given: range_given, round_mode: round_mode)
    end

    def self.quantize_and_dequantize_v3(input: nil, input_min: nil, input_max: nil, num_bits: nil, signed_input: nil, range_given: nil)
      OpsExecutor.execute("QuantizeAndDequantizeV3", [input, input_min, input_max, num_bits], signed_input: signed_input, range_given: range_given)
    end

    def self.quantize_down_and_shrink_range(input: nil, input_min: nil, input_max: nil, out_type: nil)
      OpsExecutor.execute("QuantizeDownAndShrinkRange", [input, input_min, input_max], out_type: out_type)
    end

    def self.quantize_v2(input: nil, min_range: nil, max_range: nil, mode: nil, round_mode: nil)
      OpsExecutor.execute("QuantizeV2", [input, min_range, max_range], mode: mode, round_mode: round_mode)
    end

    def self.quantized_add(x: nil, y: nil, min_x: nil, max_x: nil, min_y: nil, max_y: nil)
      OpsExecutor.execute("QuantizedAdd", [x, y, min_x, max_x, min_y, max_y])
    end

    def self.quantized_avg_pool(input: nil, min_input: nil, max_input: nil, ksize: nil, strides: nil, padding: nil)
      OpsExecutor.execute("QuantizedAvgPool", [input, min_input, max_input], ksize: ksize, strides: strides, padding: padding)
    end

    def self.quantized_batch_norm_with_global_normalization(t: nil, t_min: nil, t_max: nil, m: nil, m_min: nil, m_max: nil, v: nil, v_min: nil, v_max: nil, beta: nil, beta_min: nil, beta_max: nil, gamma: nil, gamma_min: nil, gamma_max: nil, out_type: nil, variance_epsilon: nil, scale_after_normalization: nil)
      OpsExecutor.execute("QuantizedBatchNormWithGlobalNormalization", [t, t_min, t_max, m, m_min, m_max, v, v_min, v_max, beta, beta_min, beta_max, gamma, gamma_min, gamma_max], out_type: out_type, variance_epsilon: variance_epsilon, scale_after_normalization: scale_after_normalization)
    end

    def self.quantized_bias_add(input: nil, bias: nil, min_input: nil, max_input: nil, min_bias: nil, max_bias: nil, out_type: nil)
      OpsExecutor.execute("QuantizedBiasAdd", [input, bias, min_input, max_input, min_bias, max_bias], out_type: out_type)
    end

    def self.quantized_concat(concat_dim: nil, values: nil, input_mins: nil, input_maxes: nil)
      OpsExecutor.execute("QuantizedConcat", [concat_dim, values, input_mins, input_maxes])
    end

    def self.quantized_conv2d(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("QuantizedConv2D", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
    end

    def self.quantized_conv2d_and_relu(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DAndRelu", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_and_relu_and_requantize(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DAndReluAndRequantize", [input, filter, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_and_requantize(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DAndRequantize", [input, filter, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_per_channel(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("QuantizedConv2DPerChannel", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
    end

    def self.quantized_conv2d_with_bias(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DWithBias", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_with_bias_and_relu(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DWithBiasAndRelu", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_with_bias_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DWithBiasAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_with_bias_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DWithBiasAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_with_bias_signed_sum_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, summand: nil, min_summand: nil, max_summand: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DWithBiasSignedSumAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output, summand, min_summand, max_summand], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_with_bias_sum_and_relu(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, summand: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DWithBiasSumAndRelu", [input, filter, bias, min_input, max_input, min_filter, max_filter, summand], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_conv2d_with_bias_sum_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, summand: nil, min_summand: nil, max_summand: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
      OpsExecutor.execute("QuantizedConv2DWithBiasSumAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output, summand, min_summand, max_summand], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
    end

    def self.quantized_depthwise_conv2d(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("QuantizedDepthwiseConv2D", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
    end

    def self.quantized_depthwise_conv2d_with_bias(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("QuantizedDepthwiseConv2DWithBias", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
    end

    def self.quantized_depthwise_conv2d_with_bias_and_relu(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("QuantizedDepthwiseConv2DWithBiasAndRelu", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
    end

    def self.quantized_depthwise_conv2d_with_bias_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
      OpsExecutor.execute("QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
    end

    def self.quantized_instance_norm(x: nil, x_min: nil, x_max: nil, output_range_given: nil, given_y_min: nil, given_y_max: nil, variance_epsilon: nil, min_separation: nil)
      OpsExecutor.execute("QuantizedInstanceNorm", [x, x_min, x_max], output_range_given: output_range_given, given_y_min: given_y_min, given_y_max: given_y_max, variance_epsilon: variance_epsilon, min_separation: min_separation)
    end

    def self.quantized_mat_mul(a: nil, b: nil, min_a: nil, max_a: nil, min_b: nil, max_b: nil, transpose_a: nil, transpose_b: nil)
      OpsExecutor.execute("QuantizedMatMul", [a, b, min_a, max_a, min_b, max_b], transpose_a: transpose_a, transpose_b: transpose_b)
    end

    def self.quantized_max_pool(input: nil, min_input: nil, max_input: nil, ksize: nil, strides: nil, padding: nil)
      OpsExecutor.execute("QuantizedMaxPool", [input, min_input, max_input], ksize: ksize, strides: strides, padding: padding)
    end

    def self.quantized_mul(x: nil, y: nil, min_x: nil, max_x: nil, min_y: nil, max_y: nil)
      OpsExecutor.execute("QuantizedMul", [x, y, min_x, max_x, min_y, max_y])
    end

    def self.quantized_relu(features: nil, min_features: nil, max_features: nil, out_type: nil)
      OpsExecutor.execute("QuantizedRelu", [features, min_features, max_features], out_type: out_type)
    end

    def self.quantized_relu6(features: nil, min_features: nil, max_features: nil, out_type: nil)
      OpsExecutor.execute("QuantizedRelu6", [features, min_features, max_features], out_type: out_type)
    end

    def self.quantized_relu_x(features: nil, max_value: nil, min_features: nil, max_features: nil, out_type: nil)
      OpsExecutor.execute("QuantizedReluX", [features, max_value, min_features, max_features], out_type: out_type)
    end

    def self.quantized_reshape(tensor: nil, shape: nil, input_min: nil, input_max: nil)
      OpsExecutor.execute("QuantizedReshape", [tensor, shape, input_min, input_max])
    end

    def self.quantized_resize_bilinear(images: nil, size: nil, min: nil, max: nil, align_corners: nil, half_pixel_centers: nil)
      OpsExecutor.execute("QuantizedResizeBilinear", [images, size, min, max], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
    end

    def self.queue_close(handle: nil, cancel_pending_enqueues: nil)
      OpsExecutor.execute("QueueClose", [handle], cancel_pending_enqueues: cancel_pending_enqueues)
    end

    def self.queue_close_v2(handle: nil, cancel_pending_enqueues: nil)
      OpsExecutor.execute("QueueCloseV2", [handle], cancel_pending_enqueues: cancel_pending_enqueues)
    end

    def self.queue_dequeue(handle: nil, component_types: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueDequeue", [handle], component_types: component_types, timeout_ms: timeout_ms)
    end

    def self.queue_dequeue_many(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueDequeueMany", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
    end

    def self.queue_dequeue_many_v2(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueDequeueManyV2", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
    end

    def self.queue_dequeue_up_to(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueDequeueUpTo", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
    end

    def self.queue_dequeue_up_to_v2(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueDequeueUpToV2", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
    end

    def self.queue_dequeue_v2(handle: nil, component_types: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueDequeueV2", [handle], component_types: component_types, timeout_ms: timeout_ms)
    end

    def self.queue_enqueue(handle: nil, components: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueEnqueue", [handle, components], timeout_ms: timeout_ms)
    end

    def self.queue_enqueue_many(handle: nil, components: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueEnqueueMany", [handle, components], timeout_ms: timeout_ms)
    end

    def self.queue_enqueue_many_v2(handle: nil, components: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueEnqueueManyV2", [handle, components], timeout_ms: timeout_ms)
    end

    def self.queue_enqueue_v2(handle: nil, components: nil, timeout_ms: nil)
      OpsExecutor.execute("QueueEnqueueV2", [handle, components], timeout_ms: timeout_ms)
    end

    def self.queue_is_closed(handle: nil)
      OpsExecutor.execute("QueueIsClosed", [handle])
    end

    def self.queue_is_closed_v2(handle: nil)
      OpsExecutor.execute("QueueIsClosedV2", [handle])
    end

    def self.queue_size(handle: nil)
      OpsExecutor.execute("QueueSize", [handle])
    end

    def self.queue_size_v2(handle: nil)
      OpsExecutor.execute("QueueSizeV2", [handle])
    end

    def self.rfft(input: nil, fft_length: nil)
      OpsExecutor.execute("RFFT", [input, fft_length])
    end

    def self.rfft2d(input: nil, fft_length: nil)
      OpsExecutor.execute("RFFT2D", [input, fft_length])
    end

    def self.rfft3d(input: nil, fft_length: nil)
      OpsExecutor.execute("RFFT3D", [input, fft_length])
    end

    def self.rgb_to_hsv(images: nil)
      OpsExecutor.execute("RGBToHSV", [images])
    end

    def self.ragged_gather(params_nested_splits: nil, params_dense_values: nil, indices: nil)
      OpsExecutor.execute("RaggedGather", [params_nested_splits, params_dense_values, indices])
    end

    def self.ragged_range(starts: nil, limits: nil, deltas: nil)
      OpsExecutor.execute("RaggedRange", [starts, limits, deltas])
    end

    def self.ragged_tensor_from_variant(encoded_ragged: nil, input_ragged_rank: nil, output_ragged_rank: nil)
      OpsExecutor.execute("RaggedTensorFromVariant", [encoded_ragged], input_ragged_rank: input_ragged_rank, output_ragged_rank: output_ragged_rank)
    end

    def self.ragged_tensor_to_sparse(rt_nested_splits: nil, rt_dense_values: nil)
      OpsExecutor.execute("RaggedTensorToSparse", [rt_nested_splits, rt_dense_values])
    end

    def self.ragged_tensor_to_variant(rt_nested_splits: nil, rt_dense_values: nil, batched_input: nil)
      OpsExecutor.execute("RaggedTensorToVariant", [rt_nested_splits, rt_dense_values], batched_input: batched_input)
    end

    def self.random_crop(image: nil, size: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("RandomCrop", [image, size], seed: seed, seed2: seed2)
    end

    def self.random_gamma(shape: nil, alpha: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("RandomGamma", [shape, alpha], seed: seed, seed2: seed2)
    end

    def self.random_gamma_grad(alpha: nil, sample: nil)
      OpsExecutor.execute("RandomGammaGrad", [alpha, sample])
    end

    def self.random_poisson(shape: nil, rate: nil, seed: nil, seed2: nil, dtype: nil)
      OpsExecutor.execute("RandomPoisson", [shape, rate], seed: seed, seed2: seed2, dtype: dtype)
    end

    def self.random_poisson_v2(shape: nil, rate: nil, seed: nil, seed2: nil, dtype: nil)
      OpsExecutor.execute("RandomPoissonV2", [shape, rate], seed: seed, seed2: seed2, dtype: dtype)
    end

    def self.random_shuffle(value: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("RandomShuffle", [value], seed: seed, seed2: seed2)
    end

    def self.random_shuffle_queue(component_types: nil, shapes: nil, capacity: nil, min_after_dequeue: nil, seed: nil, seed2: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("RandomShuffleQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, min_after_dequeue: min_after_dequeue, seed: seed, seed2: seed2, container: container, shared_name: shared_name)
    end

    def self.random_shuffle_queue_v2(component_types: nil, shapes: nil, capacity: nil, min_after_dequeue: nil, seed: nil, seed2: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("RandomShuffleQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, min_after_dequeue: min_after_dequeue, seed: seed, seed2: seed2, container: container, shared_name: shared_name)
    end

    def self.random_standard_normal(shape: nil, seed: nil, seed2: nil, dtype: nil)
      OpsExecutor.execute("RandomStandardNormal", [shape], seed: seed, seed2: seed2, dtype: dtype)
    end

    def self.random_uniform(shape: nil, seed: nil, seed2: nil, dtype: nil)
      OpsExecutor.execute("RandomUniform", [shape], seed: seed, seed2: seed2, dtype: dtype)
    end

    def self.random_uniform_int(shape: nil, minval: nil, maxval: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("RandomUniformInt", [shape, minval, maxval], seed: seed, seed2: seed2)
    end

    def self.range(start: nil, limit: nil, delta: nil)
      OpsExecutor.execute("Range", [start, limit, delta])
    end

    def self.range_dataset(start: nil, stop: nil, step: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("RangeDataset", [start, stop, step], output_types: output_types, output_shapes: output_shapes)
    end

    def self.rank(input: nil)
      OpsExecutor.execute("Rank", [input])
    end

    def self.read_file(filename: nil)
      OpsExecutor.execute("ReadFile", [filename])
    end

    def self.read_variable_op(resource: nil, dtype: nil)
      OpsExecutor.execute("ReadVariableOp", [resource], dtype: dtype)
    end

    def self.reader_num_records_produced(reader_handle: nil)
      OpsExecutor.execute("ReaderNumRecordsProduced", [reader_handle])
    end

    def self.reader_num_records_produced_v2(reader_handle: nil)
      OpsExecutor.execute("ReaderNumRecordsProducedV2", [reader_handle])
    end

    def self.reader_num_work_units_completed(reader_handle: nil)
      OpsExecutor.execute("ReaderNumWorkUnitsCompleted", [reader_handle])
    end

    def self.reader_num_work_units_completed_v2(reader_handle: nil)
      OpsExecutor.execute("ReaderNumWorkUnitsCompletedV2", [reader_handle])
    end

    def self.reader_read(reader_handle: nil, queue_handle: nil)
      OpsExecutor.execute("ReaderRead", [reader_handle, queue_handle])
    end

    def self.reader_read_up_to(reader_handle: nil, queue_handle: nil, num_records: nil)
      OpsExecutor.execute("ReaderReadUpTo", [reader_handle, queue_handle, num_records])
    end

    def self.reader_read_up_to_v2(reader_handle: nil, queue_handle: nil, num_records: nil)
      OpsExecutor.execute("ReaderReadUpToV2", [reader_handle, queue_handle, num_records])
    end

    def self.reader_read_v2(reader_handle: nil, queue_handle: nil)
      OpsExecutor.execute("ReaderReadV2", [reader_handle, queue_handle])
    end

    def self.reader_reset(reader_handle: nil)
      OpsExecutor.execute("ReaderReset", [reader_handle])
    end

    def self.reader_reset_v2(reader_handle: nil)
      OpsExecutor.execute("ReaderResetV2", [reader_handle])
    end

    def self.reader_restore_state(reader_handle: nil, state: nil)
      OpsExecutor.execute("ReaderRestoreState", [reader_handle, state])
    end

    def self.reader_restore_state_v2(reader_handle: nil, state: nil)
      OpsExecutor.execute("ReaderRestoreStateV2", [reader_handle, state])
    end

    def self.reader_serialize_state(reader_handle: nil)
      OpsExecutor.execute("ReaderSerializeState", [reader_handle])
    end

    def self.reader_serialize_state_v2(reader_handle: nil)
      OpsExecutor.execute("ReaderSerializeStateV2", [reader_handle])
    end

    def self.real(input: nil)
      OpsExecutor.execute("Real", [input])
    end

    def self.real_div(x: nil, y: nil)
      OpsExecutor.execute("RealDiv", [x, y])
    end

    def self.reciprocal(x: nil)
      OpsExecutor.execute("Reciprocal", [x])
    end

    def self.reciprocal_grad(y: nil, dy: nil)
      OpsExecutor.execute("ReciprocalGrad", [y, dy])
    end

    def self.record_input(file_pattern: nil, file_random_seed: nil, file_shuffle_shift_ratio: nil, file_buffer_size: nil, file_parallelism: nil, batch_size: nil, compression_type: nil)
      OpsExecutor.execute("RecordInput", [], file_pattern: file_pattern, file_random_seed: file_random_seed, file_shuffle_shift_ratio: file_shuffle_shift_ratio, file_buffer_size: file_buffer_size, file_parallelism: file_parallelism, batch_size: batch_size, compression_type: compression_type)
    end

    def self.recv_tpu_embedding_activations(num_outputs: nil, config: nil)
      OpsExecutor.execute("RecvTPUEmbeddingActivations", [], num_outputs: num_outputs, config: config)
    end

    def self.reduce_dataset(input_dataset: nil, initial_state: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil)
      OpsExecutor.execute("ReduceDataset", [input_dataset, initial_state, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism)
    end

    def self.reduce_join(inputs: nil, reduction_indices: nil, keep_dims: nil, separator: nil)
      OpsExecutor.execute("ReduceJoin", [inputs, reduction_indices], keep_dims: keep_dims, separator: separator)
    end

    def self.ref_enter(data: nil, frame_name: nil, is_constant: nil, parallel_iterations: nil)
      OpsExecutor.execute("RefEnter", [data], frame_name: frame_name, is_constant: is_constant, parallel_iterations: parallel_iterations)
    end

    def self.ref_exit(data: nil)
      OpsExecutor.execute("RefExit", [data])
    end

    def self.ref_identity(input: nil)
      OpsExecutor.execute("RefIdentity", [input])
    end

    def self.ref_merge(inputs: nil)
      OpsExecutor.execute("RefMerge", [inputs])
    end

    def self.ref_next_iteration(data: nil)
      OpsExecutor.execute("RefNextIteration", [data])
    end

    def self.ref_select(index: nil, inputs: nil)
      OpsExecutor.execute("RefSelect", [index, inputs])
    end

    def self.ref_switch(data: nil, pred: nil)
      OpsExecutor.execute("RefSwitch", [data, pred])
    end

    def self.regex_full_match(input: nil, pattern: nil)
      OpsExecutor.execute("RegexFullMatch", [input, pattern])
    end

    def self.regex_replace(input: nil, pattern: nil, rewrite: nil, replace_global: nil)
      OpsExecutor.execute("RegexReplace", [input, pattern, rewrite], replace_global: replace_global)
    end

    def self.relu(features: nil)
      OpsExecutor.execute("Relu", [features])
    end

    def self.relu6(features: nil)
      OpsExecutor.execute("Relu6", [features])
    end

    def self.relu6_grad(gradients: nil, features: nil)
      OpsExecutor.execute("Relu6Grad", [gradients, features])
    end

    def self.relu_grad(gradients: nil, features: nil)
      OpsExecutor.execute("ReluGrad", [gradients, features])
    end

    def self.remote_call(target: nil, args: nil, f: nil)
      OpsExecutor.execute("RemoteCall", [target, args], f: f)
    end

    def self.remote_fused_graph_execute(inputs: nil, serialized_remote_fused_graph_execute_info: nil)
      OpsExecutor.execute("RemoteFusedGraphExecute", [inputs], serialized_remote_fused_graph_execute_info: serialized_remote_fused_graph_execute_info)
    end

    def self.repeat_dataset(input_dataset: nil, count: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("RepeatDataset", [input_dataset, count], output_types: output_types, output_shapes: output_shapes)
    end

    def self.requantization_range(input: nil, input_min: nil, input_max: nil)
      OpsExecutor.execute("RequantizationRange", [input, input_min, input_max])
    end

    def self.requantization_range_per_channel(input: nil, input_min: nil, input_max: nil, clip_value_max: nil)
      OpsExecutor.execute("RequantizationRangePerChannel", [input, input_min, input_max], clip_value_max: clip_value_max)
    end

    def self.requantize(input: nil, input_min: nil, input_max: nil, requested_output_min: nil, requested_output_max: nil, out_type: nil)
      OpsExecutor.execute("Requantize", [input, input_min, input_max, requested_output_min, requested_output_max], out_type: out_type)
    end

    def self.requantize_per_channel(input: nil, input_min: nil, input_max: nil, requested_output_min: nil, requested_output_max: nil, out_type: nil)
      OpsExecutor.execute("RequantizePerChannel", [input, input_min, input_max, requested_output_min, requested_output_max], out_type: out_type)
    end

    def self.reshape(tensor: nil, shape: nil)
      OpsExecutor.execute("Reshape", [tensor, shape])
    end

    def self.resize_area(images: nil, size: nil, align_corners: nil)
      OpsExecutor.execute("ResizeArea", [images, size], align_corners: align_corners)
    end

    def self.resize_bicubic(images: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
      OpsExecutor.execute("ResizeBicubic", [images, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
    end

    def self.resize_bicubic_grad(grads: nil, original_image: nil, align_corners: nil, half_pixel_centers: nil)
      OpsExecutor.execute("ResizeBicubicGrad", [grads, original_image], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
    end

    def self.resize_bilinear(images: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
      OpsExecutor.execute("ResizeBilinear", [images, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
    end

    def self.resize_bilinear_grad(grads: nil, original_image: nil, align_corners: nil, half_pixel_centers: nil)
      OpsExecutor.execute("ResizeBilinearGrad", [grads, original_image], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
    end

    def self.resize_nearest_neighbor(images: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
      OpsExecutor.execute("ResizeNearestNeighbor", [images, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
    end

    def self.resize_nearest_neighbor_grad(grads: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
      OpsExecutor.execute("ResizeNearestNeighborGrad", [grads, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
    end

    def self.resource_apply_ada_max(var: nil, m: nil, v: nil, beta1_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyAdaMax", [var, m, v, beta1_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking)
    end

    def self.resource_apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad], use_locking: use_locking)
    end

    def self.resource_apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, use_locking: nil, update_slots: nil)
      OpsExecutor.execute("ResourceApplyAdagrad", [var, accum, lr, grad], use_locking: use_locking, update_slots: update_slots)
    end

    def self.resource_apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step], use_locking: use_locking)
    end

    def self.resource_apply_adam(var: nil, m: nil, v: nil, beta1_power: nil, beta2_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("ResourceApplyAdam", [var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.resource_apply_adam_with_amsgrad(var: nil, m: nil, v: nil, vhat: nil, beta1_power: nil, beta2_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyAdamWithAmsgrad", [var, m, v, vhat, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking)
    end

    def self.resource_apply_add_sign(var: nil, m: nil, lr: nil, alpha: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyAddSign", [var, m, lr, alpha, sign_decay, beta, grad], use_locking: use_locking)
    end

    def self.resource_apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
    end

    def self.resource_apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyFtrl", [var, accum, linear, grad, lr, l1, l2, lr_power], use_locking: use_locking)
    end

    def self.resource_apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyFtrlV2", [var, accum, linear, grad, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
    end

    def self.resource_apply_gradient_descent(var: nil, alpha: nil, delta: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyGradientDescent", [var, alpha, delta], use_locking: use_locking)
    end

    def self.resource_apply_keras_momentum(var: nil, accum: nil, lr: nil, grad: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("ResourceApplyKerasMomentum", [var, accum, lr, grad, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.resource_apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("ResourceApplyMomentum", [var, accum, lr, grad, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.resource_apply_power_sign(var: nil, m: nil, lr: nil, logbase: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyPowerSign", [var, m, lr, logbase, sign_decay, beta, grad], use_locking: use_locking)
    end

    def self.resource_apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyProximalAdagrad", [var, accum, lr, l1, l2, grad], use_locking: use_locking)
    end

    def self.resource_apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, delta: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyProximalGradientDescent", [var, alpha, l1, l2, delta], use_locking: use_locking)
    end

    def self.resource_apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
      OpsExecutor.execute("ResourceApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
    end

    def self.resource_count_up_to(resource: nil, limit: nil)
      OpsExecutor.execute("ResourceCountUpTo", [resource], limit: limit)
    end

    def self.resource_gather(resource: nil, indices: nil, batch_dims: nil, validate_indices: nil, dtype: nil)
      OpsExecutor.execute("ResourceGather", [resource, indices], batch_dims: batch_dims, validate_indices: validate_indices, dtype: dtype)
    end

    def self.resource_gather_nd(resource: nil, indices: nil, dtype: nil)
      OpsExecutor.execute("ResourceGatherNd", [resource, indices], dtype: dtype)
    end

    def self.resource_scatter_add(resource: nil, indices: nil, updates: nil, dtype: nil)
      OpsExecutor.execute("ResourceScatterAdd", [resource, indices, updates], dtype: dtype)
    end

    def self.resource_scatter_div(resource: nil, indices: nil, updates: nil, dtype: nil)
      OpsExecutor.execute("ResourceScatterDiv", [resource, indices, updates], dtype: dtype)
    end

    def self.resource_scatter_max(resource: nil, indices: nil, updates: nil, dtype: nil)
      OpsExecutor.execute("ResourceScatterMax", [resource, indices, updates], dtype: dtype)
    end

    def self.resource_scatter_min(resource: nil, indices: nil, updates: nil, dtype: nil)
      OpsExecutor.execute("ResourceScatterMin", [resource, indices, updates], dtype: dtype)
    end

    def self.resource_scatter_mul(resource: nil, indices: nil, updates: nil, dtype: nil)
      OpsExecutor.execute("ResourceScatterMul", [resource, indices, updates], dtype: dtype)
    end

    def self.resource_scatter_nd_add(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ResourceScatterNdAdd", [ref, indices, updates], use_locking: use_locking)
    end

    def self.resource_scatter_nd_sub(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ResourceScatterNdSub", [ref, indices, updates], use_locking: use_locking)
    end

    def self.resource_scatter_nd_update(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ResourceScatterNdUpdate", [ref, indices, updates], use_locking: use_locking)
    end

    def self.resource_scatter_sub(resource: nil, indices: nil, updates: nil, dtype: nil)
      OpsExecutor.execute("ResourceScatterSub", [resource, indices, updates], dtype: dtype)
    end

    def self.resource_scatter_update(resource: nil, indices: nil, updates: nil, dtype: nil)
      OpsExecutor.execute("ResourceScatterUpdate", [resource, indices, updates], dtype: dtype)
    end

    def self.resource_sparse_apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad, indices], use_locking: use_locking)
    end

    def self.resource_sparse_apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, use_locking: nil, update_slots: nil)
      OpsExecutor.execute("ResourceSparseApplyAdagrad", [var, accum, lr, grad, indices], use_locking: use_locking, update_slots: update_slots)
    end

    def self.resource_sparse_apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step], use_locking: use_locking)
    end

    def self.resource_sparse_apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
    end

    def self.resource_sparse_apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyFtrl", [var, accum, linear, grad, indices, lr, l1, l2, lr_power], use_locking: use_locking)
    end

    def self.resource_sparse_apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyFtrlV2", [var, accum, linear, grad, indices, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
    end

    def self.resource_sparse_apply_keras_momentum(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("ResourceSparseApplyKerasMomentum", [var, accum, lr, grad, indices, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.resource_sparse_apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("ResourceSparseApplyMomentum", [var, accum, lr, grad, indices, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.resource_sparse_apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyProximalAdagrad", [var, accum, lr, l1, l2, grad, indices], use_locking: use_locking)
    end

    def self.resource_sparse_apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyProximalGradientDescent", [var, alpha, l1, l2, grad, indices], use_locking: use_locking)
    end

    def self.resource_sparse_apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("ResourceSparseApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
    end

    def self.resource_strided_slice_assign(ref: nil, start: nil, stop: nil, strides: nil, value: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
      OpsExecutor.execute("ResourceStridedSliceAssign", [ref, start, stop, strides, value], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
    end

    def self.restore(file_pattern: nil, tensor_name: nil, dt: nil, preferred_shard: nil)
      OpsExecutor.execute("Restore", [file_pattern, tensor_name], dt: dt, preferred_shard: preferred_shard)
    end

    def self.restore_slice(file_pattern: nil, tensor_name: nil, shape_and_slice: nil, dt: nil, preferred_shard: nil)
      OpsExecutor.execute("RestoreSlice", [file_pattern, tensor_name, shape_and_slice], dt: dt, preferred_shard: preferred_shard)
    end

    def self.restore_v2(prefix: nil, tensor_names: nil, shape_and_slices: nil, dtypes: nil)
      OpsExecutor.execute("RestoreV2", [prefix, tensor_names, shape_and_slices], dtypes: dtypes)
    end

    def self.retrieve_tpu_embedding_adam_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingADAMParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_adam_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingADAMParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_adadelta_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingAdadeltaParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_adadelta_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_adagrad_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingAdagradParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_adagrad_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingAdagradParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_centered_rms_prop_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingCenteredRMSPropParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_ftrl_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingFTRLParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_ftrl_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingFTRLParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_mdl_adagrad_light_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingMDLAdagradLightParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_momentum_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingMomentumParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_momentum_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingMomentumParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_proximal_adagrad_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingProximalAdagradParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_rms_prop_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingRMSPropParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_rms_prop_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.retrieve_tpu_embedding_stochastic_gradient_descent_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
      OpsExecutor.execute("RetrieveTPUEmbeddingStochasticGradientDescentParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
    end

    def self.reverse(tensor: nil, dims: nil)
      OpsExecutor.execute("Reverse", [tensor, dims])
    end

    def self.reverse_sequence(input: nil, seq_lengths: nil, seq_dim: nil, batch_dim: nil)
      OpsExecutor.execute("ReverseSequence", [input, seq_lengths], seq_dim: seq_dim, batch_dim: batch_dim)
    end

    def self.reverse_v2(tensor: nil, axis: nil)
      OpsExecutor.execute("ReverseV2", [tensor, axis])
    end

    def self.right_shift(x: nil, y: nil)
      OpsExecutor.execute("RightShift", [x, y])
    end

    def self.rint(x: nil)
      OpsExecutor.execute("Rint", [x])
    end

    def self.rng_skip(resource: nil, algorithm: nil, delta: nil)
      OpsExecutor.execute("RngSkip", [resource, algorithm, delta])
    end

    def self.roll(input: nil, shift: nil, axis: nil)
      OpsExecutor.execute("Roll", [input, shift, axis])
    end

    def self.round(x: nil)
      OpsExecutor.execute("Round", [x])
    end

    def self.rpc(address: nil, method: nil, request: nil, protocol: nil, fail_fast: nil, timeout_in_ms: nil)
      OpsExecutor.execute("Rpc", [address, method, request], protocol: protocol, fail_fast: fail_fast, timeout_in_ms: timeout_in_ms)
    end

    def self.rsqrt(x: nil)
      OpsExecutor.execute("Rsqrt", [x])
    end

    def self.rsqrt_grad(y: nil, dy: nil)
      OpsExecutor.execute("RsqrtGrad", [y, dy])
    end

    def self.sample_distorted_bounding_box(image_size: nil, bounding_boxes: nil, seed: nil, seed2: nil, min_object_covered: nil, aspect_ratio_range: nil, area_range: nil, max_attempts: nil, use_image_if_no_bounding_boxes: nil)
      OpsExecutor.execute("SampleDistortedBoundingBox", [image_size, bounding_boxes], seed: seed, seed2: seed2, min_object_covered: min_object_covered, aspect_ratio_range: aspect_ratio_range, area_range: area_range, max_attempts: max_attempts, use_image_if_no_bounding_boxes: use_image_if_no_bounding_boxes)
    end

    def self.sample_distorted_bounding_box_v2(image_size: nil, bounding_boxes: nil, min_object_covered: nil, seed: nil, seed2: nil, aspect_ratio_range: nil, area_range: nil, max_attempts: nil, use_image_if_no_bounding_boxes: nil)
      OpsExecutor.execute("SampleDistortedBoundingBoxV2", [image_size, bounding_boxes, min_object_covered], seed: seed, seed2: seed2, aspect_ratio_range: aspect_ratio_range, area_range: area_range, max_attempts: max_attempts, use_image_if_no_bounding_boxes: use_image_if_no_bounding_boxes)
    end

    def self.sampling_dataset(input_dataset: nil, rate: nil, seed: nil, seed2: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("SamplingDataset", [input_dataset, rate, seed, seed2], output_types: output_types, output_shapes: output_shapes)
    end

    def self.save(filename: nil, tensor_names: nil, data: nil)
      OpsExecutor.execute("Save", [filename, tensor_names, data])
    end

    def self.save_slices(filename: nil, tensor_names: nil, shapes_and_slices: nil, data: nil)
      OpsExecutor.execute("SaveSlices", [filename, tensor_names, shapes_and_slices, data])
    end

    def self.save_v2(prefix: nil, tensor_names: nil, shape_and_slices: nil, tensors: nil, dtypes: nil)
      OpsExecutor.execute("SaveV2", [prefix, tensor_names, shape_and_slices, tensors], dtypes: dtypes)
    end

    def self.scalar_summary(tags: nil, values: nil)
      OpsExecutor.execute("ScalarSummary", [tags, values])
    end

    def self.scale_and_translate(images: nil, size: nil, scale: nil, translation: nil, kernel_type: nil, antialias: nil)
      OpsExecutor.execute("ScaleAndTranslate", [images, size, scale, translation], kernel_type: kernel_type, antialias: antialias)
    end

    def self.scale_and_translate_grad(grads: nil, original_image: nil, scale: nil, translation: nil, kernel_type: nil, antialias: nil)
      OpsExecutor.execute("ScaleAndTranslateGrad", [grads, original_image, scale, translation], kernel_type: kernel_type, antialias: antialias)
    end

    def self.scatter_add(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterAdd", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_div(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterDiv", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_max(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterMax", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_min(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterMin", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_mul(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterMul", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_nd(indices: nil, updates: nil, shape: nil)
      OpsExecutor.execute("ScatterNd", [indices, updates, shape])
    end

    def self.scatter_nd_add(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterNdAdd", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_nd_non_aliasing_add(input: nil, indices: nil, updates: nil)
      OpsExecutor.execute("ScatterNdNonAliasingAdd", [input, indices, updates])
    end

    def self.scatter_nd_sub(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterNdSub", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_nd_update(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterNdUpdate", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_sub(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterSub", [ref, indices, updates], use_locking: use_locking)
    end

    def self.scatter_update(ref: nil, indices: nil, updates: nil, use_locking: nil)
      OpsExecutor.execute("ScatterUpdate", [ref, indices, updates], use_locking: use_locking)
    end

    def self.sdca_fprint(input: nil)
      OpsExecutor.execute("SdcaFprint", [input])
    end

    def self.sdca_optimizer(sparse_example_indices: nil, sparse_feature_indices: nil, sparse_feature_values: nil, dense_features: nil, example_weights: nil, example_labels: nil, sparse_indices: nil, sparse_weights: nil, dense_weights: nil, example_state_data: nil, loss_type: nil, adaptative: nil, num_sparse_features: nil, num_sparse_features_with_values: nil, num_dense_features: nil, l1: nil, l2: nil, num_loss_partitions: nil, num_inner_iterations: nil)
      OpsExecutor.execute("SdcaOptimizer", [sparse_example_indices, sparse_feature_indices, sparse_feature_values, dense_features, example_weights, example_labels, sparse_indices, sparse_weights, dense_weights, example_state_data], loss_type: loss_type, adaptative: adaptative, num_sparse_features: num_sparse_features, num_sparse_features_with_values: num_sparse_features_with_values, num_dense_features: num_dense_features, l1: l1, l2: l2, num_loss_partitions: num_loss_partitions, num_inner_iterations: num_inner_iterations)
    end

    def self.sdca_optimizer_v2(sparse_example_indices: nil, sparse_feature_indices: nil, sparse_feature_values: nil, dense_features: nil, example_weights: nil, example_labels: nil, sparse_indices: nil, sparse_weights: nil, dense_weights: nil, example_state_data: nil, loss_type: nil, adaptive: nil, num_sparse_features: nil, num_sparse_features_with_values: nil, num_dense_features: nil, l1: nil, l2: nil, num_loss_partitions: nil, num_inner_iterations: nil)
      OpsExecutor.execute("SdcaOptimizerV2", [sparse_example_indices, sparse_feature_indices, sparse_feature_values, dense_features, example_weights, example_labels, sparse_indices, sparse_weights, dense_weights, example_state_data], loss_type: loss_type, adaptive: adaptive, num_sparse_features: num_sparse_features, num_sparse_features_with_values: num_sparse_features_with_values, num_dense_features: num_dense_features, l1: l1, l2: l2, num_loss_partitions: num_loss_partitions, num_inner_iterations: num_inner_iterations)
    end

    def self.sdca_shrink_l1(weights: nil, num_features: nil, l1: nil, l2: nil)
      OpsExecutor.execute("SdcaShrinkL1", [weights], num_features: num_features, l1: l1, l2: l2)
    end

    def self.segment_max(data: nil, segment_ids: nil)
      OpsExecutor.execute("SegmentMax", [data, segment_ids])
    end

    def self.segment_mean(data: nil, segment_ids: nil)
      OpsExecutor.execute("SegmentMean", [data, segment_ids])
    end

    def self.segment_min(data: nil, segment_ids: nil)
      OpsExecutor.execute("SegmentMin", [data, segment_ids])
    end

    def self.segment_prod(data: nil, segment_ids: nil)
      OpsExecutor.execute("SegmentProd", [data, segment_ids])
    end

    def self.segment_sum(data: nil, segment_ids: nil)
      OpsExecutor.execute("SegmentSum", [data, segment_ids])
    end

    def self.select(condition: nil, t: nil, e: nil)
      OpsExecutor.execute("Select", [condition, t, e])
    end

    def self.select_v2(condition: nil, t: nil, e: nil)
      OpsExecutor.execute("SelectV2", [condition, t, e])
    end

    def self.self_adjoint_eig(input: nil)
      OpsExecutor.execute("SelfAdjointEig", [input])
    end

    def self.self_adjoint_eig_v2(input: nil, compute_v: nil)
      OpsExecutor.execute("SelfAdjointEigV2", [input], compute_v: compute_v)
    end

    def self.selu(features: nil)
      OpsExecutor.execute("Selu", [features])
    end

    def self.selu_grad(gradients: nil, outputs: nil)
      OpsExecutor.execute("SeluGrad", [gradients, outputs])
    end

    def self.send_tpu_embedding_gradients(inputs: nil, learning_rates: nil, config: nil)
      OpsExecutor.execute("SendTPUEmbeddingGradients", [inputs, learning_rates], config: config)
    end

    def self.serialize_iterator(resource_handle: nil)
      OpsExecutor.execute("SerializeIterator", [resource_handle])
    end

    def self.serialize_many_sparse(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, out_type: nil)
      OpsExecutor.execute("SerializeManySparse", [sparse_indices, sparse_values, sparse_shape], out_type: out_type)
    end

    def self.serialize_sparse(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, out_type: nil)
      OpsExecutor.execute("SerializeSparse", [sparse_indices, sparse_values, sparse_shape], out_type: out_type)
    end

    def self.serialize_tensor(tensor: nil)
      OpsExecutor.execute("SerializeTensor", [tensor])
    end

    def self.set_size(set_indices: nil, set_values: nil, set_shape: nil, validate_indices: nil)
      OpsExecutor.execute("SetSize", [set_indices, set_values, set_shape], validate_indices: validate_indices)
    end

    def self.shape(input: nil, out_type: nil)
      OpsExecutor.execute("Shape", [input], out_type: out_type)
    end

    def self.shape_n(input: nil, out_type: nil)
      OpsExecutor.execute("ShapeN", [input], out_type: out_type)
    end

    def self.shard_dataset(input_dataset: nil, num_shards: nil, index: nil, require_non_empty: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ShardDataset", [input_dataset, num_shards, index], require_non_empty: require_non_empty, output_types: output_types, output_shapes: output_shapes)
    end

    def self.sharded_filename(basename: nil, shard: nil, num_shards: nil)
      OpsExecutor.execute("ShardedFilename", [basename, shard, num_shards])
    end

    def self.sharded_filespec(basename: nil, num_shards: nil)
      OpsExecutor.execute("ShardedFilespec", [basename, num_shards])
    end

    def self.shuffle_and_repeat_dataset(input_dataset: nil, buffer_size: nil, seed: nil, seed2: nil, count: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ShuffleAndRepeatDataset", [input_dataset, buffer_size, seed, seed2, count], output_types: output_types, output_shapes: output_shapes)
    end

    def self.shuffle_dataset(input_dataset: nil, buffer_size: nil, seed: nil, seed2: nil, reshuffle_each_iteration: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ShuffleDataset", [input_dataset, buffer_size, seed, seed2], reshuffle_each_iteration: reshuffle_each_iteration, output_types: output_types, output_shapes: output_shapes)
    end

    def self.shutdown_distributed_tpu
      OpsExecutor.execute("ShutdownDistributedTPU", [])
    end

    def self.sigmoid(x: nil)
      OpsExecutor.execute("Sigmoid", [x])
    end

    def self.sigmoid_grad(y: nil, dy: nil)
      OpsExecutor.execute("SigmoidGrad", [y, dy])
    end

    def self.sign(x: nil)
      OpsExecutor.execute("Sign", [x])
    end

    def self.sin(x: nil)
      OpsExecutor.execute("Sin", [x])
    end

    def self.sinh(x: nil)
      OpsExecutor.execute("Sinh", [x])
    end

    def self.size(input: nil, out_type: nil)
      OpsExecutor.execute("Size", [input], out_type: out_type)
    end

    def self.skip_dataset(input_dataset: nil, count: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("SkipDataset", [input_dataset, count], output_types: output_types, output_shapes: output_shapes)
    end

    def self.skipgram(filename: nil, batch_size: nil, window_size: nil, min_count: nil, subsample: nil)
      OpsExecutor.execute("Skipgram", [], filename: filename, batch_size: batch_size, window_size: window_size, min_count: min_count, subsample: subsample)
    end

    def self.slice(input: nil, start: nil, size: nil)
      OpsExecutor.execute("Slice", [input, start, size])
    end

    def self.snapshot(input: nil)
      OpsExecutor.execute("Snapshot", [input])
    end

    def self.snapshot_dataset(input_dataset: nil, path: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("SnapshotDataset", [input_dataset, path], output_types: output_types, output_shapes: output_shapes)
    end

    def self.softmax(logits: nil)
      OpsExecutor.execute("Softmax", [logits])
    end

    def self.softmax_cross_entropy_with_logits(features: nil, labels: nil)
      OpsExecutor.execute("SoftmaxCrossEntropyWithLogits", [features, labels])
    end

    def self.softplus(features: nil)
      OpsExecutor.execute("Softplus", [features])
    end

    def self.softplus_grad(gradients: nil, features: nil)
      OpsExecutor.execute("SoftplusGrad", [gradients, features])
    end

    def self.softsign(features: nil)
      OpsExecutor.execute("Softsign", [features])
    end

    def self.softsign_grad(gradients: nil, features: nil)
      OpsExecutor.execute("SoftsignGrad", [gradients, features])
    end

    def self.space_to_batch(input: nil, paddings: nil, block_size: nil)
      OpsExecutor.execute("SpaceToBatch", [input, paddings], block_size: block_size)
    end

    def self.space_to_batch_nd(input: nil, block_shape: nil, paddings: nil)
      OpsExecutor.execute("SpaceToBatchND", [input, block_shape, paddings])
    end

    def self.space_to_depth(input: nil, block_size: nil, data_format: nil)
      OpsExecutor.execute("SpaceToDepth", [input], block_size: block_size, data_format: data_format)
    end

    def self.sparse_accumulator_apply_gradient(handle: nil, local_step: nil, gradient_indices: nil, gradient_values: nil, gradient_shape: nil, dtype: nil, has_known_shape: nil)
      OpsExecutor.execute("SparseAccumulatorApplyGradient", [handle, local_step, gradient_indices, gradient_values, gradient_shape], dtype: dtype, has_known_shape: has_known_shape)
    end

    def self.sparse_accumulator_take_gradient(handle: nil, num_required: nil, dtype: nil)
      OpsExecutor.execute("SparseAccumulatorTakeGradient", [handle, num_required], dtype: dtype)
    end

    def self.sparse_add(a_indices: nil, a_values: nil, a_shape: nil, b_indices: nil, b_values: nil, b_shape: nil, thresh: nil)
      OpsExecutor.execute("SparseAdd", [a_indices, a_values, a_shape, b_indices, b_values, b_shape, thresh])
    end

    def self.sparse_add_grad(backprop_val_grad: nil, a_indices: nil, b_indices: nil, sum_indices: nil)
      OpsExecutor.execute("SparseAddGrad", [backprop_val_grad, a_indices, b_indices, sum_indices])
    end

    def self.sparse_apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad, indices], use_locking: use_locking)
    end

    def self.sparse_apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, use_locking: nil, update_slots: nil)
      OpsExecutor.execute("SparseApplyAdagrad", [var, accum, lr, grad, indices], use_locking: use_locking, update_slots: update_slots)
    end

    def self.sparse_apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step], use_locking: use_locking)
    end

    def self.sparse_apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
    end

    def self.sparse_apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyFtrl", [var, accum, linear, grad, indices, lr, l1, l2, lr_power], use_locking: use_locking)
    end

    def self.sparse_apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyFtrlV2", [var, accum, linear, grad, indices, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
    end

    def self.sparse_apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
      OpsExecutor.execute("SparseApplyMomentum", [var, accum, lr, grad, indices, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
    end

    def self.sparse_apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyProximalAdagrad", [var, accum, lr, l1, l2, grad, indices], use_locking: use_locking)
    end

    def self.sparse_apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyProximalGradientDescent", [var, alpha, l1, l2, grad, indices], use_locking: use_locking)
    end

    def self.sparse_apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
      OpsExecutor.execute("SparseApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
    end

    def self.sparse_concat(indices: nil, values: nil, shapes: nil, concat_dim: nil)
      OpsExecutor.execute("SparseConcat", [indices, values, shapes], concat_dim: concat_dim)
    end

    def self.sparse_conditional_accumulator(dtype: nil, shape: nil, container: nil, shared_name: nil, reduction_type: nil)
      OpsExecutor.execute("SparseConditionalAccumulator", [], dtype: dtype, shape: shape, container: container, shared_name: shared_name, reduction_type: reduction_type)
    end

    def self.sparse_cross(indices: nil, values: nil, shapes: nil, dense_inputs: nil, hashed_output: nil, num_buckets: nil, hash_key: nil, sparse_types: nil, dense_types: nil, out_type: nil, internal_type: nil)
      OpsExecutor.execute("SparseCross", [indices, values, shapes, dense_inputs], hashed_output: hashed_output, num_buckets: num_buckets, hash_key: hash_key, sparse_types: sparse_types, dense_types: dense_types, out_type: out_type, internal_type: internal_type)
    end

    def self.sparse_dense_cwise_add(sp_indices: nil, sp_values: nil, sp_shape: nil, dense: nil)
      OpsExecutor.execute("SparseDenseCwiseAdd", [sp_indices, sp_values, sp_shape, dense])
    end

    def self.sparse_dense_cwise_div(sp_indices: nil, sp_values: nil, sp_shape: nil, dense: nil)
      OpsExecutor.execute("SparseDenseCwiseDiv", [sp_indices, sp_values, sp_shape, dense])
    end

    def self.sparse_dense_cwise_mul(sp_indices: nil, sp_values: nil, sp_shape: nil, dense: nil)
      OpsExecutor.execute("SparseDenseCwiseMul", [sp_indices, sp_values, sp_shape, dense])
    end

    def self.sparse_fill_empty_rows(indices: nil, values: nil, dense_shape: nil, default_value: nil)
      OpsExecutor.execute("SparseFillEmptyRows", [indices, values, dense_shape, default_value])
    end

    def self.sparse_fill_empty_rows_grad(reverse_index_map: nil, grad_values: nil)
      OpsExecutor.execute("SparseFillEmptyRowsGrad", [reverse_index_map, grad_values])
    end

    def self.sparse_mat_mul(a: nil, b: nil, transpose_a: nil, transpose_b: nil, a_is_sparse: nil, b_is_sparse: nil)
      OpsExecutor.execute("SparseMatMul", [a, b], transpose_a: transpose_a, transpose_b: transpose_b, a_is_sparse: a_is_sparse, b_is_sparse: b_is_sparse)
    end

    def self.sparse_reduce_max(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
      OpsExecutor.execute("SparseReduceMax", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
    end

    def self.sparse_reduce_max_sparse(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
      OpsExecutor.execute("SparseReduceMaxSparse", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
    end

    def self.sparse_reduce_sum(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
      OpsExecutor.execute("SparseReduceSum", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
    end

    def self.sparse_reduce_sum_sparse(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
      OpsExecutor.execute("SparseReduceSumSparse", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
    end

    def self.sparse_reorder(input_indices: nil, input_values: nil, input_shape: nil)
      OpsExecutor.execute("SparseReorder", [input_indices, input_values, input_shape])
    end

    def self.sparse_reshape(input_indices: nil, input_shape: nil, new_shape: nil)
      OpsExecutor.execute("SparseReshape", [input_indices, input_shape, new_shape])
    end

    def self.sparse_segment_mean(data: nil, indices: nil, segment_ids: nil)
      OpsExecutor.execute("SparseSegmentMean", [data, indices, segment_ids])
    end

    def self.sparse_segment_mean_grad(grad: nil, indices: nil, segment_ids: nil, output_dim0: nil)
      OpsExecutor.execute("SparseSegmentMeanGrad", [grad, indices, segment_ids, output_dim0])
    end

    def self.sparse_segment_mean_with_num_segments(data: nil, indices: nil, segment_ids: nil, num_segments: nil)
      OpsExecutor.execute("SparseSegmentMeanWithNumSegments", [data, indices, segment_ids, num_segments])
    end

    def self.sparse_segment_sqrt_n(data: nil, indices: nil, segment_ids: nil)
      OpsExecutor.execute("SparseSegmentSqrtN", [data, indices, segment_ids])
    end

    def self.sparse_segment_sqrt_n_grad(grad: nil, indices: nil, segment_ids: nil, output_dim0: nil)
      OpsExecutor.execute("SparseSegmentSqrtNGrad", [grad, indices, segment_ids, output_dim0])
    end

    def self.sparse_segment_sqrt_n_with_num_segments(data: nil, indices: nil, segment_ids: nil, num_segments: nil)
      OpsExecutor.execute("SparseSegmentSqrtNWithNumSegments", [data, indices, segment_ids, num_segments])
    end

    def self.sparse_segment_sum(data: nil, indices: nil, segment_ids: nil)
      OpsExecutor.execute("SparseSegmentSum", [data, indices, segment_ids])
    end

    def self.sparse_segment_sum_with_num_segments(data: nil, indices: nil, segment_ids: nil, num_segments: nil)
      OpsExecutor.execute("SparseSegmentSumWithNumSegments", [data, indices, segment_ids, num_segments])
    end

    def self.sparse_slice(indices: nil, values: nil, shape: nil, start: nil, size: nil)
      OpsExecutor.execute("SparseSlice", [indices, values, shape, start, size])
    end

    def self.sparse_slice_grad(backprop_val_grad: nil, input_indices: nil, input_start: nil, output_indices: nil)
      OpsExecutor.execute("SparseSliceGrad", [backprop_val_grad, input_indices, input_start, output_indices])
    end

    def self.sparse_softmax(sp_indices: nil, sp_values: nil, sp_shape: nil)
      OpsExecutor.execute("SparseSoftmax", [sp_indices, sp_values, sp_shape])
    end

    def self.sparse_softmax_cross_entropy_with_logits(features: nil, labels: nil)
      OpsExecutor.execute("SparseSoftmaxCrossEntropyWithLogits", [features, labels])
    end

    def self.sparse_sparse_maximum(a_indices: nil, a_values: nil, a_shape: nil, b_indices: nil, b_values: nil, b_shape: nil)
      OpsExecutor.execute("SparseSparseMaximum", [a_indices, a_values, a_shape, b_indices, b_values, b_shape])
    end

    def self.sparse_sparse_minimum(a_indices: nil, a_values: nil, a_shape: nil, b_indices: nil, b_values: nil, b_shape: nil)
      OpsExecutor.execute("SparseSparseMinimum", [a_indices, a_values, a_shape, b_indices, b_values, b_shape])
    end

    def self.sparse_split(split_dim: nil, indices: nil, values: nil, shape: nil, num_split: nil)
      OpsExecutor.execute("SparseSplit", [split_dim, indices, values, shape], num_split: num_split)
    end

    def self.sparse_tensor_dense_add(a_indices: nil, a_values: nil, a_shape: nil, b: nil)
      OpsExecutor.execute("SparseTensorDenseAdd", [a_indices, a_values, a_shape, b])
    end

    def self.sparse_tensor_dense_mat_mul(a_indices: nil, a_values: nil, a_shape: nil, b: nil, adjoint_a: nil, adjoint_b: nil)
      OpsExecutor.execute("SparseTensorDenseMatMul", [a_indices, a_values, a_shape, b], adjoint_a: adjoint_a, adjoint_b: adjoint_b)
    end

    def self.sparse_tensor_slice_dataset(indices: nil, values: nil, dense_shape: nil)
      OpsExecutor.execute("SparseTensorSliceDataset", [indices, values, dense_shape])
    end

    def self.sparse_to_dense(sparse_indices: nil, output_shape: nil, sparse_values: nil, default_value: nil, validate_indices: nil)
      OpsExecutor.execute("SparseToDense", [sparse_indices, output_shape, sparse_values, default_value], validate_indices: validate_indices)
    end

    def self.sparse_to_sparse_set_operation(set1_indices: nil, set1_values: nil, set1_shape: nil, set2_indices: nil, set2_values: nil, set2_shape: nil, set_operation: nil, validate_indices: nil)
      OpsExecutor.execute("SparseToSparseSetOperation", [set1_indices, set1_values, set1_shape, set2_indices, set2_values, set2_shape], set_operation: set_operation, validate_indices: validate_indices)
    end

    def self.split(split_dim: nil, value: nil, num_split: nil)
      OpsExecutor.execute("Split", [split_dim, value], num_split: num_split)
    end

    def self.split_v(value: nil, size_splits: nil, split_dim: nil, num_split: nil)
      OpsExecutor.execute("SplitV", [value, size_splits, split_dim], num_split: num_split)
    end

    def self.sqrt(x: nil)
      OpsExecutor.execute("Sqrt", [x])
    end

    def self.sqrt_grad(y: nil, dy: nil)
      OpsExecutor.execute("SqrtGrad", [y, dy])
    end

    def self.square(x: nil)
      OpsExecutor.execute("Square", [x])
    end

    def self.squared_difference(x: nil, y: nil)
      OpsExecutor.execute("SquaredDifference", [x, y])
    end

    def self.squeeze(input: nil, squeeze_dims: nil)
      OpsExecutor.execute("Squeeze", [input], squeeze_dims: squeeze_dims)
    end

    def self.stack(elem_type: nil, stack_name: nil)
      OpsExecutor.execute("Stack", [], elem_type: elem_type, stack_name: stack_name)
    end

    def self.stack_close(handle: nil)
      OpsExecutor.execute("StackClose", [handle])
    end

    def self.stack_close_v2(handle: nil)
      OpsExecutor.execute("StackCloseV2", [handle])
    end

    def self.stack_pop(handle: nil, elem_type: nil)
      OpsExecutor.execute("StackPop", [handle], elem_type: elem_type)
    end

    def self.stack_pop_v2(handle: nil, elem_type: nil)
      OpsExecutor.execute("StackPopV2", [handle], elem_type: elem_type)
    end

    def self.stack_push(handle: nil, elem: nil, swap_memory: nil)
      OpsExecutor.execute("StackPush", [handle, elem], swap_memory: swap_memory)
    end

    def self.stack_push_v2(handle: nil, elem: nil, swap_memory: nil)
      OpsExecutor.execute("StackPushV2", [handle, elem], swap_memory: swap_memory)
    end

    def self.stack_v2(max_size: nil, elem_type: nil, stack_name: nil)
      OpsExecutor.execute("StackV2", [max_size], elem_type: elem_type, stack_name: stack_name)
    end

    def self.stage(values: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("Stage", [values], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.stage_clear(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("StageClear", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.stage_peek(index: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("StagePeek", [index], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.stage_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("StageSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.stateful_partitioned_call(args: nil, f: nil, config: nil, config_proto: nil, executor_type: nil)
      OpsExecutor.execute("StatefulPartitionedCall", [args], f: f, config: config, config_proto: config_proto, executor_type: executor_type)
    end

    def self.stateful_random_binomial(resource: nil, algorithm: nil, shape: nil, counts: nil, probs: nil, dtype: nil)
      OpsExecutor.execute("StatefulRandomBinomial", [resource, algorithm, shape, counts, probs], dtype: dtype)
    end

    def self.stateful_standard_normal(resource: nil, shape: nil, dtype: nil, shape_dtype: nil)
      OpsExecutor.execute("StatefulStandardNormal", [resource, shape], dtype: dtype, shape_dtype: shape_dtype)
    end

    def self.stateful_standard_normal_v2(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
      OpsExecutor.execute("StatefulStandardNormalV2", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
    end

    def self.stateful_truncated_normal(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
      OpsExecutor.execute("StatefulTruncatedNormal", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
    end

    def self.stateful_uniform(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
      OpsExecutor.execute("StatefulUniform", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
    end

    def self.stateful_uniform_full_int(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
      OpsExecutor.execute("StatefulUniformFullInt", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
    end

    def self.stateful_uniform_int(resource: nil, algorithm: nil, shape: nil, minval: nil, maxval: nil, dtype: nil, shape_dtype: nil)
      OpsExecutor.execute("StatefulUniformInt", [resource, algorithm, shape, minval, maxval], dtype: dtype, shape_dtype: shape_dtype)
    end

    def self.stateless_if(cond: nil, input: nil, then_branch: nil, else_branch: nil)
      OpsExecutor.execute("StatelessIf", [cond, input], then_branch: then_branch, else_branch: else_branch)
    end

    def self.stateless_multinomial(logits: nil, num_samples: nil, seed: nil, output_dtype: nil)
      OpsExecutor.execute("StatelessMultinomial", [logits, num_samples, seed], output_dtype: output_dtype)
    end

    def self.stateless_random_normal(shape: nil, seed: nil, dtype: nil)
      OpsExecutor.execute("StatelessRandomNormal", [shape, seed], dtype: dtype)
    end

    def self.stateless_random_uniform(shape: nil, seed: nil, dtype: nil)
      OpsExecutor.execute("StatelessRandomUniform", [shape, seed], dtype: dtype)
    end

    def self.stateless_random_uniform_int(shape: nil, seed: nil, minval: nil, maxval: nil, dtype: nil)
      OpsExecutor.execute("StatelessRandomUniformInt", [shape, seed, minval, maxval], dtype: dtype)
    end

    def self.stateless_truncated_normal(shape: nil, seed: nil, dtype: nil)
      OpsExecutor.execute("StatelessTruncatedNormal", [shape, seed], dtype: dtype)
    end

    def self.stateless_while(input: nil, cond: nil, body: nil)
      OpsExecutor.execute("StatelessWhile", [input], cond: cond, body: body)
    end

    def self.static_regex_full_match(input: nil, pattern: nil)
      OpsExecutor.execute("StaticRegexFullMatch", [input], pattern: pattern)
    end

    def self.static_regex_replace(input: nil, pattern: nil, rewrite: nil, replace_global: nil)
      OpsExecutor.execute("StaticRegexReplace", [input], pattern: pattern, rewrite: rewrite, replace_global: replace_global)
    end

    def self.stats_aggregator_handle_v2(container: nil, shared_name: nil)
      OpsExecutor.execute("StatsAggregatorHandleV2", [], container: container, shared_name: shared_name)
    end

    def self.stats_aggregator_set_summary_writer(stats_aggregator: nil, summary: nil)
      OpsExecutor.execute("StatsAggregatorSetSummaryWriter", [stats_aggregator, summary])
    end

    def self.stop_gradient(input: nil)
      OpsExecutor.execute("StopGradient", [input])
    end

    def self.strided_slice(input: nil, start: nil, stop: nil, strides: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
      OpsExecutor.execute("StridedSlice", [input, start, stop, strides], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
    end

    def self.strided_slice_assign(ref: nil, start: nil, stop: nil, strides: nil, value: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
      OpsExecutor.execute("StridedSliceAssign", [ref, start, stop, strides, value], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
    end

    def self.strided_slice_grad(shape: nil, start: nil, stop: nil, strides: nil, dy: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
      OpsExecutor.execute("StridedSliceGrad", [shape, start, stop, strides, dy], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
    end

    def self.string_format(inputs: nil, template: nil, placeholder: nil, summarize: nil)
      OpsExecutor.execute("StringFormat", [inputs], template: template, placeholder: placeholder, summarize: summarize)
    end

    def self.string_join(inputs: nil, separator: nil)
      OpsExecutor.execute("StringJoin", [inputs], separator: separator)
    end

    def self.string_length(input: nil, unit: nil)
      OpsExecutor.execute("StringLength", [input], unit: unit)
    end

    def self.string_lower(input: nil, encoding: nil)
      OpsExecutor.execute("StringLower", [input], encoding: encoding)
    end

    def self.string_split(input: nil, delimiter: nil, skip_empty: nil)
      OpsExecutor.execute("StringSplit", [input, delimiter], skip_empty: skip_empty)
    end

    def self.string_split_v2(input: nil, sep: nil, maxsplit: nil)
      OpsExecutor.execute("StringSplitV2", [input, sep], maxsplit: maxsplit)
    end

    def self.string_strip(input: nil)
      OpsExecutor.execute("StringStrip", [input])
    end

    def self.string_to_hash_bucket(string_tensor: nil, num_buckets: nil)
      OpsExecutor.execute("StringToHashBucket", [string_tensor], num_buckets: num_buckets)
    end

    def self.string_to_hash_bucket_fast(input: nil, num_buckets: nil)
      OpsExecutor.execute("StringToHashBucketFast", [input], num_buckets: num_buckets)
    end

    def self.string_to_hash_bucket_strong(input: nil, num_buckets: nil, key: nil)
      OpsExecutor.execute("StringToHashBucketStrong", [input], num_buckets: num_buckets, key: key)
    end

    def self.string_to_number(string_tensor: nil, out_type: nil)
      OpsExecutor.execute("StringToNumber", [string_tensor], out_type: out_type)
    end

    def self.string_upper(input: nil, encoding: nil)
      OpsExecutor.execute("StringUpper", [input], encoding: encoding)
    end

    def self.sub(x: nil, y: nil)
      OpsExecutor.execute("Sub", [x, y])
    end

    def self.substr(input: nil, pos: nil, len: nil, unit: nil)
      OpsExecutor.execute("Substr", [input, pos, len], unit: unit)
    end

    def self.sum(input: nil, reduction_indices: nil, keep_dims: nil)
      OpsExecutor.execute("Sum", [input, reduction_indices], keep_dims: keep_dims)
    end

    def self.summary_writer(shared_name: nil, container: nil)
      OpsExecutor.execute("SummaryWriter", [], shared_name: shared_name, container: container)
    end

    def self.svd(input: nil, compute_uv: nil, full_matrices: nil)
      OpsExecutor.execute("Svd", [input], compute_uv: compute_uv, full_matrices: full_matrices)
    end

    def self.switch(data: nil, pred: nil)
      OpsExecutor.execute("Switch", [data, pred])
    end

    def self.symbolic_gradient(input: nil, f: nil)
      OpsExecutor.execute("SymbolicGradient", [input], f: f)
    end

    def self.tf_record_dataset(filenames: nil, compression_type: nil, buffer_size: nil)
      OpsExecutor.execute("TFRecordDataset", [filenames, compression_type, buffer_size])
    end

    def self.tf_record_reader(container: nil, shared_name: nil, compression_type: nil)
      OpsExecutor.execute("TFRecordReader", [], container: container, shared_name: shared_name, compression_type: compression_type)
    end

    def self.tf_record_reader_v2(container: nil, shared_name: nil, compression_type: nil)
      OpsExecutor.execute("TFRecordReaderV2", [], container: container, shared_name: shared_name, compression_type: compression_type)
    end

    def self.tpu_compilation_result
      OpsExecutor.execute("TPUCompilationResult", [])
    end

    def self.tpu_embedding_activations(embedding_variable: nil, sliced_activations: nil, table_id: nil, lookup_id: nil)
      OpsExecutor.execute("TPUEmbeddingActivations", [embedding_variable, sliced_activations], table_id: table_id, lookup_id: lookup_id)
    end

    def self.tpu_ordinal_selector
      OpsExecutor.execute("TPUOrdinalSelector", [])
    end

    def self.tpu_partitioned_call(args: nil, device_ordinal: nil, f: nil)
      OpsExecutor.execute("TPUPartitionedCall", [args, device_ordinal], f: f)
    end

    def self.tpu_replicate_metadata(num_replicas: nil, num_cores_per_replica: nil, topology: nil, use_tpu: nil, device_assignment: nil, computation_shape: nil, host_compute_core: nil, padding_map: nil, step_marker_location: nil)
      OpsExecutor.execute("TPUReplicateMetadata", [], num_replicas: num_replicas, num_cores_per_replica: num_cores_per_replica, topology: topology, use_tpu: use_tpu, device_assignment: device_assignment, computation_shape: computation_shape, host_compute_core: host_compute_core, padding_map: padding_map, step_marker_location: step_marker_location)
    end

    def self.tpu_replicated_input(inputs: nil)
      OpsExecutor.execute("TPUReplicatedInput", [inputs])
    end

    def self.tpu_replicated_output(input: nil, num_replicas: nil)
      OpsExecutor.execute("TPUReplicatedOutput", [input], num_replicas: num_replicas)
    end

    def self.take_dataset(input_dataset: nil, count: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("TakeDataset", [input_dataset, count], output_types: output_types, output_shapes: output_shapes)
    end

    def self.take_many_sparse_from_tensors_map(sparse_handles: nil, dtype: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("TakeManySparseFromTensorsMap", [sparse_handles], dtype: dtype, container: container, shared_name: shared_name)
    end

    def self.tan(x: nil)
      OpsExecutor.execute("Tan", [x])
    end

    def self.tanh(x: nil)
      OpsExecutor.execute("Tanh", [x])
    end

    def self.tanh_grad(y: nil, dy: nil)
      OpsExecutor.execute("TanhGrad", [y, dy])
    end

    def self.temporary_variable(shape: nil, dtype: nil, var_name: nil)
      OpsExecutor.execute("TemporaryVariable", [], shape: shape, dtype: dtype, var_name: var_name)
    end

    def self.tensor_array(size: nil, dtype: nil, dynamic_size: nil, clear_after_read: nil, tensor_array_name: nil, element_shape: nil)
      OpsExecutor.execute("TensorArray", [size], dtype: dtype, dynamic_size: dynamic_size, clear_after_read: clear_after_read, tensor_array_name: tensor_array_name, element_shape: element_shape)
    end

    def self.tensor_array_close(handle: nil)
      OpsExecutor.execute("TensorArrayClose", [handle])
    end

    def self.tensor_array_close_v2(handle: nil)
      OpsExecutor.execute("TensorArrayCloseV2", [handle])
    end

    def self.tensor_array_close_v3(handle: nil)
      OpsExecutor.execute("TensorArrayCloseV3", [handle])
    end

    def self.tensor_array_concat(handle: nil, flow_in: nil, dtype: nil, element_shape_except0: nil)
      OpsExecutor.execute("TensorArrayConcat", [handle, flow_in], dtype: dtype, element_shape_except0: element_shape_except0)
    end

    def self.tensor_array_concat_v2(handle: nil, flow_in: nil, dtype: nil, element_shape_except0: nil)
      OpsExecutor.execute("TensorArrayConcatV2", [handle, flow_in], dtype: dtype, element_shape_except0: element_shape_except0)
    end

    def self.tensor_array_concat_v3(handle: nil, flow_in: nil, dtype: nil, element_shape_except0: nil)
      OpsExecutor.execute("TensorArrayConcatV3", [handle, flow_in], dtype: dtype, element_shape_except0: element_shape_except0)
    end

    def self.tensor_array_gather(handle: nil, indices: nil, flow_in: nil, dtype: nil, element_shape: nil)
      OpsExecutor.execute("TensorArrayGather", [handle, indices, flow_in], dtype: dtype, element_shape: element_shape)
    end

    def self.tensor_array_gather_v2(handle: nil, indices: nil, flow_in: nil, dtype: nil, element_shape: nil)
      OpsExecutor.execute("TensorArrayGatherV2", [handle, indices, flow_in], dtype: dtype, element_shape: element_shape)
    end

    def self.tensor_array_gather_v3(handle: nil, indices: nil, flow_in: nil, dtype: nil, element_shape: nil)
      OpsExecutor.execute("TensorArrayGatherV3", [handle, indices, flow_in], dtype: dtype, element_shape: element_shape)
    end

    def self.tensor_array_grad(handle: nil, flow_in: nil, source: nil)
      OpsExecutor.execute("TensorArrayGrad", [handle, flow_in], source: source)
    end

    def self.tensor_array_grad_v2(handle: nil, flow_in: nil, source: nil)
      OpsExecutor.execute("TensorArrayGradV2", [handle, flow_in], source: source)
    end

    def self.tensor_array_grad_v3(handle: nil, flow_in: nil, source: nil)
      OpsExecutor.execute("TensorArrayGradV3", [handle, flow_in], source: source)
    end

    def self.tensor_array_grad_with_shape(handle: nil, flow_in: nil, shape_to_prepend: nil, source: nil)
      OpsExecutor.execute("TensorArrayGradWithShape", [handle, flow_in, shape_to_prepend], source: source)
    end

    def self.tensor_array_pack(handle: nil, flow_in: nil, dtype: nil, element_shape: nil)
      OpsExecutor.execute("TensorArrayPack", [handle, flow_in], dtype: dtype, element_shape: element_shape)
    end

    def self.tensor_array_read(handle: nil, index: nil, flow_in: nil, dtype: nil)
      OpsExecutor.execute("TensorArrayRead", [handle, index, flow_in], dtype: dtype)
    end

    def self.tensor_array_read_v2(handle: nil, index: nil, flow_in: nil, dtype: nil)
      OpsExecutor.execute("TensorArrayReadV2", [handle, index, flow_in], dtype: dtype)
    end

    def self.tensor_array_read_v3(handle: nil, index: nil, flow_in: nil, dtype: nil)
      OpsExecutor.execute("TensorArrayReadV3", [handle, index, flow_in], dtype: dtype)
    end

    def self.tensor_array_scatter(handle: nil, indices: nil, value: nil, flow_in: nil)
      OpsExecutor.execute("TensorArrayScatter", [handle, indices, value, flow_in])
    end

    def self.tensor_array_scatter_v2(handle: nil, indices: nil, value: nil, flow_in: nil)
      OpsExecutor.execute("TensorArrayScatterV2", [handle, indices, value, flow_in])
    end

    def self.tensor_array_scatter_v3(handle: nil, indices: nil, value: nil, flow_in: nil)
      OpsExecutor.execute("TensorArrayScatterV3", [handle, indices, value, flow_in])
    end

    def self.tensor_array_size(handle: nil, flow_in: nil)
      OpsExecutor.execute("TensorArraySize", [handle, flow_in])
    end

    def self.tensor_array_size_v2(handle: nil, flow_in: nil)
      OpsExecutor.execute("TensorArraySizeV2", [handle, flow_in])
    end

    def self.tensor_array_size_v3(handle: nil, flow_in: nil)
      OpsExecutor.execute("TensorArraySizeV3", [handle, flow_in])
    end

    def self.tensor_array_split(handle: nil, value: nil, lengths: nil, flow_in: nil)
      OpsExecutor.execute("TensorArraySplit", [handle, value, lengths, flow_in])
    end

    def self.tensor_array_split_v2(handle: nil, value: nil, lengths: nil, flow_in: nil)
      OpsExecutor.execute("TensorArraySplitV2", [handle, value, lengths, flow_in])
    end

    def self.tensor_array_split_v3(handle: nil, value: nil, lengths: nil, flow_in: nil)
      OpsExecutor.execute("TensorArraySplitV3", [handle, value, lengths, flow_in])
    end

    def self.tensor_array_unpack(handle: nil, value: nil, flow_in: nil)
      OpsExecutor.execute("TensorArrayUnpack", [handle, value, flow_in])
    end

    def self.tensor_array_v2(size: nil, dtype: nil, element_shape: nil, dynamic_size: nil, clear_after_read: nil, tensor_array_name: nil)
      OpsExecutor.execute("TensorArrayV2", [size], dtype: dtype, element_shape: element_shape, dynamic_size: dynamic_size, clear_after_read: clear_after_read, tensor_array_name: tensor_array_name)
    end

    def self.tensor_array_v3(size: nil, dtype: nil, element_shape: nil, dynamic_size: nil, clear_after_read: nil, identical_element_shapes: nil, tensor_array_name: nil)
      OpsExecutor.execute("TensorArrayV3", [size], dtype: dtype, element_shape: element_shape, dynamic_size: dynamic_size, clear_after_read: clear_after_read, identical_element_shapes: identical_element_shapes, tensor_array_name: tensor_array_name)
    end

    def self.tensor_array_write(handle: nil, index: nil, value: nil, flow_in: nil)
      OpsExecutor.execute("TensorArrayWrite", [handle, index, value, flow_in])
    end

    def self.tensor_array_write_v2(handle: nil, index: nil, value: nil, flow_in: nil)
      OpsExecutor.execute("TensorArrayWriteV2", [handle, index, value, flow_in])
    end

    def self.tensor_array_write_v3(handle: nil, index: nil, value: nil, flow_in: nil)
      OpsExecutor.execute("TensorArrayWriteV3", [handle, index, value, flow_in])
    end

    def self.tensor_dataset(components: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("TensorDataset", [components], Toutput_types: output_types, output_shapes: output_shapes)
    end

    def self.tensor_forest_create_tree_variable(tree_handle: nil, tree_config: nil)
      OpsExecutor.execute("TensorForestCreateTreeVariable", [tree_handle, tree_config])
    end

    def self.tensor_forest_tree_deserialize(tree_handle: nil, tree_config: nil)
      OpsExecutor.execute("TensorForestTreeDeserialize", [tree_handle, tree_config])
    end

    def self.tensor_forest_tree_is_initialized_op(tree_handle: nil)
      OpsExecutor.execute("TensorForestTreeIsInitializedOp", [tree_handle])
    end

    def self.tensor_forest_tree_predict(tree_handle: nil, dense_features: nil, logits_dimension: nil)
      OpsExecutor.execute("TensorForestTreePredict", [tree_handle, dense_features], logits_dimension: logits_dimension)
    end

    def self.tensor_forest_tree_resource_handle_op(container: nil, shared_name: nil)
      OpsExecutor.execute("TensorForestTreeResourceHandleOp", [], container: container, shared_name: shared_name)
    end

    def self.tensor_forest_tree_serialize(tree_handle: nil)
      OpsExecutor.execute("TensorForestTreeSerialize", [tree_handle])
    end

    def self.tensor_forest_tree_size(tree_handle: nil)
      OpsExecutor.execute("TensorForestTreeSize", [tree_handle])
    end

    def self.tensor_list_concat(input_handle: nil, element_dtype: nil, element_shape: nil)
      OpsExecutor.execute("TensorListConcat", [input_handle], element_dtype: element_dtype, element_shape: element_shape)
    end

    def self.tensor_list_concat_lists(input_a: nil, input_b: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListConcatLists", [input_a, input_b], element_dtype: element_dtype)
    end

    def self.tensor_list_concat_v2(input_handle: nil, element_shape: nil, leading_dims: nil, element_dtype: nil, shape_type: nil)
      OpsExecutor.execute("TensorListConcatV2", [input_handle, element_shape, leading_dims], element_dtype: element_dtype, shape_type: shape_type)
    end

    def self.tensor_list_element_shape(input_handle: nil, shape_type: nil)
      OpsExecutor.execute("TensorListElementShape", [input_handle], shape_type: shape_type)
    end

    def self.tensor_list_from_tensor(tensor: nil, element_shape: nil, element_dtype: nil, shape_type: nil)
      OpsExecutor.execute("TensorListFromTensor", [tensor, element_shape], element_dtype: element_dtype, shape_type: shape_type)
    end

    def self.tensor_list_gather(input_handle: nil, indices: nil, element_shape: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListGather", [input_handle, indices, element_shape], element_dtype: element_dtype)
    end

    def self.tensor_list_get_item(input_handle: nil, index: nil, element_shape: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListGetItem", [input_handle, index, element_shape], element_dtype: element_dtype)
    end

    def self.tensor_list_length(input_handle: nil)
      OpsExecutor.execute("TensorListLength", [input_handle])
    end

    def self.tensor_list_pop_back(input_handle: nil, element_shape: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListPopBack", [input_handle, element_shape], element_dtype: element_dtype)
    end

    def self.tensor_list_push_back(input_handle: nil, tensor: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListPushBack", [input_handle, tensor], element_dtype: element_dtype)
    end

    def self.tensor_list_push_back_batch(input_handles: nil, tensor: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListPushBackBatch", [input_handles, tensor], element_dtype: element_dtype)
    end

    def self.tensor_list_reserve(element_shape: nil, num_elements: nil, element_dtype: nil, shape_type: nil)
      OpsExecutor.execute("TensorListReserve", [element_shape, num_elements], element_dtype: element_dtype, shape_type: shape_type)
    end

    def self.tensor_list_resize(input_handle: nil, size: nil)
      OpsExecutor.execute("TensorListResize", [input_handle, size])
    end

    def self.tensor_list_scatter(tensor: nil, indices: nil, element_shape: nil, element_dtype: nil, shape_type: nil)
      OpsExecutor.execute("TensorListScatter", [tensor, indices, element_shape], element_dtype: element_dtype, shape_type: shape_type)
    end

    def self.tensor_list_scatter_into_existing_list(input_handle: nil, tensor: nil, indices: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListScatterIntoExistingList", [input_handle, tensor, indices], element_dtype: element_dtype)
    end

    def self.tensor_list_scatter_v2(tensor: nil, indices: nil, element_shape: nil, num_elements: nil, element_dtype: nil, shape_type: nil)
      OpsExecutor.execute("TensorListScatterV2", [tensor, indices, element_shape, num_elements], element_dtype: element_dtype, shape_type: shape_type)
    end

    def self.tensor_list_set_item(input_handle: nil, index: nil, item: nil, element_dtype: nil)
      OpsExecutor.execute("TensorListSetItem", [input_handle, index, item], element_dtype: element_dtype)
    end

    def self.tensor_list_split(tensor: nil, element_shape: nil, lengths: nil, element_dtype: nil, shape_type: nil)
      OpsExecutor.execute("TensorListSplit", [tensor, element_shape, lengths], element_dtype: element_dtype, shape_type: shape_type)
    end

    def self.tensor_list_stack(input_handle: nil, element_shape: nil, element_dtype: nil, num_elements: nil)
      OpsExecutor.execute("TensorListStack", [input_handle, element_shape], element_dtype: element_dtype, num_elements: num_elements)
    end

    def self.tensor_scatter_add(tensor: nil, indices: nil, updates: nil)
      OpsExecutor.execute("TensorScatterAdd", [tensor, indices, updates])
    end

    def self.tensor_scatter_sub(tensor: nil, indices: nil, updates: nil)
      OpsExecutor.execute("TensorScatterSub", [tensor, indices, updates])
    end

    def self.tensor_scatter_update(tensor: nil, indices: nil, updates: nil)
      OpsExecutor.execute("TensorScatterUpdate", [tensor, indices, updates])
    end

    def self.tensor_slice_dataset(components: nil, output_shapes: nil)
      OpsExecutor.execute("TensorSliceDataset", [components], output_shapes: output_shapes)
    end

    def self.tensor_strided_slice_update(input: nil, start: nil, stop: nil, strides: nil, value: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
      OpsExecutor.execute("TensorStridedSliceUpdate", [input, start, stop, strides, value], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
    end

    def self.tensor_summary(tensor: nil, description: nil, labels: nil, display_name: nil)
      OpsExecutor.execute("TensorSummary", [tensor], description: description, labels: labels, display_name: display_name)
    end

    def self.tensor_summary_v2(tag: nil, tensor: nil, serialized_summary_metadata: nil)
      OpsExecutor.execute("TensorSummaryV2", [tag, tensor, serialized_summary_metadata])
    end

    def self.text_line_dataset(filenames: nil, compression_type: nil, buffer_size: nil)
      OpsExecutor.execute("TextLineDataset", [filenames, compression_type, buffer_size])
    end

    def self.text_line_reader(skip_header_lines: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("TextLineReader", [], skip_header_lines: skip_header_lines, container: container, shared_name: shared_name)
    end

    def self.text_line_reader_v2(skip_header_lines: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("TextLineReaderV2", [], skip_header_lines: skip_header_lines, container: container, shared_name: shared_name)
    end

    def self.thread_unsafe_unigram_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("ThreadUnsafeUnigramCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
    end

    def self.tile(input: nil, multiples: nil)
      OpsExecutor.execute("Tile", [input, multiples])
    end

    def self.tile_grad(input: nil, multiples: nil)
      OpsExecutor.execute("TileGrad", [input, multiples])
    end

    def self.timestamp
      OpsExecutor.execute("Timestamp", [])
    end

    def self.top_k(input: nil, k: nil, sorted: nil)
      OpsExecutor.execute("TopK", [input], k: k, sorted: sorted)
    end

    def self.top_kv2(input: nil, k: nil, sorted: nil)
      OpsExecutor.execute("TopKV2", [input, k], sorted: sorted)
    end

    def self.transpose(x: nil, perm: nil)
      OpsExecutor.execute("Transpose", [x, perm])
    end

    def self.tridiagonal_mat_mul(superdiag: nil, maindiag: nil, subdiag: nil, rhs: nil)
      OpsExecutor.execute("TridiagonalMatMul", [superdiag, maindiag, subdiag, rhs])
    end

    def self.tridiagonal_solve(diagonals: nil, rhs: nil, partial_pivoting: nil)
      OpsExecutor.execute("TridiagonalSolve", [diagonals, rhs], partial_pivoting: partial_pivoting)
    end

    def self.truncate_div(x: nil, y: nil)
      OpsExecutor.execute("TruncateDiv", [x, y])
    end

    def self.truncate_mod(x: nil, y: nil)
      OpsExecutor.execute("TruncateMod", [x, y])
    end

    def self.truncated_normal(shape: nil, seed: nil, seed2: nil, dtype: nil)
      OpsExecutor.execute("TruncatedNormal", [shape], seed: seed, seed2: seed2, dtype: dtype)
    end

    def self.try_rpc(address: nil, method: nil, request: nil, protocol: nil, fail_fast: nil, timeout_in_ms: nil)
      OpsExecutor.execute("TryRpc", [address, method, request], protocol: protocol, fail_fast: fail_fast, timeout_in_ms: timeout_in_ms)
    end

    def self.unbatch(batched_tensor: nil, batch_index: nil, id: nil, timeout_micros: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("Unbatch", [batched_tensor, batch_index, id], timeout_micros: timeout_micros, container: container, shared_name: shared_name)
    end

    def self.unbatch_grad(original_input: nil, batch_index: nil, grad: nil, id: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("UnbatchGrad", [original_input, batch_index, grad, id], container: container, shared_name: shared_name)
    end

    def self.unicode_decode(input: nil, input_encoding: nil, errors: nil, replacement_char: nil, replace_control_characters: nil)
      OpsExecutor.execute("UnicodeDecode", [input], input_encoding: input_encoding, errors: errors, replacement_char: replacement_char, replace_control_characters: replace_control_characters)
    end

    def self.unicode_decode_with_offsets(input: nil, input_encoding: nil, errors: nil, replacement_char: nil, replace_control_characters: nil)
      OpsExecutor.execute("UnicodeDecodeWithOffsets", [input], input_encoding: input_encoding, errors: errors, replacement_char: replacement_char, replace_control_characters: replace_control_characters)
    end

    def self.unicode_encode(input_values: nil, input_splits: nil, errors: nil, output_encoding: nil, replacement_char: nil)
      OpsExecutor.execute("UnicodeEncode", [input_values, input_splits], errors: errors, output_encoding: output_encoding, replacement_char: replacement_char)
    end

    def self.unicode_script(input: nil)
      OpsExecutor.execute("UnicodeScript", [input])
    end

    def self.unicode_transcode(input: nil, input_encoding: nil, output_encoding: nil, errors: nil, replacement_char: nil, replace_control_characters: nil)
      OpsExecutor.execute("UnicodeTranscode", [input], input_encoding: input_encoding, output_encoding: output_encoding, errors: errors, replacement_char: replacement_char, replace_control_characters: replace_control_characters)
    end

    def self.uniform_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
      OpsExecutor.execute("UniformCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
    end

    def self.unique(x: nil, out_idx: nil)
      OpsExecutor.execute("Unique", [x], out_idx: out_idx)
    end

    def self.unique_v2(x: nil, axis: nil, out_idx: nil)
      OpsExecutor.execute("UniqueV2", [x, axis], out_idx: out_idx)
    end

    def self.unique_with_counts(x: nil, out_idx: nil)
      OpsExecutor.execute("UniqueWithCounts", [x], out_idx: out_idx)
    end

    def self.unique_with_counts_v2(x: nil, axis: nil, out_idx: nil)
      OpsExecutor.execute("UniqueWithCountsV2", [x, axis], out_idx: out_idx)
    end

    def self.unpack(value: nil, num: nil, axis: nil)
      OpsExecutor.execute("Unpack", [value], num: num, axis: axis)
    end

    def self.unravel_index(indices: nil, dims: nil)
      OpsExecutor.execute("UnravelIndex", [indices, dims])
    end

    def self.unsorted_segment_max(data: nil, segment_ids: nil, num_segments: nil)
      OpsExecutor.execute("UnsortedSegmentMax", [data, segment_ids, num_segments])
    end

    def self.unsorted_segment_min(data: nil, segment_ids: nil, num_segments: nil)
      OpsExecutor.execute("UnsortedSegmentMin", [data, segment_ids, num_segments])
    end

    def self.unsorted_segment_prod(data: nil, segment_ids: nil, num_segments: nil)
      OpsExecutor.execute("UnsortedSegmentProd", [data, segment_ids, num_segments])
    end

    def self.unsorted_segment_sum(data: nil, segment_ids: nil, num_segments: nil)
      OpsExecutor.execute("UnsortedSegmentSum", [data, segment_ids, num_segments])
    end

    def self.unstage(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("Unstage", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
    end

    def self.unwrap_dataset_variant(input_handle: nil)
      OpsExecutor.execute("UnwrapDatasetVariant", [input_handle])
    end

    def self.upper_bound(sorted_inputs: nil, values: nil, out_type: nil)
      OpsExecutor.execute("UpperBound", [sorted_inputs, values], out_type: out_type)
    end

    def self.var_handle_op(container: nil, shared_name: nil, dtype: nil, shape: nil)
      OpsExecutor.execute("VarHandleOp", [], container: container, shared_name: shared_name, dtype: dtype, shape: shape)
    end

    def self.var_is_initialized_op(resource: nil)
      OpsExecutor.execute("VarIsInitializedOp", [resource])
    end

    def self.variable(shape: nil, dtype: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("Variable", [], shape: shape, dtype: dtype, container: container, shared_name: shared_name)
    end

    def self.variable_shape(input: nil, out_type: nil)
      OpsExecutor.execute("VariableShape", [input], out_type: out_type)
    end

    def self.variable_v2(shape: nil, dtype: nil, container: nil, shared_name: nil)
      OpsExecutor.execute("VariableV2", [], shape: shape, dtype: dtype, container: container, shared_name: shared_name)
    end

    def self.where(input: nil)
      OpsExecutor.execute("Where", [input])
    end

    def self.while(input: nil, cond: nil, body: nil, output_shapes: nil, parallel_iterations: nil)
      OpsExecutor.execute("While", [input], cond: cond, body: body, output_shapes: output_shapes, parallel_iterations: parallel_iterations)
    end

    def self.whole_file_reader(container: nil, shared_name: nil)
      OpsExecutor.execute("WholeFileReader", [], container: container, shared_name: shared_name)
    end

    def self.whole_file_reader_v2(container: nil, shared_name: nil)
      OpsExecutor.execute("WholeFileReaderV2", [], container: container, shared_name: shared_name)
    end

    def self.window_dataset(input_dataset: nil, size: nil, shift: nil, stride: nil, drop_remainder: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("WindowDataset", [input_dataset, size, shift, stride, drop_remainder], output_types: output_types, output_shapes: output_shapes)
    end

    def self.worker_heartbeat(request: nil)
      OpsExecutor.execute("WorkerHeartbeat", [request])
    end

    def self.wrap_dataset_variant(input_handle: nil)
      OpsExecutor.execute("WrapDatasetVariant", [input_handle])
    end

    def self.write_audio_summary(writer: nil, step: nil, tag: nil, tensor: nil, sample_rate: nil, max_outputs: nil)
      OpsExecutor.execute("WriteAudioSummary", [writer, step, tag, tensor, sample_rate], max_outputs: max_outputs)
    end

    def self.write_file(filename: nil, contents: nil)
      OpsExecutor.execute("WriteFile", [filename, contents])
    end

    def self.write_graph_summary(writer: nil, step: nil, tensor: nil)
      OpsExecutor.execute("WriteGraphSummary", [writer, step, tensor])
    end

    def self.write_histogram_summary(writer: nil, step: nil, tag: nil, values: nil)
      OpsExecutor.execute("WriteHistogramSummary", [writer, step, tag, values])
    end

    def self.write_image_summary(writer: nil, step: nil, tag: nil, tensor: nil, bad_color: nil, max_images: nil)
      OpsExecutor.execute("WriteImageSummary", [writer, step, tag, tensor, bad_color], max_images: max_images)
    end

    def self.write_raw_proto_summary(writer: nil, step: nil, tensor: nil)
      OpsExecutor.execute("WriteRawProtoSummary", [writer, step, tensor])
    end

    def self.write_scalar_summary(writer: nil, step: nil, tag: nil, value: nil)
      OpsExecutor.execute("WriteScalarSummary", [writer, step, tag, value])
    end

    def self.write_summary(writer: nil, step: nil, tensor: nil, tag: nil, summary_metadata: nil)
      OpsExecutor.execute("WriteSummary", [writer, step, tensor, tag, summary_metadata])
    end

    def self.xdivy(x: nil, y: nil)
      OpsExecutor.execute("Xdivy", [x, y])
    end

    def self.xlogy(x: nil, y: nil)
      OpsExecutor.execute("Xlogy", [x, y])
    end

    def self.zeros_like(x: nil)
      OpsExecutor.execute("ZerosLike", [x])
    end

    def self.zeta(x: nil, q: nil)
      OpsExecutor.execute("Zeta", [x, q])
    end

    def self.zip_dataset(input_datasets: nil, output_types: nil, output_shapes: nil)
      OpsExecutor.execute("ZipDataset", [input_datasets], output_types: output_types, output_shapes: output_shapes, N: input_datasets.length)
    end
  end
end
